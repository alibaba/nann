# -*- encoding:utf-8 -*-
import torch
import torch.nn as nn
from uer.utils.constants import *
from uer.utils.subword import *
from uer.layers.transformer_qkv import TransformerLayer as TransformerLayer_qkv
from uer.layers.transformer import TransformerLayer
from torch.autograd import Variable
from uer.layers.layer_norm import LayerNorm


class VaeModel(nn.Module):
    """
    BertModel consists of three parts:
        - embedding: token embedding, position embedding, segment embedding
        - encoder: multi-layer transformer encoders
        - target: mlm and nsp tasks
    """
    def __init__(self, args, embedding, encoder, target, subencoder = None):
        super(VaeModel, self).__init__()
        self.embedding = embedding
        self.encoder = encoder
        self.target = target
        self.hidden_size = args.hidden_size
        self.layers_num = args.layers_num
        self.seq_length = args.seq_length

        self.condition_text_mulogvar = nn.Linear(self.hidden_size, self.hidden_size * 2, bias=False)
        self.condition_title_mulogvar = nn.Sequential(
            nn.Linear(self.hidden_size, self.hidden_size),
            nn.Tanh(),
            nn.Linear(self.hidden_size, self.hidden_size * 2, bias=False)
        )
        self.cluster_center = Variable(0.02 * torch.randn(10, self.hidden_size), requires_grad = True)
        self.w_transformer = TransformerLayer_qkv(args)

        self.decoder_query = Variable(0.02 * torch.randn(self.seq_length, self.hidden_size), requires_grad = True)
        self.decoder_w_transformer = TransformerLayer_qkv(args)
        self.decoder_transformer = nn.ModuleList([
            TransformerLayer(args) for _ in range(self.layers_num)
        ])

        self.dropout = nn.Dropout(args.dropout)
        self.layer_norm = LayerNorm(args.emb_size)




    def forward(self, src, tgt, seg, condition_title, condition_title_seg, condition_text, condition_text_seg, masks):
        # [batch_size, seq_length, emb_size]

        batch_size, seq_length = src.size()
        batch_size, condition_length = condition_title.size()
        mask = torch.zeros(batch_size, 1, condition_length, condition_length, device=condition_title.device)
        condition_title_emb = self.embedding(condition_title, condition_title_seg)
        '''
        mask = (condition_title_seg > 0). \
                unsqueeze(1). \
                repeat(1, condition_length, 1). \
                unsqueeze(1)
        mask = mask.float()
        mask = (1.0 - mask) * -10000.0
        '''
        condition_title_output = self.encoder(condition_title_emb, condition_title_seg, mask)

        condition_title_length = condition_text.size(1)
        mask = torch.zeros(batch_size, 1, condition_title_length, condition_title_length, device=condition_title.device)
        condition_text_emb = self.embedding(condition_text, condition_text_seg)
        '''
        mask = (condition_text_seg > 0). \
                unsqueeze(1). \
                repeat(1, condition_length, 1). \
                unsqueeze(1)
        mask = mask.float()
        mask = (1.0 - mask) * -10000.0
        '''
        condition_text_output = self.encoder(condition_text_emb, condition_text_seg, mask)

        query = self.cluster_center.to(device=condition_text_output.device).unsqueeze(0).repeat(batch_size, 1, 1)
        #query = self.cluster_center.unsqueeze(0).repeat(batch_size, 1, 1)

        mask = torch.zeros(batch_size, 1, 10, condition_length, device=condition_title_output.device)
        condition_title_output = self.w_transformer(query, condition_title_output, condition_title_output, mask)

        mask = torch.zeros(batch_size, 1, 10, condition_title_length, device=condition_text_output.device)
        condition_text_output = self.w_transformer(query, condition_text_output, condition_text_output, mask)

        hidden_size = condition_text_output.size(-1)

        condition_title_mu, condition_title_logvar = self.condition_title_mulogvar(condition_title_output).split(hidden_size, dim=-1)
        condition_text_mu, condition_text_logvar = self.condition_text_mulogvar(condition_text_output).split(hidden_size, dim=-1)

        z = torch.randn([batch_size, 10, self.hidden_size], device=condition_text_mu.device)
        condition_title_latent = z * torch.exp(0.5 * condition_title_logvar) + condition_title_mu
        condition_text_latent = z * torch.exp(0.5 * condition_text_logvar) + condition_text_mu

        decoder_query = self.decoder_query.to(device=condition_text_latent.device).unsqueeze(0).repeat(batch_size, 1, 1)
        mask = torch.zeros(batch_size, 1, self.seq_length, 10, device=condition_text_latent.device)
        decoder_input = self.decoder_w_transformer(decoder_query, condition_text_latent, condition_text_latent, mask)
        mask = torch.zeros(batch_size, 1, self.seq_length, self.seq_length, device=decoder_input.device)
        pos_emb = self.embedding.position_embedding(torch.arange(0, decoder_input.size(1), device=decoder_input.device, \
                                          dtype=torch.long).unsqueeze(0).repeat(decoder_input.size(0), 1))
        hidden = decoder_input + pos_emb
        hidden = self.dropout(self.layer_norm(hidden))
        for i in range(self.layers_num):
            hidden = self.decoder_transformer[i](hidden, mask)
        output = hidden

        loss_info = self.target(output, tgt, condition_title_mu, condition_title_logvar, condition_text_mu, condition_text_logvar)

        return loss_info
