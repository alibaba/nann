+ LD_LIBRARY_PATH=/usr/local/nvidia/lib64
+ PATH=/usr/local/nvidia/bin/
+ /usr/local/nvidia/bin/nvidia-cuda-mps-control -d
An instance of this daemon is already running
+ TF_XLA_PTX_CACHE_DIR=./xla_cache
+ TF_CPP_MIN_VLOG_LEVEL=0
+ BLAZE_USE_MPS=1
+ LD_LIBRARY_PATH=/usr/local/nvidia/lib64:/usr/local/cuda-11.2/lib64
+ ../../../build/benchmark/benchmark benchmark_conf
2022-08-04 08:14:33.627125: I /home/yunlong.xyl/blaze-benchmark/benchmark/core/model.cc:333] 1656400837458256.runmeta, inferred batchsize = 448, ad_rtp_wt_ctr_wt_union_v1_turing
2022-08-04 08:14:33.628075: I /home/yunlong.xyl/tensorflow/tensorflow/core/common_runtime/direct_session.h:441] Blaze will use globla_opts : device_count {
  key: "GPU"
  value: 1
}
gpu_options {
  allow_growth: true
  visible_device_list: "0"
  experimental {
    virtual_devices {
      memory_limit_mb: 12288
      memory_limit_mb: 12288
      memory_limit_mb: 12288
      memory_limit_mb: 12288
    }
  }
}
allow_soft_placement: true
graph_options {
  rewrite_options {
    layout_optimizer: OFF
    auto_mixed_precision: ON
  }
}
blaze_options {
  warmup_batchsize: 1
  warmup_batchsize: 64
  warmup_batchsize: 128
  warmup_batchsize: 256
  warmup_batchsize: 384
  warmup_batchsize: 512
  warmup_batchsize: 1024
  xla_compilation: true
  gemm_optimization: true
  auto_mixed_precision: true
  no_warmup_inputs: "att_ncomm2"
  config_proto {
    graph_options {
      rewrite_options {
        auto_mixed_precision: OFF
        gemm_optimization: ON
      }
    }
    force_run_in_caller_thread: true
    enable_graph_opt_place: true
  }
  wait_ms: 20
}

2022-08-04 08:14:33.628212: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-08-04 08:14:33.729039: I /home/yunlong.xyl/blaze-benchmark/benchmark/core/model.cc:166] GetDeviceCount: cpu_count =  1, gpu_count = 4
2022-08-04 08:14:33.729143: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F FMA
2022-08-04 08:14:33.744850: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-08-04 08:14:33.744874: I tensorflow/stream_executor/executor_cache.cc:41] TF_NUM_CONTEXTS_PER_GPU = 4
2022-08-04 08:14:33.744886: I tensorflow/stream_executor/executor_cache.cc:62] TF_NUM_CONTEXTS_PER_GPU = 4
2022-08-04 08:14:33.745266: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2022-08-04 08:14:33.750250: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559f0d696c10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-08-04 08:14:33.750270: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-08-04 08:14:33.751535: I tensorflow/stream_executor/executor_cache.cc:62] TF_NUM_CONTEXTS_PER_GPU = 4
2022-08-04 08:14:33.880166: I tensorflow/stream_executor/cuda/cuda_driver.cc:454] cuDevicePrimaryCtxRetain context 0x559f0d201f00
2022-08-04 08:14:33.883609: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559f0d12c2b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-08-04 08:14:33.883629: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-SXM4-80GB, Compute Capability 8.0
2022-08-04 08:14:33.887167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1642] Found device 0 with properties: 
name: NVIDIA A100-SXM4-80GB major: 8 minor: 0 memoryClockRate(GHz): 1.41
pciBusID: 0000:54:00.0
2022-08-04 08:14:33.887183: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-08-04 08:14:33.890095: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-08-04 08:14:33.890841: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-08-04 08:14:33.891023: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-08-04 08:14:33.891681: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2022-08-04 08:14:33.892231: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-08-04 08:14:33.892307: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-08-04 08:14:33.898697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1770] Adding visible gpu devices: 0
2022-08-04 08:14:33.898738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-08-04 08:14:33.898743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2022-08-04 08:14:33.898746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2022-08-04 08:14:33.914203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 08:14:33.917528: I tensorflow/stream_executor/executor_cache.cc:62] TF_NUM_CONTEXTS_PER_GPU = 4
2022-08-04 08:14:34.016821: I tensorflow/stream_executor/cuda/cuda_driver.cc:458] Primary context has been used, cuCtxCreate context 0x559f0da78880
2022-08-04 08:14:34.016850: W tensorflow/stream_executor/cuda/cuda_driver.cc:472] A non-primary context 0x559f0d201f00 for device 0 exists before initializing the StreamExecutor. The primary context is now 0x559f0da78880. We haven't verified StreamExecutor works with that.
2022-08-04 08:14:34.020045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 08:14:34.023482: I tensorflow/stream_executor/executor_cache.cc:62] TF_NUM_CONTEXTS_PER_GPU = 4
2022-08-04 08:14:34.134370: I tensorflow/stream_executor/cuda/cuda_driver.cc:458] Primary context has been used, cuCtxCreate context 0x559f0e067800
2022-08-04 08:14:34.134393: W tensorflow/stream_executor/cuda/cuda_driver.cc:472] A non-primary context 0x559f0da78880 for device 0 exists before initializing the StreamExecutor. The primary context is now 0x559f0e067800. We haven't verified StreamExecutor works with that.
2022-08-04 08:14:34.137662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 08:14:34.141461: I tensorflow/stream_executor/executor_cache.cc:62] TF_NUM_CONTEXTS_PER_GPU = 4
2022-08-04 08:14:34.238584: I tensorflow/stream_executor/cuda/cuda_driver.cc:458] Primary context has been used, cuCtxCreate context 0x559f0e6619d0
2022-08-04 08:14:34.238608: W tensorflow/stream_executor/cuda/cuda_driver.cc:472] A non-primary context 0x559f0e067800 for device 0 exists before initializing the StreamExecutor. The primary context is now 0x559f0e6619d0. We haven't verified StreamExecutor works with that.
2022-08-04 08:14:34.241740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 08:14:34.246936: I tensorflow/core/common_runtime/placer.cc:130] Not allow optimize placer
2022-08-04 08:14:34.246986: I /home/yunlong.xyl/blaze-benchmark/benchmark/core/model.cc:234] Predictor 0 uses session ad_rtp_wt_ctr_wt_union_v1_turing/CPU:0/GPU:0
2022-08-04 08:14:34.250399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1642] Found device 0 with properties: 
name: NVIDIA A100-SXM4-80GB major: 8 minor: 0 memoryClockRate(GHz): 1.41
pciBusID: 0000:54:00.0
2022-08-04 08:14:34.250421: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-08-04 08:14:34.250427: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-08-04 08:14:34.250432: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-08-04 08:14:34.250437: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-08-04 08:14:34.250441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2022-08-04 08:14:34.250446: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-08-04 08:14:34.250450: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-08-04 08:14:34.256385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1770] Adding visible gpu devices: 0
2022-08-04 08:14:34.256407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-08-04 08:14:34.256412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2022-08-04 08:14:34.256416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2022-08-04 08:14:34.271933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 08:14:34.275425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 08:14:34.278814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 08:14:34.282113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 08:14:34.282410: I tensorflow/core/common_runtime/placer.cc:130] Not allow optimize placer
2022-08-04 08:14:34.282456: I /home/yunlong.xyl/blaze-benchmark/benchmark/core/model.cc:234] Predictor 1 uses session ad_rtp_wt_ctr_wt_union_v1_turing/CPU:0/GPU:1
2022-08-04 08:14:34.286425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1642] Found device 0 with properties: 
name: NVIDIA A100-SXM4-80GB major: 8 minor: 0 memoryClockRate(GHz): 1.41
pciBusID: 0000:54:00.0
2022-08-04 08:14:34.286449: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-08-04 08:14:34.286455: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-08-04 08:14:34.286467: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-08-04 08:14:34.286474: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-08-04 08:14:34.286481: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2022-08-04 08:14:34.286488: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-08-04 08:14:34.286495: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-08-04 08:14:34.293092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1770] Adding visible gpu devices: 0
2022-08-04 08:14:34.293118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-08-04 08:14:34.293123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2022-08-04 08:14:34.293127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2022-08-04 08:14:34.309408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 08:14:34.312609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 08:14:34.315931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 08:14:34.319237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 08:14:34.319428: I tensorflow/core/common_runtime/placer.cc:130] Not allow optimize placer
2022-08-04 08:14:34.319468: I /home/yunlong.xyl/blaze-benchmark/benchmark/core/model.cc:234] Predictor 2 uses session ad_rtp_wt_ctr_wt_union_v1_turing/CPU:0/GPU:2
2022-08-04 08:14:34.323025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1642] Found device 0 with properties: 
name: NVIDIA A100-SXM4-80GB major: 8 minor: 0 memoryClockRate(GHz): 1.41
pciBusID: 0000:54:00.0
2022-08-04 08:14:34.323042: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-08-04 08:14:34.323049: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-08-04 08:14:34.323056: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-08-04 08:14:34.323062: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-08-04 08:14:34.323069: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2022-08-04 08:14:34.323074: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-08-04 08:14:34.323080: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-08-04 08:14:34.329388: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1770] Adding visible gpu devices: 0
2022-08-04 08:14:34.329407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-08-04 08:14:34.329412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2022-08-04 08:14:34.329416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2022-08-04 08:14:34.345342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 08:14:34.348475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 08:14:34.351635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 08:14:34.354778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 08:14:34.354949: I tensorflow/core/common_runtime/placer.cc:130] Not allow optimize placer
2022-08-04 08:14:34.354979: I /home/yunlong.xyl/blaze-benchmark/benchmark/core/model.cc:234] Predictor 3 uses session ad_rtp_wt_ctr_wt_union_v1_turing/CPU:0/GPU:3
2022-08-04 08:14:34.388533: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1816] Running auto_mixed_precision graph optimizer
2022-08-04 08:14:34.388731: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1268] No whitelist ops found, nothing to do
2022-08-04 08:14:34.392797: I tensorflow/core/kernels/blaze_xla_kernel.cc:80] blaze set thread pool size 2
2022-08-04 08:14:34.393007: I tensorflow/core/kernels/blaze_xla_kernel.cc:80] blaze set thread pool size 2
2022-08-04 08:14:34.393016: I tensorflow/core/kernels/blaze_xla_kernel.cc:88] blaze max waiting count 10
2022-08-04 08:14:34.393114: I tensorflow/core/kernels/blaze_xla_kernel.cc:155] Parse blaze options succ warmup_batchsize: 1
warmup_batchsize: 64
warmup_batchsize: 128
warmup_batchsize: 256
warmup_batchsize: 384
warmup_batchsize: 512
warmup_batchsize: 1024
xla_compilation: true
gemm_optimization: true
auto_mixed_precision: true
no_warmup_inputs: "att_ncomm2"
config_proto {
  graph_options {
    rewrite_options {
      auto_mixed_precision: OFF
      gemm_optimization: ON
    }
  }
  force_run_in_caller_thread: true
  enable_graph_opt_place: true
}
wait_ms: 20

[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:317] Error parsing text-format tensorflow.GraphDef: 2:1: Expected identifier, got: 6
2022-08-04 08:14:34.469892: I tensorflow/core/kernels/blaze_xla_kernel.cc:100] Blaze create with options warmup_batchsize: 1
warmup_batchsize: 64
warmup_batchsize: 128
warmup_batchsize: 256
warmup_batchsize: 384
warmup_batchsize: 512
warmup_batchsize: 1024
xla_compilation: true
gemm_optimization: true
auto_mixed_precision: true
no_warmup_inputs: "att_ncomm2"
config_proto {
  gpu_options {
    allow_growth: true
  }
  allow_soft_placement: true
  graph_options {
    rewrite_options {
      auto_mixed_precision: OFF
      gemm_optimization: ON
    }
  }
  force_run_in_caller_thread: true
  enable_graph_opt_place: true
}
wait_ms: 20

2022-08-04 08:14:34.473983: I tensorflow/core/kernels/blaze_predictor.cc:110] create session with config gpu_options {
  allow_growth: true
  visible_device_list: "0"
  experimental {
    virtual_devices {
      memory_limit_mb: 12288
      memory_limit_mb: 12288
      memory_limit_mb: 12288
      memory_limit_mb: 12288
    }
  }
}
allow_soft_placement: true
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    auto_mixed_precision: OFF
    gemm_optimization: ON
  }
}
enable_graph_opt_place: true
is_blaze: true

2022-08-04 08:14:34.476628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1642] Found device 0 with properties: 
name: NVIDIA A100-SXM4-80GB major: 8 minor: 0 memoryClockRate(GHz): 1.41
pciBusID: 0000:54:00.0
2022-08-04 08:14:34.476651: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-08-04 08:14:34.476658: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-08-04 08:14:34.476663: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-08-04 08:14:34.476670: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-08-04 08:14:34.476676: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2022-08-04 08:14:34.476684: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-08-04 08:14:34.476691: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-08-04 08:14:34.481189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1770] Adding visible gpu devices: 0
2022-08-04 08:14:34.481216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-08-04 08:14:34.481222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2022-08-04 08:14:34.481225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2022-08-04 08:14:34.492730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 08:14:34.494983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 08:14:34.497241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 08:14:34.499484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 08:14:34.499529: I tensorflow/core/kernels/blaze_predictor.cc:119] Blaze start with step id 1024
2022-08-04 08:14:34.499534: I tensorflow/core/kernels/blaze_predictor.cc:120] Creat session succ 0x559f0ef54440
2022-08-04 08:14:34.499541: I tensorflow/core/kernels/blaze_predictor.cc:73] BlazePredictor will use device /job:localhost/replica:0/task:0/device:GPU:0
2022-08-04 08:14:34.507892: I tensorflow/core/common_runtime/placer.cc:128] Allow optimize placer
2022-08-04 08:14:34.508200: I tensorflow/core/kernels/blaze_predictor.cc:92] create session with callable options feed: "ncomm"
feed: "comm"
fetch: "Softmax"
feed_devices {
  key: "comm"
  value: "/job:localhost/replica:0/task:0/device:GPU:0"
}
feed_devices {
  key: "ncomm"
  value: "/job:localhost/replica:0/task:0/device:GPU:0"
}
fetch_devices {
  key: "Softmax"
  value: "/job:localhost/replica:0/task:0/device:GPU:0"
}
fetch_skip_sync: true

2022-08-04 08:14:34.635682: I tensorflow/compiler/jit/build_xla_ops_pass.cc:398] enable_xla_auto_padding=0
2022-08-04 08:14:34.635717: I tensorflow/compiler/jit/build_xla_ops_pass.cc:404] auto_padding_shape 
2022-08-04 08:14:34.637498: I tensorflow/core/kernels/blaze_predictor.cc:132] MakeCallable succ 0x559f0ef54440
2022-08-04 08:14:34.637519: I tensorflow/core/kernels/blaze_predictor.cc:205] req_dev: /device:CPU:0; blaze_dev: /device:GPU:0
2022-08-04 08:14:34.638930: I tensorflow/core/kernels/blaze_xla_predictor.cc:367] Begin warmup
2022-08-04 08:14:34.640221: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 1
2022-08-04 08:14:34.652217: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [1,906],float [1,975]; Tensor<type: int32 shape: [2] values: 1 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 08:14:34.800822: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:268] Cache XLA PTXs in ./xla_cache. This line is logged at most once for the lifetime of the process.
2022-08-04 08:14:34.800844: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:285] Will not cache XLA CUBINs. This line is logged at most once for the lifetime of the process.
2022-08-04 08:14:34.981399: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:448] Dump 542969767593946827.ptx to ./xla_cache
2022-08-04 08:14:34.981425: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:449] Dump 542969767593946827.hlomodule to ./xla_cache
2022-08-04 08:14:35.150379: I tensorflow/compiler/jit/xla_compilation_cache.cc:292] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-08-04 08:14:35.153862: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 1 has warmuped; cost us: 513602
2022-08-04 08:14:35.153900: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 64
2022-08-04 08:14:35.154110: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [64,906],float [1,975]; Tensor<type: int32 shape: [2] values: 64 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 08:14:35.334542: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:448] Dump 8600006099596751288.ptx to ./xla_cache
2022-08-04 08:14:35.334568: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:449] Dump 8600006099596751288.hlomodule to ./xla_cache
2022-08-04 08:14:35.446673: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-08-04 08:14:36.171279: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-08-04 08:14:36.172146: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 64 has warmuped; cost us: 1018234
2022-08-04 08:14:36.172169: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 128
2022-08-04 08:14:36.172419: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [128,906],float [1,975]; Tensor<type: int32 shape: [2] values: 128 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 08:14:36.354666: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:448] Dump 1994997111870553696.ptx to ./xla_cache
2022-08-04 08:14:36.354692: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:449] Dump 1994997111870553696.hlomodule to ./xla_cache
2022-08-04 08:14:36.496043: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 128 has warmuped; cost us: 323867
2022-08-04 08:14:36.496064: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 256
2022-08-04 08:14:36.496264: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [256,906],float [1,975]; Tensor<type: int32 shape: [2] values: 256 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 08:14:36.677528: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:448] Dump 13167832310349898986.ptx to ./xla_cache
2022-08-04 08:14:36.677565: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:449] Dump 13167832310349898986.hlomodule to ./xla_cache
2022-08-04 08:14:36.812659: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 256 has warmuped; cost us: 316583
2022-08-04 08:14:36.812699: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 384
2022-08-04 08:14:36.813017: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [384,906],float [1,975]; Tensor<type: int32 shape: [2] values: 384 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 08:14:36.996799: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:448] Dump 17001634320680435347.ptx to ./xla_cache
2022-08-04 08:14:36.996824: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:449] Dump 17001634320680435347.hlomodule to ./xla_cache
2022-08-04 08:14:37.136699: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 384 has warmuped; cost us: 323992
2022-08-04 08:14:37.136719: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 512
2022-08-04 08:14:37.136891: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [512,906],float [1,975]; Tensor<type: int32 shape: [2] values: 512 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 08:14:37.318459: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:448] Dump 13437866815018818254.ptx to ./xla_cache
2022-08-04 08:14:37.318493: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:449] Dump 13437866815018818254.hlomodule to ./xla_cache
2022-08-04 08:14:37.454029: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 512 has warmuped; cost us: 317302
2022-08-04 08:14:37.454054: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 1024
2022-08-04 08:14:37.454237: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [1024,906],float [1,975]; Tensor<type: int32 shape: [2] values: 1024 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 08:14:37.631459: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:448] Dump 3038161262149193002.ptx to ./xla_cache
2022-08-04 08:14:37.631494: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:449] Dump 3038161262149193002.hlomodule to ./xla_cache
2022-08-04 08:14:37.769630: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 1024 has warmuped; cost us: 315564
2022-08-04 08:14:37.774224: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1816] Running auto_mixed_precision graph optimizer
2022-08-04 08:14:37.774425: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1268] No whitelist ops found, nothing to do
2022-08-04 08:14:37.785451: I tensorflow/core/kernels/blaze_xla_kernel.cc:80] blaze set thread pool size 2
2022-08-04 08:14:37.785750: I tensorflow/core/kernels/blaze_xla_kernel.cc:80] blaze set thread pool size 2
2022-08-04 08:14:37.785758: I tensorflow/core/kernels/blaze_xla_kernel.cc:88] blaze max waiting count 10
2022-08-04 08:14:37.785947: I tensorflow/core/kernels/blaze_xla_kernel.cc:155] Parse blaze options succ warmup_batchsize: 1
warmup_batchsize: 64
warmup_batchsize: 128
warmup_batchsize: 256
warmup_batchsize: 384
warmup_batchsize: 512
warmup_batchsize: 1024
xla_compilation: true
gemm_optimization: true
auto_mixed_precision: true
no_warmup_inputs: "att_ncomm2"
config_proto {
  graph_options {
    rewrite_options {
      auto_mixed_precision: OFF
      gemm_optimization: ON
    }
  }
  force_run_in_caller_thread: true
  enable_graph_opt_place: true
}
wait_ms: 20

[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:317] Error parsing text-format tensorflow.GraphDef: 2:1: Expected identifier, got: 6
2022-08-04 08:14:37.868182: I tensorflow/core/kernels/blaze_xla_kernel.cc:100] Blaze create with options warmup_batchsize: 1
warmup_batchsize: 64
warmup_batchsize: 128
warmup_batchsize: 256
warmup_batchsize: 384
warmup_batchsize: 512
warmup_batchsize: 1024
xla_compilation: true
gemm_optimization: true
auto_mixed_precision: true
no_warmup_inputs: "att_ncomm2"
config_proto {
  gpu_options {
    allow_growth: true
  }
  allow_soft_placement: true
  graph_options {
    rewrite_options {
      auto_mixed_precision: OFF
      gemm_optimization: ON
    }
  }
  force_run_in_caller_thread: true
  enable_graph_opt_place: true
}
wait_ms: 20

2022-08-04 08:14:37.870864: I tensorflow/core/kernels/blaze_predictor.cc:110] create session with config gpu_options {
  allow_growth: true
  visible_device_list: "0"
  experimental {
    virtual_devices {
      memory_limit_mb: 12288
      memory_limit_mb: 12288
      memory_limit_mb: 12288
      memory_limit_mb: 12288
    }
  }
}
allow_soft_placement: true
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    auto_mixed_precision: OFF
    gemm_optimization: ON
  }
}
enable_graph_opt_place: true
is_blaze: true

2022-08-04 08:14:37.873959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1642] Found device 0 with properties: 
name: NVIDIA A100-SXM4-80GB major: 8 minor: 0 memoryClockRate(GHz): 1.41
pciBusID: 0000:54:00.0
2022-08-04 08:14:37.873985: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-08-04 08:14:37.873998: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-08-04 08:14:37.874005: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-08-04 08:14:37.874014: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-08-04 08:14:37.874024: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2022-08-04 08:14:37.874029: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-08-04 08:14:37.874034: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-08-04 08:14:37.878488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1770] Adding visible gpu devices: 0
2022-08-04 08:14:37.878533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-08-04 08:14:37.878538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2022-08-04 08:14:37.878542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2022-08-04 08:14:37.889891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 08:14:37.892166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 08:14:37.894425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 08:14:37.896680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 08:14:37.896736: I tensorflow/core/kernels/blaze_predictor.cc:119] Blaze start with step id 1024
2022-08-04 08:14:37.896741: I tensorflow/core/kernels/blaze_predictor.cc:120] Creat session succ 0x559f13430110
2022-08-04 08:14:37.896749: I tensorflow/core/kernels/blaze_predictor.cc:73] BlazePredictor will use device /job:localhost/replica:0/task:0/device:GPU:1
2022-08-04 08:14:37.906728: I tensorflow/core/common_runtime/placer.cc:128] Allow optimize placer
2022-08-04 08:14:37.907031: I tensorflow/core/kernels/blaze_predictor.cc:92] create session with callable options feed: "ncomm"
feed: "comm"
fetch: "Softmax"
feed_devices {
  key: "comm"
  value: "/job:localhost/replica:0/task:0/device:GPU:1"
}
feed_devices {
  key: "ncomm"
  value: "/job:localhost/replica:0/task:0/device:GPU:1"
}
fetch_devices {
  key: "Softmax"
  value: "/job:localhost/replica:0/task:0/device:GPU:1"
}
fetch_skip_sync: true

2022-08-04 08:14:37.994653: I tensorflow/compiler/jit/build_xla_ops_pass.cc:398] enable_xla_auto_padding=0
2022-08-04 08:14:37.994695: I tensorflow/compiler/jit/build_xla_ops_pass.cc:404] auto_padding_shape 
2022-08-04 08:14:37.995207: I tensorflow/core/kernels/blaze_predictor.cc:132] MakeCallable succ 0x559f13430110
2022-08-04 08:14:37.995226: I tensorflow/core/kernels/blaze_predictor.cc:205] req_dev: /device:CPU:0; blaze_dev: /device:GPU:1
2022-08-04 08:14:37.995588: I tensorflow/core/kernels/blaze_xla_predictor.cc:367] Begin warmup
2022-08-04 08:14:37.996680: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 1
2022-08-04 08:14:37.996858: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [1,906],float [1,975]; Tensor<type: int32 shape: [2] values: 1 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 08:14:38.514667: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 1 has warmuped; cost us: 517965
2022-08-04 08:14:38.514703: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 64
2022-08-04 08:14:38.514922: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [64,906],float [1,975]; Tensor<type: int32 shape: [2] values: 64 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 08:14:38.698877: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-08-04 08:14:39.419124: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 64 has warmuped; cost us: 904401
2022-08-04 08:14:39.419163: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 128
2022-08-04 08:14:39.419327: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [128,906],float [1,975]; Tensor<type: int32 shape: [2] values: 128 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 08:14:39.591621: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-08-04 08:14:39.596470: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 128 has warmuped; cost us: 177292
2022-08-04 08:14:39.596491: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 256
2022-08-04 08:14:39.596661: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [256,906],float [1,975]; Tensor<type: int32 shape: [2] values: 256 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 08:14:39.774724: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-08-04 08:14:39.779227: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 256 has warmuped; cost us: 182727
2022-08-04 08:14:39.779243: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 384
2022-08-04 08:14:39.779386: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [384,906],float [1,975]; Tensor<type: int32 shape: [2] values: 384 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 08:14:39.954495: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-08-04 08:14:39.958920: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 384 has warmuped; cost us: 179668
2022-08-04 08:14:39.958938: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 512
2022-08-04 08:14:39.959066: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [512,906],float [1,975]; Tensor<type: int32 shape: [2] values: 512 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 08:14:40.134549: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-08-04 08:14:41.013064: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 512 has warmuped; cost us: 1054107
2022-08-04 08:14:41.013110: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 1024
2022-08-04 08:14:41.013278: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [1024,906],float [1,975]; Tensor<type: int32 shape: [2] values: 1024 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 08:14:41.185852: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-08-04 08:14:41.190751: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 1024 has warmuped; cost us: 177627
2022-08-04 08:14:41.202275: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1816] Running auto_mixed_precision graph optimizer
2022-08-04 08:14:41.202485: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1268] No whitelist ops found, nothing to do
2022-08-04 08:14:41.205712: I tensorflow/core/kernels/blaze_xla_kernel.cc:80] blaze set thread pool size 2
2022-08-04 08:14:41.205923: I tensorflow/core/kernels/blaze_xla_kernel.cc:80] blaze set thread pool size 2
2022-08-04 08:14:41.205931: I tensorflow/core/kernels/blaze_xla_kernel.cc:88] blaze max waiting count 10
2022-08-04 08:14:41.206026: I tensorflow/core/kernels/blaze_xla_kernel.cc:155] Parse blaze options succ warmup_batchsize: 1
warmup_batchsize: 64
warmup_batchsize: 128
warmup_batchsize: 256
warmup_batchsize: 384
warmup_batchsize: 512
warmup_batchsize: 1024
xla_compilation: true
gemm_optimization: true
auto_mixed_precision: true
no_warmup_inputs: "att_ncomm2"
config_proto {
  graph_options {
    rewrite_options {
      auto_mixed_precision: OFF
      gemm_optimization: ON
    }
  }
  force_run_in_caller_thread: true
  enable_graph_opt_place: true
}
wait_ms: 20

[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:317] Error parsing text-format tensorflow.GraphDef: 2:1: Expected identifier, got: 6
2022-08-04 08:14:41.281909: I tensorflow/core/kernels/blaze_xla_kernel.cc:100] Blaze create with options warmup_batchsize: 1
warmup_batchsize: 64
warmup_batchsize: 128
warmup_batchsize: 256
warmup_batchsize: 384
warmup_batchsize: 512
warmup_batchsize: 1024
xla_compilation: true
gemm_optimization: true
auto_mixed_precision: true
no_warmup_inputs: "att_ncomm2"
config_proto {
  gpu_options {
    allow_growth: true
  }
  allow_soft_placement: true
  graph_options {
    rewrite_options {
      auto_mixed_precision: OFF
      gemm_optimization: ON
    }
  }
  force_run_in_caller_thread: true
  enable_graph_opt_place: true
}
wait_ms: 20

2022-08-04 08:14:41.284359: I tensorflow/core/kernels/blaze_predictor.cc:110] create session with config gpu_options {
  allow_growth: true
  visible_device_list: "0"
  experimental {
    virtual_devices {
      memory_limit_mb: 12288
      memory_limit_mb: 12288
      memory_limit_mb: 12288
      memory_limit_mb: 12288
    }
  }
}
allow_soft_placement: true
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    auto_mixed_precision: OFF
    gemm_optimization: ON
  }
}
enable_graph_opt_place: true
is_blaze: true

2022-08-04 08:14:41.287079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1642] Found device 0 with properties: 
name: NVIDIA A100-SXM4-80GB major: 8 minor: 0 memoryClockRate(GHz): 1.41
pciBusID: 0000:54:00.0
2022-08-04 08:14:41.287104: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-08-04 08:14:41.287112: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-08-04 08:14:41.287119: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-08-04 08:14:41.287138: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-08-04 08:14:41.287149: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2022-08-04 08:14:41.287159: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-08-04 08:14:41.287169: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-08-04 08:14:41.291615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1770] Adding visible gpu devices: 0
2022-08-04 08:14:41.291648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-08-04 08:14:41.291653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2022-08-04 08:14:41.291657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2022-08-04 08:14:41.302717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 08:14:41.304968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 08:14:41.307195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 08:14:41.309421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 08:14:41.309479: I tensorflow/core/kernels/blaze_predictor.cc:119] Blaze start with step id 1024
2022-08-04 08:14:41.309484: I tensorflow/core/kernels/blaze_predictor.cc:120] Creat session succ 0x559f171917d0
2022-08-04 08:14:41.309492: I tensorflow/core/kernels/blaze_predictor.cc:73] BlazePredictor will use device /job:localhost/replica:0/task:0/device:GPU:2
2022-08-04 08:14:41.315449: I tensorflow/core/common_runtime/placer.cc:128] Allow optimize placer
2022-08-04 08:14:41.315751: I tensorflow/core/kernels/blaze_predictor.cc:92] create session with callable options feed: "ncomm"
feed: "comm"
fetch: "Softmax"
feed_devices {
  key: "comm"
  value: "/job:localhost/replica:0/task:0/device:GPU:2"
}
feed_devices {
  key: "ncomm"
  value: "/job:localhost/replica:0/task:0/device:GPU:2"
}
fetch_devices {
  key: "Softmax"
  value: "/job:localhost/replica:0/task:0/device:GPU:2"
}
fetch_skip_sync: true

2022-08-04 08:14:41.399429: I tensorflow/compiler/jit/build_xla_ops_pass.cc:398] enable_xla_auto_padding=0
2022-08-04 08:14:41.399472: I tensorflow/compiler/jit/build_xla_ops_pass.cc:404] auto_padding_shape 
2022-08-04 08:14:41.399934: I tensorflow/core/kernels/blaze_predictor.cc:132] MakeCallable succ 0x559f171917d0
2022-08-04 08:14:41.399950: I tensorflow/core/kernels/blaze_predictor.cc:205] req_dev: /device:CPU:0; blaze_dev: /device:GPU:2
2022-08-04 08:14:41.400279: I tensorflow/core/kernels/blaze_xla_predictor.cc:367] Begin warmup
2022-08-04 08:14:41.401368: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 1
2022-08-04 08:14:41.401565: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [1,906],float [1,975]; Tensor<type: int32 shape: [2] values: 1 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 08:14:41.919228: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 1 has warmuped; cost us: 517835
2022-08-04 08:14:41.919265: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 64
2022-08-04 08:14:41.919404: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [64,906],float [1,975]; Tensor<type: int32 shape: [2] values: 64 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 08:14:42.099869: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-08-04 08:14:42.632346: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 64 has warmuped; cost us: 713036
2022-08-04 08:14:42.632406: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 128
2022-08-04 08:14:42.632692: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [128,906],float [1,975]; Tensor<type: int32 shape: [2] values: 128 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 08:14:42.814619: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-08-04 08:14:42.817921: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 128 has warmuped; cost us: 185504
2022-08-04 08:14:42.817942: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 256
2022-08-04 08:14:42.818073: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [256,906],float [1,975]; Tensor<type: int32 shape: [2] values: 256 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 08:14:42.989999: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-08-04 08:14:42.993290: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 256 has warmuped; cost us: 175342
2022-08-04 08:14:42.993301: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 384
2022-08-04 08:14:42.993414: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [384,906],float [1,975]; Tensor<type: int32 shape: [2] values: 384 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 08:14:43.165977: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-08-04 08:14:43.169245: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 384 has warmuped; cost us: 175938
2022-08-04 08:14:43.169258: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 512
2022-08-04 08:14:43.169380: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [512,906],float [1,975]; Tensor<type: int32 shape: [2] values: 512 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 08:14:43.341432: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-08-04 08:14:43.344619: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 512 has warmuped; cost us: 175351
2022-08-04 08:14:43.344640: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 1024
2022-08-04 08:14:43.344768: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [1024,906],float [1,975]; Tensor<type: int32 shape: [2] values: 1024 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 08:14:43.519163: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-08-04 08:14:43.523073: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 1024 has warmuped; cost us: 178424
2022-08-04 08:14:43.527677: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1816] Running auto_mixed_precision graph optimizer
2022-08-04 08:14:43.527881: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1268] No whitelist ops found, nothing to do
2022-08-04 08:14:43.533157: I tensorflow/core/kernels/blaze_xla_kernel.cc:80] blaze set thread pool size 2
2022-08-04 08:14:43.533438: I tensorflow/core/kernels/blaze_xla_kernel.cc:80] blaze set thread pool size 2
2022-08-04 08:14:43.533446: I tensorflow/core/kernels/blaze_xla_kernel.cc:88] blaze max waiting count 10
2022-08-04 08:14:43.533561: I tensorflow/core/kernels/blaze_xla_kernel.cc:155] Parse blaze options succ warmup_batchsize: 1
warmup_batchsize: 64
warmup_batchsize: 128
warmup_batchsize: 256
warmup_batchsize: 384
warmup_batchsize: 512
warmup_batchsize: 1024
xla_compilation: true
gemm_optimization: true
auto_mixed_precision: true
no_warmup_inputs: "att_ncomm2"
config_proto {
  graph_options {
    rewrite_options {
      auto_mixed_precision: OFF
      gemm_optimization: ON
    }
  }
  force_run_in_caller_thread: true
  enable_graph_opt_place: true
}
wait_ms: 20

[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:317] Error parsing text-format tensorflow.GraphDef: 2:1: Expected identifier, got: 6
2022-08-04 08:14:43.616588: I tensorflow/core/kernels/blaze_xla_kernel.cc:100] Blaze create with options warmup_batchsize: 1
warmup_batchsize: 64
warmup_batchsize: 128
warmup_batchsize: 256
warmup_batchsize: 384
warmup_batchsize: 512
warmup_batchsize: 1024
xla_compilation: true
gemm_optimization: true
auto_mixed_precision: true
no_warmup_inputs: "att_ncomm2"
config_proto {
  gpu_options {
    allow_growth: true
  }
  allow_soft_placement: true
  graph_options {
    rewrite_options {
      auto_mixed_precision: OFF
      gemm_optimization: ON
    }
  }
  force_run_in_caller_thread: true
  enable_graph_opt_place: true
}
wait_ms: 20

2022-08-04 08:14:43.619319: I tensorflow/core/kernels/blaze_predictor.cc:110] create session with config gpu_options {
  allow_growth: true
  visible_device_list: "0"
  experimental {
    virtual_devices {
      memory_limit_mb: 12288
      memory_limit_mb: 12288
      memory_limit_mb: 12288
      memory_limit_mb: 12288
    }
  }
}
allow_soft_placement: true
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    auto_mixed_precision: OFF
    gemm_optimization: ON
  }
}
enable_graph_opt_place: true
is_blaze: true

2022-08-04 08:14:43.640651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1642] Found device 0 with properties: 
name: NVIDIA A100-SXM4-80GB major: 8 minor: 0 memoryClockRate(GHz): 1.41
pciBusID: 0000:54:00.0
2022-08-04 08:14:43.640688: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-08-04 08:14:43.640704: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-08-04 08:14:43.640711: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-08-04 08:14:43.640717: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-08-04 08:14:43.640723: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2022-08-04 08:14:43.640729: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-08-04 08:14:43.640733: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-08-04 08:14:43.647095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1770] Adding visible gpu devices: 0
2022-08-04 08:14:43.647140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-08-04 08:14:43.647145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2022-08-04 08:14:43.647149: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2022-08-04 08:14:43.662971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 08:14:43.666088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 08:14:43.669197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 08:14:43.672338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 08:14:43.672388: I tensorflow/core/kernels/blaze_predictor.cc:119] Blaze start with step id 1024
2022-08-04 08:14:43.672394: I tensorflow/core/kernels/blaze_predictor.cc:120] Creat session succ 0x559f19650da0
2022-08-04 08:14:43.672401: I tensorflow/core/kernels/blaze_predictor.cc:73] BlazePredictor will use device /job:localhost/replica:0/task:0/device:GPU:3
2022-08-04 08:14:43.681451: I tensorflow/core/common_runtime/placer.cc:128] Allow optimize placer
2022-08-04 08:14:43.681743: I tensorflow/core/kernels/blaze_predictor.cc:92] create session with callable options feed: "ncomm"
feed: "comm"
fetch: "Softmax"
feed_devices {
  key: "comm"
  value: "/job:localhost/replica:0/task:0/device:GPU:3"
}
feed_devices {
  key: "ncomm"
  value: "/job:localhost/replica:0/task:0/device:GPU:3"
}
fetch_devices {
  key: "Softmax"
  value: "/job:localhost/replica:0/task:0/device:GPU:3"
}
fetch_skip_sync: true

2022-08-04 08:14:43.770773: I tensorflow/compiler/jit/build_xla_ops_pass.cc:398] enable_xla_auto_padding=0
2022-08-04 08:14:43.770812: I tensorflow/compiler/jit/build_xla_ops_pass.cc:404] auto_padding_shape 
2022-08-04 08:14:43.771292: I tensorflow/core/kernels/blaze_predictor.cc:132] MakeCallable succ 0x559f19650da0
2022-08-04 08:14:43.771309: I tensorflow/core/kernels/blaze_predictor.cc:205] req_dev: /device:CPU:0; blaze_dev: /device:GPU:3
2022-08-04 08:14:43.772896: I tensorflow/core/kernels/blaze_xla_predictor.cc:367] Begin warmup
2022-08-04 08:14:43.774013: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 1
2022-08-04 08:14:43.774189: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [1,906],float [1,975]; Tensor<type: int32 shape: [2] values: 1 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 08:14:44.308843: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 1 has warmuped; cost us: 534807
2022-08-04 08:14:44.308877: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 64
2022-08-04 08:14:44.309119: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [64,906],float [1,975]; Tensor<type: int32 shape: [2] values: 64 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 08:14:44.493370: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-08-04 08:14:45.057020: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 64 has warmuped; cost us: 748124
2022-08-04 08:14:45.057057: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 128
2022-08-04 08:14:45.057229: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [128,906],float [1,975]; Tensor<type: int32 shape: [2] values: 128 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 08:14:45.237890: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-08-04 08:14:45.241772: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 128 has warmuped; cost us: 184704
2022-08-04 08:14:45.241791: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 256
2022-08-04 08:14:45.241926: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [256,906],float [1,975]; Tensor<type: int32 shape: [2] values: 256 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 08:14:45.411939: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-08-04 08:14:45.415088: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 256 has warmuped; cost us: 173289
2022-08-04 08:14:45.415101: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 384
2022-08-04 08:14:45.415220: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [384,906],float [1,975]; Tensor<type: int32 shape: [2] values: 384 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 08:14:45.589608: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-08-04 08:14:45.596199: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 384 has warmuped; cost us: 181088
2022-08-04 08:14:45.596218: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 512
2022-08-04 08:14:45.596357: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [512,906],float [1,975]; Tensor<type: int32 shape: [2] values: 512 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 08:14:45.766732: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-08-04 08:14:45.769896: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 512 has warmuped; cost us: 173669
2022-08-04 08:14:45.769916: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 1024
2022-08-04 08:14:45.770033: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [1024,906],float [1,975]; Tensor<type: int32 shape: [2] values: 1024 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 08:14:45.945596: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-08-04 08:14:45.949246: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 1024 has warmuped; cost us: 179322
2022-08-04 08:14:45.949900: I /home/yunlong.xyl/blaze-benchmark/benchmark/core/model.cc:435] Init and warmup model complete: ad_rtp_wt_ctr_wt_union_v1_turing
2022-Aug-04 08:14:48.950540 ====================================================
-- Histograms ------------------------------------------------------------------
ad_rtp_wt_ctr_wt_union_v1_turing_batchsize
             count = 21443
               min = 448
               max = 448
              mean = 448.00
            stddev = 0.00
            median = 448.00
              75% <= 448.00
              95% <= 448.00
              98% <= 448.00
              99% <= 448.00
            99.9% <= 448.00
ad_rtp_wt_ctr_wt_union_v1_turing_latency
             count = 21447
               min = 390
               max = 1061
              mean = 557.83
            stddev = 47.72
            median = 555.00
              75% <= 583.00
              95% <= 634.00
              98% <= 662.00
              99% <= 675.75
            99.9% <= 1055.85

-- Meters ----------------------------------------------------------------------
ad_rtp_wt_ctr_wt_union_v1_turing_throughput
             count = 21447
         mean rate = 7160.61 events per 1 Seconds
     1-minute rate = 0.00 events per 1 Seconds
     5-minute rate = 0.00 events per 1 Seconds
    15-minute rate = 0.00 events per 1 Seconds


2022-Aug-04 08:14:51.950998 ====================================================
-- Histograms ------------------------------------------------------------------
ad_rtp_wt_ctr_wt_union_v1_turing_batchsize
             count = 43170
               min = 448
               max = 448
              mean = 448.00
            stddev = 0.00
            median = 448.00
              75% <= 448.00
              95% <= 448.00
              98% <= 448.00
              99% <= 448.00
            99.9% <= 448.00
ad_rtp_wt_ctr_wt_union_v1_turing_latency
             count = 43170
               min = 390
               max = 1061
              mean = 554.08
            stddev = 47.35
            median = 553.00
              75% <= 578.00
              95% <= 623.75
              98% <= 657.50
              99% <= 675.75
            99.9% <= 1055.85

-- Meters ----------------------------------------------------------------------
ad_rtp_wt_ctr_wt_union_v1_turing_throughput
             count = 43170
         mean rate = 7200.40 events per 1 Seconds
     1-minute rate = 7208.40 events per 1 Seconds
     5-minute rate = 7208.40 events per 1 Seconds
    15-minute rate = 7208.40 events per 1 Seconds


2022-Aug-04 08:14:54.951361 ====================================================
-- Histograms ------------------------------------------------------------------
ad_rtp_wt_ctr_wt_union_v1_turing_batchsize
             count = 64335
               min = 448
               max = 448
              mean = 448.00
            stddev = 0.00
            median = 448.00
              75% <= 448.00
              95% <= 448.00
              98% <= 448.00
              99% <= 448.00
            99.9% <= 448.00
ad_rtp_wt_ctr_wt_union_v1_turing_latency
             count = 64335
               min = 400
               max = 1061
              mean = 560.51
            stddev = 47.36
            median = 559.00
              75% <= 585.00
              95% <= 629.00
              98% <= 661.00
              99% <= 689.25
            99.9% <= 1055.85

-- Meters ----------------------------------------------------------------------
ad_rtp_wt_ctr_wt_union_v1_turing_throughput
             count = 64337
         mean rate = 7151.85 events per 1 Seconds
     1-minute rate = 7208.40 events per 1 Seconds
     5-minute rate = 7208.40 events per 1 Seconds
    15-minute rate = 7208.40 events per 1 Seconds


2022-Aug-04 08:14:57.951739 ====================================================
-- Histograms ------------------------------------------------------------------
ad_rtp_wt_ctr_wt_union_v1_turing_batchsize
             count = 85433
               min = 448
               max = 448
              mean = 448.00
            stddev = 0.00
            median = 448.00
              75% <= 448.00
              95% <= 448.00
              98% <= 448.00
              99% <= 448.00
            99.9% <= 448.00
ad_rtp_wt_ctr_wt_union_v1_turing_latency
             count = 85434
               min = 403
               max = 2131
              mean = 563.35
            stddev = 66.30
            median = 563.00
              75% <= 587.00
              95% <= 634.00
              98% <= 656.50
              99% <= 677.50
            99.9% <= 2099.10

-- Meters ----------------------------------------------------------------------
ad_rtp_wt_ctr_wt_union_v1_turing_throughput
             count = 85435
         mean rate = 7121.71 events per 1 Seconds
     1-minute rate = 7196.69 events per 1 Seconds
     5-minute rate = 7205.98 events per 1 Seconds
    15-minute rate = 7207.59 events per 1 Seconds


2022-Aug-04 08:15:00.952304 ====================================================
-- Histograms ------------------------------------------------------------------
ad_rtp_wt_ctr_wt_union_v1_turing_batchsize
             count = 106381
               min = 448
               max = 448
              mean = 448.00
            stddev = 0.00
            median = 448.00
              75% <= 448.00
              95% <= 448.00
              98% <= 448.00
              99% <= 448.00
            99.9% <= 448.00
ad_rtp_wt_ctr_wt_union_v1_turing_latency
             count = 106383
               min = 403
               max = 855
              mean = 562.25
            stddev = 44.09
            median = 563.00
              75% <= 588.00
              95% <= 633.75
              98% <= 655.50
              99% <= 670.00
            99.9% <= 853.53

-- Meters ----------------------------------------------------------------------
ad_rtp_wt_ctr_wt_union_v1_turing_throughput
             count = 106385
         mean rate = 7093.78 events per 1 Seconds
     1-minute rate = 7196.69 events per 1 Seconds
     5-minute rate = 7205.98 events per 1 Seconds
    15-minute rate = 7207.59 events per 1 Seconds


2022-Aug-04 08:15:03.952838 ====================================================
-- Histograms ------------------------------------------------------------------
ad_rtp_wt_ctr_wt_union_v1_turing_batchsize
             count = 127674
               min = 448
               max = 448
              mean = 448.00
            stddev = 0.00
            median = 448.00
              75% <= 448.00
              95% <= 448.00
              98% <= 448.00
              99% <= 448.00
            99.9% <= 448.00
ad_rtp_wt_ctr_wt_union_v1_turing_latency
             count = 127675
               min = 395
               max = 855
              mean = 561.77
            stddev = 44.61
            median = 563.00
              75% <= 588.00
              95% <= 633.00
              98% <= 656.00
              99% <= 670.00
            99.9% <= 853.53

-- Meters ----------------------------------------------------------------------
ad_rtp_wt_ctr_wt_union_v1_turing_throughput
             count = 127678
         mean rate = 7094.23 events per 1 Seconds
     1-minute rate = 7181.83 events per 1 Seconds
     5-minute rate = 7202.75 events per 1 Seconds
    15-minute rate = 7206.50 events per 1 Seconds


2022-Aug-04 08:15:06.953324 ====================================================
-- Histograms ------------------------------------------------------------------
ad_rtp_wt_ctr_wt_union_v1_turing_batchsize
             count = 148621
               min = 448
               max = 448
              mean = 448.00
            stddev = 0.00
            median = 448.00
              75% <= 448.00
              95% <= 448.00
              98% <= 448.00
              99% <= 448.00
            99.9% <= 448.00
ad_rtp_wt_ctr_wt_union_v1_turing_latency
             count = 148621
               min = 395
               max = 855
              mean = 563.91
            stddev = 44.47
            median = 566.00
              75% <= 589.00
              95% <= 633.00
              98% <= 655.00
              99% <= 676.00
            99.9% <= 853.53

-- Meters ----------------------------------------------------------------------
ad_rtp_wt_ctr_wt_union_v1_turing_throughput
             count = 148623
         mean rate = 7077.96 events per 1 Seconds
     1-minute rate = 7171.63 events per 1 Seconds
     5-minute rate = 7200.30 events per 1 Seconds
    15-minute rate = 7205.65 events per 1 Seconds


