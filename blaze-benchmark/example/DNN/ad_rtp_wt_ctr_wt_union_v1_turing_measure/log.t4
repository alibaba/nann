+ /usr/local/nvidia/bin/nvidia-cuda-mps-control -d
An instance of this daemon is already running
+ TF_XLA_PTX_CACHE_DIR=./xla_cache
+ TF_CPP_MIN_VLOG_LEVEL=0
+ BLAZE_USE_MPS=1
+ LD_LIBRARY_PATH=/usr/local/nvidia/lib64:/usr/local/cuda-11.2/lib64
+ ../../../build/benchmark/benchmark benchmark_conf
2022-07-20 05:35:10.033187: I /home/yunlong.xyl/projects/temp/blaze-benchmark/benchmark/core/model.cc:295] Inferred batchsize = 448, ad_rtp_wt_ctr_wt_union_v1_turing
2022-07-20 05:35:10.034844: I /home/yunlong.xyl/projects/temp/tensorflow/tensorflow/core/common_runtime/direct_session.h:441] Blaze will use globla_opts : device_count {
  key: "GPU"
  value: 1
}
gpu_options {
  allow_growth: true
  visible_device_list: "0"
  experimental {
    virtual_devices {
      memory_limit_mb: 12288
      memory_limit_mb: 12288
      memory_limit_mb: 12288
      memory_limit_mb: 12288
    }
  }
}
allow_soft_placement: true
graph_options {
  rewrite_options {
    layout_optimizer: OFF
    auto_mixed_precision: ON
  }
}
blaze_options {
  warmup_batchsize: 1
  warmup_batchsize: 64
  warmup_batchsize: 128
  warmup_batchsize: 256
  warmup_batchsize: 384
  warmup_batchsize: 512
  warmup_batchsize: 1024
  xla_compilation: true
  gemm_optimization: true
  auto_mixed_precision: true
  no_warmup_inputs: "att_ncomm2"
  config_proto {
    graph_options {
      rewrite_options {
        auto_mixed_precision: ON
        gemm_optimization: ON
      }
    }
    force_run_in_caller_thread: true
    enable_graph_opt_place: true
  }
  wait_ms: 20
}

2022-07-20 05:35:10.035090: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-07-20 05:35:10.044392: I /home/yunlong.xyl/projects/temp/blaze-benchmark/benchmark/core/model.cc:162] GetDeviceCount: cpu_count =  1, gpu_count = 4
2022-07-20 05:35:10.044487: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F FMA
2022-07-20 05:35:10.067287: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-07-20 05:35:10.067321: I tensorflow/stream_executor/executor_cache.cc:41] TF_NUM_CONTEXTS_PER_GPU = 4
2022-07-20 05:35:10.067340: I tensorflow/stream_executor/executor_cache.cc:62] TF_NUM_CONTEXTS_PER_GPU = 4
2022-07-20 05:35:10.067548: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2499445000 Hz
2022-07-20 05:35:10.073137: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f5982846640 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-07-20 05:35:10.073161: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-07-20 05:35:10.074671: I tensorflow/stream_executor/executor_cache.cc:62] TF_NUM_CONTEXTS_PER_GPU = 4
2022-07-20 05:35:10.180175: I tensorflow/stream_executor/cuda/cuda_driver.cc:454] cuDevicePrimaryCtxRetain context 0x7f5982a28450
2022-07-20 05:35:10.181176: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f5982845d50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-07-20 05:35:10.181205: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
2022-07-20 05:35:10.181972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1642] Found device 0 with properties: 
name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
pciBusID: 0000:5e:00.0
2022-07-20 05:35:10.181998: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-07-20 05:35:10.185873: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-07-20 05:35:10.187142: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-07-20 05:35:10.187406: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-07-20 05:35:10.188470: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2022-07-20 05:35:10.189376: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-07-20 05:35:10.193855: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-07-20 05:35:10.195064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1770] Adding visible gpu devices: 0
2022-07-20 05:35:10.195137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-07-20 05:35:10.195145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2022-07-20 05:35:10.195153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2022-07-20 05:35:10.198042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12288 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5)
2022-07-20 05:35:10.199038: I tensorflow/stream_executor/executor_cache.cc:62] TF_NUM_CONTEXTS_PER_GPU = 4
2022-07-20 05:35:10.298546: I tensorflow/stream_executor/cuda/cuda_driver.cc:458] Primary context has been used, cuCtxCreate context 0x7f5983698ef0
2022-07-20 05:35:10.298605: W tensorflow/stream_executor/cuda/cuda_driver.cc:472] A non-primary context 0x7f5982a28450 for device 0 exists before initializing the StreamExecutor. The primary context is now 0x7f5983698ef0. We haven't verified StreamExecutor works with that.
2022-07-20 05:35:10.299344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 12288 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5)
2022-07-20 05:35:10.300243: I tensorflow/stream_executor/executor_cache.cc:62] TF_NUM_CONTEXTS_PER_GPU = 4
2022-07-20 05:35:10.394508: I tensorflow/stream_executor/cuda/cuda_driver.cc:458] Primary context has been used, cuCtxCreate context 0x7f5983cbb640
2022-07-20 05:35:10.394553: W tensorflow/stream_executor/cuda/cuda_driver.cc:472] A non-primary context 0x7f5983698ef0 for device 0 exists before initializing the StreamExecutor. The primary context is now 0x7f5983cbb640. We haven't verified StreamExecutor works with that.
2022-07-20 05:35:10.395289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 12288 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5)
2022-07-20 05:35:10.396169: I tensorflow/stream_executor/executor_cache.cc:62] TF_NUM_CONTEXTS_PER_GPU = 4
2022-07-20 05:35:10.492896: I tensorflow/stream_executor/cuda/cuda_driver.cc:458] Primary context has been used, cuCtxCreate context 0x7f59842e92e0
2022-07-20 05:35:10.492937: W tensorflow/stream_executor/cuda/cuda_driver.cc:472] A non-primary context 0x7f5983cbb640 for device 0 exists before initializing the StreamExecutor. The primary context is now 0x7f59842e92e0. We haven't verified StreamExecutor works with that.
2022-07-20 05:35:10.493668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 12288 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5)
2022-07-20 05:35:10.499143: I tensorflow/core/common_runtime/placer.cc:130] Not allow optimize placer
2022-07-20 05:35:10.499222: I /home/yunlong.xyl/projects/temp/blaze-benchmark/benchmark/core/model.cc:206] Predictor 0 uses session ad_rtp_wt_ctr_wt_union_v1_turing/CPU:0/GPU:0
2022-07-20 05:35:10.500117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1642] Found device 0 with properties: 
name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
pciBusID: 0000:5e:00.0
2022-07-20 05:35:10.500148: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-07-20 05:35:10.500156: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-07-20 05:35:10.500163: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-07-20 05:35:10.500169: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-07-20 05:35:10.500175: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2022-07-20 05:35:10.500181: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-07-20 05:35:10.500187: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-07-20 05:35:10.501296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1770] Adding visible gpu devices: 0
2022-07-20 05:35:10.501328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-07-20 05:35:10.501334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2022-07-20 05:35:10.501339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2022-07-20 05:35:10.504096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12288 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5)
2022-07-20 05:35:10.504669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 12288 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5)
2022-07-20 05:35:10.505244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 12288 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5)
2022-07-20 05:35:10.505817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 12288 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5)
2022-07-20 05:35:10.506068: I tensorflow/core/common_runtime/placer.cc:130] Not allow optimize placer
2022-07-20 05:35:10.506119: I /home/yunlong.xyl/projects/temp/blaze-benchmark/benchmark/core/model.cc:206] Predictor 1 uses session ad_rtp_wt_ctr_wt_union_v1_turing/CPU:0/GPU:1
2022-07-20 05:35:10.506967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1642] Found device 0 with properties: 
name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
pciBusID: 0000:5e:00.0
2022-07-20 05:35:10.506988: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-07-20 05:35:10.506995: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-07-20 05:35:10.507001: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-07-20 05:35:10.507007: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-07-20 05:35:10.507013: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2022-07-20 05:35:10.507018: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-07-20 05:35:10.507024: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-07-20 05:35:10.508125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1770] Adding visible gpu devices: 0
2022-07-20 05:35:10.508145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-07-20 05:35:10.508151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2022-07-20 05:35:10.508155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2022-07-20 05:35:10.510942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12288 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5)
2022-07-20 05:35:10.511514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 12288 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5)
2022-07-20 05:35:10.512086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 12288 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5)
2022-07-20 05:35:10.512654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 12288 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5)
2022-07-20 05:35:10.512865: I tensorflow/core/common_runtime/placer.cc:130] Not allow optimize placer
2022-07-20 05:35:10.512915: I /home/yunlong.xyl/projects/temp/blaze-benchmark/benchmark/core/model.cc:206] Predictor 2 uses session ad_rtp_wt_ctr_wt_union_v1_turing/CPU:0/GPU:2
2022-07-20 05:35:10.513930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1642] Found device 0 with properties: 
name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
pciBusID: 0000:5e:00.0
2022-07-20 05:35:10.513952: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-07-20 05:35:10.513959: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-07-20 05:35:10.513964: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-07-20 05:35:10.513970: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-07-20 05:35:10.513975: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2022-07-20 05:35:10.513981: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-07-20 05:35:10.513987: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-07-20 05:35:10.515092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1770] Adding visible gpu devices: 0
2022-07-20 05:35:10.515112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-07-20 05:35:10.515117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2022-07-20 05:35:10.515122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2022-07-20 05:35:10.517924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12288 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5)
2022-07-20 05:35:10.518496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 12288 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5)
2022-07-20 05:35:10.519068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 12288 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5)
2022-07-20 05:35:10.519635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 12288 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5)
2022-07-20 05:35:10.519843: I tensorflow/core/common_runtime/placer.cc:130] Not allow optimize placer
2022-07-20 05:35:10.519892: I /home/yunlong.xyl/projects/temp/blaze-benchmark/benchmark/core/model.cc:206] Predictor 3 uses session ad_rtp_wt_ctr_wt_union_v1_turing/CPU:0/GPU:3
2022-07-20 05:35:10.523593: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1816] Running auto_mixed_precision graph optimizer
2022-07-20 05:35:10.523870: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1268] No whitelist ops found, nothing to do
2022-07-20 05:35:10.528676: I tensorflow/core/kernels/blaze_xla_kernel.cc:80] blaze set thread pool size 2
2022-07-20 05:35:10.528911: I tensorflow/core/kernels/blaze_xla_kernel.cc:80] blaze set thread pool size 2
2022-07-20 05:35:10.528922: I tensorflow/core/kernels/blaze_xla_kernel.cc:88] blaze max waiting count 10
2022-07-20 05:35:10.529034: I tensorflow/core/kernels/blaze_xla_kernel.cc:155] Parse blaze options succ warmup_batchsize: 1
warmup_batchsize: 64
warmup_batchsize: 128
warmup_batchsize: 256
warmup_batchsize: 384
warmup_batchsize: 512
warmup_batchsize: 1024
xla_compilation: true
gemm_optimization: true
auto_mixed_precision: true
no_warmup_inputs: "att_ncomm2"
config_proto {
  graph_options {
    rewrite_options {
      auto_mixed_precision: ON
      gemm_optimization: ON
    }
  }
  force_run_in_caller_thread: true
  enable_graph_opt_place: true
}
wait_ms: 20

[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:317] Error parsing text-format tensorflow.GraphDef: 2:1: Expected identifier, got: 6
2022-07-20 05:35:10.649845: I tensorflow/core/kernels/blaze_xla_kernel.cc:100] Blaze create with options warmup_batchsize: 1
warmup_batchsize: 64
warmup_batchsize: 128
warmup_batchsize: 256
warmup_batchsize: 384
warmup_batchsize: 512
warmup_batchsize: 1024
xla_compilation: true
gemm_optimization: true
auto_mixed_precision: true
no_warmup_inputs: "att_ncomm2"
config_proto {
  gpu_options {
    allow_growth: true
  }
  allow_soft_placement: true
  graph_options {
    rewrite_options {
      auto_mixed_precision: ON
      gemm_optimization: ON
    }
  }
  force_run_in_caller_thread: true
  enable_graph_opt_place: true
}
wait_ms: 20

2022-07-20 05:35:10.656519: I tensorflow/core/kernels/blaze_predictor.cc:110] create session with config gpu_options {
  allow_growth: true
  visible_device_list: "0"
  experimental {
    virtual_devices {
      memory_limit_mb: 12288
      memory_limit_mb: 12288
      memory_limit_mb: 12288
      memory_limit_mb: 12288
    }
  }
}
allow_soft_placement: true
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    auto_mixed_precision: ON
    gemm_optimization: ON
  }
}
enable_graph_opt_place: true
is_blaze: true

2022-07-20 05:35:10.657625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1642] Found device 0 with properties: 
name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
pciBusID: 0000:5e:00.0
2022-07-20 05:35:10.657660: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-07-20 05:35:10.657668: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-07-20 05:35:10.657675: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-07-20 05:35:10.657681: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-07-20 05:35:10.657687: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2022-07-20 05:35:10.657694: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-07-20 05:35:10.657700: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-07-20 05:35:10.658837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1770] Adding visible gpu devices: 0
2022-07-20 05:35:10.658871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-07-20 05:35:10.658879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2022-07-20 05:35:10.658884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2022-07-20 05:35:10.661647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12288 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5)
2022-07-20 05:35:10.662234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 12288 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5)
2022-07-20 05:35:10.662817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 12288 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5)
2022-07-20 05:35:10.663399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 12288 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5)
2022-07-20 05:35:10.663463: I tensorflow/core/kernels/blaze_predictor.cc:119] Blaze start with step id 1024
2022-07-20 05:35:10.663472: I tensorflow/core/kernels/blaze_predictor.cc:120] Creat session succ 0x7f5984b76ee0
2022-07-20 05:35:10.663484: I tensorflow/core/kernels/blaze_predictor.cc:73] BlazePredictor will use device /job:localhost/replica:0/task:0/device:GPU:0
2022-07-20 05:35:10.677754: I tensorflow/core/common_runtime/placer.cc:128] Allow optimize placer
2022-07-20 05:35:10.678254: I tensorflow/core/kernels/blaze_predictor.cc:92] create session with callable options feed: "ncomm"
feed: "comm"
fetch: "Softmax"
feed_devices {
  key: "comm"
  value: "/job:localhost/replica:0/task:0/device:GPU:0"
}
feed_devices {
  key: "ncomm"
  value: "/job:localhost/replica:0/task:0/device:GPU:0"
}
fetch_devices {
  key: "Softmax"
  value: "/job:localhost/replica:0/task:0/device:GPU:0"
}
fetch_skip_sync: true

2022-07-20 05:35:10.749157: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1816] Running auto_mixed_precision graph optimizer
2022-07-20 05:35:10.750875: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1772] Converted 53/91 nodes to float16 precision using 2 cast(s) to float16 (excluding Const and Variable casts)
2022-07-20 05:35:10.842838: I tensorflow/compiler/jit/build_xla_ops_pass.cc:398] enable_xla_auto_padding=0
2022-07-20 05:35:10.842888: I tensorflow/compiler/jit/build_xla_ops_pass.cc:404] auto_padding_shape 
2022-07-20 05:35:10.845291: I tensorflow/core/kernels/blaze_predictor.cc:132] MakeCallable succ 0x7f5984b76ee0
2022-07-20 05:35:10.845322: I tensorflow/core/kernels/blaze_predictor.cc:205] req_dev: /device:CPU:0; blaze_dev: /device:GPU:0
2022-07-20 05:35:10.847329: I tensorflow/core/kernels/blaze_xla_predictor.cc:367] Begin warmup
2022-07-20 05:35:10.848248: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 1
2022-07-20 05:35:10.848970: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [1,906],float [1,975]; Tensor<type: int32 shape: [2] values: 1 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-07-20 05:35:11.081065: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:268] Cache XLA PTXs in ./xla_cache. This line is logged at most once for the lifetime of the process.
2022-07-20 05:35:11.081097: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:285] Will not cache XLA CUBINs. This line is logged at most once for the lifetime of the process.
2022-07-20 05:35:11.675757: I tensorflow/compiler/jit/xla_compilation_cache.cc:292] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-07-20 05:35:11.678889: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 1 has warmuped; cost us: 830602
2022-07-20 05:35:11.678920: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 64
2022-07-20 05:35:11.679155: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [64,906],float [1,975]; Tensor<type: int32 shape: [2] values: 64 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-07-20 05:35:12.143996: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-07-20 05:35:12.725266: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-07-20 05:35:12.726777: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 64 has warmuped; cost us: 1047841
2022-07-20 05:35:12.726812: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 128
2022-07-20 05:35:12.727052: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [128,906],float [1,975]; Tensor<type: int32 shape: [2] values: 128 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-07-20 05:35:13.205796: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 128 has warmuped; cost us: 478970
2022-07-20 05:35:13.205844: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 256
2022-07-20 05:35:13.206083: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [256,906],float [1,975]; Tensor<type: int32 shape: [2] values: 256 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-07-20 05:35:13.683651: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 256 has warmuped; cost us: 477790
2022-07-20 05:35:13.683707: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 384
2022-07-20 05:35:13.683895: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [384,906],float [1,975]; Tensor<type: int32 shape: [2] values: 384 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-07-20 05:35:14.157814: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 384 has warmuped; cost us: 474088
2022-07-20 05:35:14.157848: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 512
2022-07-20 05:35:14.158090: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [512,906],float [1,975]; Tensor<type: int32 shape: [2] values: 512 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-07-20 05:35:14.636356: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 512 has warmuped; cost us: 478495
2022-07-20 05:35:14.636406: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 1024
2022-07-20 05:35:14.636627: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [1024,906],float [1,975]; Tensor<type: int32 shape: [2] values: 1024 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-07-20 05:35:15.111765: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 1024 has warmuped; cost us: 475342
2022-07-20 05:35:15.114722: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1816] Running auto_mixed_precision graph optimizer
2022-07-20 05:35:15.114988: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1268] No whitelist ops found, nothing to do
2022-07-20 05:35:15.119778: I tensorflow/core/kernels/blaze_xla_kernel.cc:80] blaze set thread pool size 2
2022-07-20 05:35:15.120053: I tensorflow/core/kernels/blaze_xla_kernel.cc:80] blaze set thread pool size 2
2022-07-20 05:35:15.120064: I tensorflow/core/kernels/blaze_xla_kernel.cc:88] blaze max waiting count 10
2022-07-20 05:35:15.120177: I tensorflow/core/kernels/blaze_xla_kernel.cc:155] Parse blaze options succ warmup_batchsize: 1
warmup_batchsize: 64
warmup_batchsize: 128
warmup_batchsize: 256
warmup_batchsize: 384
warmup_batchsize: 512
warmup_batchsize: 1024
xla_compilation: true
gemm_optimization: true
auto_mixed_precision: true
no_warmup_inputs: "att_ncomm2"
config_proto {
  graph_options {
    rewrite_options {
      auto_mixed_precision: ON
      gemm_optimization: ON
    }
  }
  force_run_in_caller_thread: true
  enable_graph_opt_place: true
}
wait_ms: 20

[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:317] Error parsing text-format tensorflow.GraphDef: 2:1: Expected identifier, got: 6
2022-07-20 05:35:15.237895: I tensorflow/core/kernels/blaze_xla_kernel.cc:100] Blaze create with options warmup_batchsize: 1
warmup_batchsize: 64
warmup_batchsize: 128
warmup_batchsize: 256
warmup_batchsize: 384
warmup_batchsize: 512
warmup_batchsize: 1024
xla_compilation: true
gemm_optimization: true
auto_mixed_precision: true
no_warmup_inputs: "att_ncomm2"
config_proto {
  gpu_options {
    allow_growth: true
  }
  allow_soft_placement: true
  graph_options {
    rewrite_options {
      auto_mixed_precision: ON
      gemm_optimization: ON
    }
  }
  force_run_in_caller_thread: true
  enable_graph_opt_place: true
}
wait_ms: 20

2022-07-20 05:35:15.243033: I tensorflow/core/kernels/blaze_predictor.cc:110] create session with config gpu_options {
  allow_growth: true
  visible_device_list: "0"
  experimental {
    virtual_devices {
      memory_limit_mb: 12288
      memory_limit_mb: 12288
      memory_limit_mb: 12288
      memory_limit_mb: 12288
    }
  }
}
allow_soft_placement: true
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    auto_mixed_precision: ON
    gemm_optimization: ON
  }
}
enable_graph_opt_place: true
is_blaze: true

2022-07-20 05:35:15.244134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1642] Found device 0 with properties: 
name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
pciBusID: 0000:5e:00.0
2022-07-20 05:35:15.244167: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-07-20 05:35:15.244177: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-07-20 05:35:15.244185: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-07-20 05:35:15.244192: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-07-20 05:35:15.244199: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2022-07-20 05:35:15.244207: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-07-20 05:35:15.244214: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-07-20 05:35:15.245307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1770] Adding visible gpu devices: 0
2022-07-20 05:35:15.245343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-07-20 05:35:15.245351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2022-07-20 05:35:15.245357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2022-07-20 05:35:15.248073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12288 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5)
2022-07-20 05:35:15.248647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 12288 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5)
2022-07-20 05:35:15.249214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 12288 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5)
2022-07-20 05:35:15.249792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 12288 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5)
2022-07-20 05:35:15.249857: I tensorflow/core/kernels/blaze_predictor.cc:119] Blaze start with step id 1024
2022-07-20 05:35:15.249866: I tensorflow/core/kernels/blaze_predictor.cc:120] Creat session succ 0x7f5988e7b070
2022-07-20 05:35:15.249875: I tensorflow/core/kernels/blaze_predictor.cc:73] BlazePredictor will use device /job:localhost/replica:0/task:0/device:GPU:1
2022-07-20 05:35:15.260161: I tensorflow/core/common_runtime/placer.cc:128] Allow optimize placer
2022-07-20 05:35:15.260646: I tensorflow/core/kernels/blaze_predictor.cc:92] create session with callable options feed: "ncomm"
feed: "comm"
fetch: "Softmax"
feed_devices {
  key: "comm"
  value: "/job:localhost/replica:0/task:0/device:GPU:1"
}
feed_devices {
  key: "ncomm"
  value: "/job:localhost/replica:0/task:0/device:GPU:1"
}
fetch_devices {
  key: "Softmax"
  value: "/job:localhost/replica:0/task:0/device:GPU:1"
}
fetch_skip_sync: true

2022-07-20 05:35:15.314379: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1816] Running auto_mixed_precision graph optimizer
2022-07-20 05:35:15.316003: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1772] Converted 53/91 nodes to float16 precision using 2 cast(s) to float16 (excluding Const and Variable casts)
2022-07-20 05:35:15.399491: I tensorflow/compiler/jit/build_xla_ops_pass.cc:398] enable_xla_auto_padding=0
2022-07-20 05:35:15.399534: I tensorflow/compiler/jit/build_xla_ops_pass.cc:404] auto_padding_shape 
2022-07-20 05:35:15.400224: I tensorflow/core/kernels/blaze_predictor.cc:132] MakeCallable succ 0x7f5988e7b070
2022-07-20 05:35:15.400248: I tensorflow/core/kernels/blaze_predictor.cc:205] req_dev: /device:CPU:0; blaze_dev: /device:GPU:1
2022-07-20 05:35:15.400682: I tensorflow/core/kernels/blaze_xla_predictor.cc:367] Begin warmup
2022-07-20 05:35:15.401614: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 1
2022-07-20 05:35:15.401842: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [1,906],float [1,975]; Tensor<type: int32 shape: [2] values: 1 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-07-20 05:35:16.219059: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 1 has warmuped; cost us: 817407
2022-07-20 05:35:16.219121: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 64
2022-07-20 05:35:16.219400: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [64,906],float [1,975]; Tensor<type: int32 shape: [2] values: 64 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-07-20 05:35:16.502654: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-07-20 05:35:16.930442: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 64 has warmuped; cost us: 711303
2022-07-20 05:35:16.930494: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 128
2022-07-20 05:35:16.930687: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [128,906],float [1,975]; Tensor<type: int32 shape: [2] values: 128 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-07-20 05:35:17.210416: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-07-20 05:35:17.214028: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 128 has warmuped; cost us: 283522
2022-07-20 05:35:17.214051: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 256
2022-07-20 05:35:17.214209: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [256,906],float [1,975]; Tensor<type: int32 shape: [2] values: 256 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-07-20 05:35:17.490815: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-07-20 05:35:17.494277: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 256 has warmuped; cost us: 280216
2022-07-20 05:35:17.494298: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 384
2022-07-20 05:35:17.494434: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [384,906],float [1,975]; Tensor<type: int32 shape: [2] values: 384 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-07-20 05:35:17.770722: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-07-20 05:35:17.774333: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 384 has warmuped; cost us: 280021
2022-07-20 05:35:17.774363: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 512
2022-07-20 05:35:17.774502: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [512,906],float [1,975]; Tensor<type: int32 shape: [2] values: 512 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-07-20 05:35:18.056966: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-07-20 05:35:18.060688: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 512 has warmuped; cost us: 286312
2022-07-20 05:35:18.060724: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 1024
2022-07-20 05:35:18.060876: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [1024,906],float [1,975]; Tensor<type: int32 shape: [2] values: 1024 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-07-20 05:35:18.336703: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-07-20 05:35:18.340399: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 1024 has warmuped; cost us: 279665
2022-07-20 05:35:18.343086: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1816] Running auto_mixed_precision graph optimizer
2022-07-20 05:35:18.343356: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1268] No whitelist ops found, nothing to do
2022-07-20 05:35:18.348176: I tensorflow/core/kernels/blaze_xla_kernel.cc:80] blaze set thread pool size 2
2022-07-20 05:35:18.348470: I tensorflow/core/kernels/blaze_xla_kernel.cc:80] blaze set thread pool size 2
2022-07-20 05:35:18.348483: I tensorflow/core/kernels/blaze_xla_kernel.cc:88] blaze max waiting count 10
2022-07-20 05:35:18.348593: I tensorflow/core/kernels/blaze_xla_kernel.cc:155] Parse blaze options succ warmup_batchsize: 1
warmup_batchsize: 64
warmup_batchsize: 128
warmup_batchsize: 256
warmup_batchsize: 384
warmup_batchsize: 512
warmup_batchsize: 1024
xla_compilation: true
gemm_optimization: true
auto_mixed_precision: true
no_warmup_inputs: "att_ncomm2"
config_proto {
  graph_options {
    rewrite_options {
      auto_mixed_precision: ON
      gemm_optimization: ON
    }
  }
  force_run_in_caller_thread: true
  enable_graph_opt_place: true
}
wait_ms: 20

[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:317] Error parsing text-format tensorflow.GraphDef: 2:1: Expected identifier, got: 6
2022-07-20 05:35:18.462964: I tensorflow/core/kernels/blaze_xla_kernel.cc:100] Blaze create with options warmup_batchsize: 1
warmup_batchsize: 64
warmup_batchsize: 128
warmup_batchsize: 256
warmup_batchsize: 384
warmup_batchsize: 512
warmup_batchsize: 1024
xla_compilation: true
gemm_optimization: true
auto_mixed_precision: true
no_warmup_inputs: "att_ncomm2"
config_proto {
  gpu_options {
    allow_growth: true
  }
  allow_soft_placement: true
  graph_options {
    rewrite_options {
      auto_mixed_precision: ON
      gemm_optimization: ON
    }
  }
  force_run_in_caller_thread: true
  enable_graph_opt_place: true
}
wait_ms: 20

2022-07-20 05:35:18.466921: I tensorflow/core/kernels/blaze_predictor.cc:110] create session with config gpu_options {
  allow_growth: true
  visible_device_list: "0"
  experimental {
    virtual_devices {
      memory_limit_mb: 12288
      memory_limit_mb: 12288
      memory_limit_mb: 12288
      memory_limit_mb: 12288
    }
  }
}
allow_soft_placement: true
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    auto_mixed_precision: ON
    gemm_optimization: ON
  }
}
enable_graph_opt_place: true
is_blaze: true

2022-07-20 05:35:18.468314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1642] Found device 0 with properties: 
name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
pciBusID: 0000:5e:00.0
2022-07-20 05:35:18.468348: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-07-20 05:35:18.468357: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-07-20 05:35:18.468363: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-07-20 05:35:18.468370: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-07-20 05:35:18.468377: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2022-07-20 05:35:18.468385: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-07-20 05:35:18.468392: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-07-20 05:35:18.469474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1770] Adding visible gpu devices: 0
2022-07-20 05:35:18.469511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-07-20 05:35:18.469523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2022-07-20 05:35:18.469528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2022-07-20 05:35:18.472231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12288 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5)
2022-07-20 05:35:18.472807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 12288 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5)
2022-07-20 05:35:18.473365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 12288 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5)
2022-07-20 05:35:18.473927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 12288 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5)
2022-07-20 05:35:18.473997: I tensorflow/core/kernels/blaze_predictor.cc:119] Blaze start with step id 1024
2022-07-20 05:35:18.474006: I tensorflow/core/kernels/blaze_predictor.cc:120] Creat session succ 0x7f59893086c0
2022-07-20 05:35:18.474016: I tensorflow/core/kernels/blaze_predictor.cc:73] BlazePredictor will use device /job:localhost/replica:0/task:0/device:GPU:2
2022-07-20 05:35:18.482056: I tensorflow/core/common_runtime/placer.cc:128] Allow optimize placer
2022-07-20 05:35:18.482550: I tensorflow/core/kernels/blaze_predictor.cc:92] create session with callable options feed: "ncomm"
feed: "comm"
fetch: "Softmax"
feed_devices {
  key: "comm"
  value: "/job:localhost/replica:0/task:0/device:GPU:2"
}
feed_devices {
  key: "ncomm"
  value: "/job:localhost/replica:0/task:0/device:GPU:2"
}
fetch_devices {
  key: "Softmax"
  value: "/job:localhost/replica:0/task:0/device:GPU:2"
}
fetch_skip_sync: true

2022-07-20 05:35:18.538428: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1816] Running auto_mixed_precision graph optimizer
2022-07-20 05:35:18.540077: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1772] Converted 53/91 nodes to float16 precision using 2 cast(s) to float16 (excluding Const and Variable casts)
2022-07-20 05:35:18.626356: I tensorflow/compiler/jit/build_xla_ops_pass.cc:398] enable_xla_auto_padding=0
2022-07-20 05:35:18.626405: I tensorflow/compiler/jit/build_xla_ops_pass.cc:404] auto_padding_shape 
2022-07-20 05:35:18.627087: I tensorflow/core/kernels/blaze_predictor.cc:132] MakeCallable succ 0x7f59893086c0
2022-07-20 05:35:18.627114: I tensorflow/core/kernels/blaze_predictor.cc:205] req_dev: /device:CPU:0; blaze_dev: /device:GPU:2
2022-07-20 05:35:18.627515: I tensorflow/core/kernels/blaze_xla_predictor.cc:367] Begin warmup
2022-07-20 05:35:18.628372: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 1
2022-07-20 05:35:18.628582: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [1,906],float [1,975]; Tensor<type: int32 shape: [2] values: 1 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-07-20 05:35:19.449925: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 1 has warmuped; cost us: 821522
2022-07-20 05:35:19.449976: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 64
2022-07-20 05:35:19.450216: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [64,906],float [1,975]; Tensor<type: int32 shape: [2] values: 64 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-07-20 05:35:19.733133: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-07-20 05:35:20.176082: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 64 has warmuped; cost us: 726086
2022-07-20 05:35:20.176135: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 128
2022-07-20 05:35:20.176341: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [128,906],float [1,975]; Tensor<type: int32 shape: [2] values: 128 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-07-20 05:35:20.457083: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-07-20 05:35:20.460782: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 128 has warmuped; cost us: 284632
2022-07-20 05:35:20.460813: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 256
2022-07-20 05:35:20.460961: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [256,906],float [1,975]; Tensor<type: int32 shape: [2] values: 256 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-07-20 05:35:20.737747: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-07-20 05:35:20.741333: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 256 has warmuped; cost us: 280507
2022-07-20 05:35:20.741366: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 384
2022-07-20 05:35:20.741509: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [384,906],float [1,975]; Tensor<type: int32 shape: [2] values: 384 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-07-20 05:35:21.017764: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-07-20 05:35:21.021396: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 384 has warmuped; cost us: 280017
2022-07-20 05:35:21.021424: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 512
2022-07-20 05:35:21.021563: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [512,906],float [1,975]; Tensor<type: int32 shape: [2] values: 512 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-07-20 05:35:21.296943: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-07-20 05:35:21.300662: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 512 has warmuped; cost us: 279225
2022-07-20 05:35:21.300696: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 1024
2022-07-20 05:35:21.300847: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [1024,906],float [1,975]; Tensor<type: int32 shape: [2] values: 1024 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-07-20 05:35:21.577241: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-07-20 05:35:21.581024: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 1024 has warmuped; cost us: 280317
2022-07-20 05:35:21.583694: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1816] Running auto_mixed_precision graph optimizer
2022-07-20 05:35:21.583965: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1268] No whitelist ops found, nothing to do
2022-07-20 05:35:21.588800: I tensorflow/core/kernels/blaze_xla_kernel.cc:80] blaze set thread pool size 2
2022-07-20 05:35:21.589073: I tensorflow/core/kernels/blaze_xla_kernel.cc:80] blaze set thread pool size 2
2022-07-20 05:35:21.589084: I tensorflow/core/kernels/blaze_xla_kernel.cc:88] blaze max waiting count 10
2022-07-20 05:35:21.589193: I tensorflow/core/kernels/blaze_xla_kernel.cc:155] Parse blaze options succ warmup_batchsize: 1
warmup_batchsize: 64
warmup_batchsize: 128
warmup_batchsize: 256
warmup_batchsize: 384
warmup_batchsize: 512
warmup_batchsize: 1024
xla_compilation: true
gemm_optimization: true
auto_mixed_precision: true
no_warmup_inputs: "att_ncomm2"
config_proto {
  graph_options {
    rewrite_options {
      auto_mixed_precision: ON
      gemm_optimization: ON
    }
  }
  force_run_in_caller_thread: true
  enable_graph_opt_place: true
}
wait_ms: 20

[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:317] Error parsing text-format tensorflow.GraphDef: 2:1: Expected identifier, got: 6
2022-07-20 05:35:21.700855: I tensorflow/core/kernels/blaze_xla_kernel.cc:100] Blaze create with options warmup_batchsize: 1
warmup_batchsize: 64
warmup_batchsize: 128
warmup_batchsize: 256
warmup_batchsize: 384
warmup_batchsize: 512
warmup_batchsize: 1024
xla_compilation: true
gemm_optimization: true
auto_mixed_precision: true
no_warmup_inputs: "att_ncomm2"
config_proto {
  gpu_options {
    allow_growth: true
  }
  allow_soft_placement: true
  graph_options {
    rewrite_options {
      auto_mixed_precision: ON
      gemm_optimization: ON
    }
  }
  force_run_in_caller_thread: true
  enable_graph_opt_place: true
}
wait_ms: 20

2022-07-20 05:35:21.704012: I tensorflow/core/kernels/blaze_predictor.cc:110] create session with config gpu_options {
  allow_growth: true
  visible_device_list: "0"
  experimental {
    virtual_devices {
      memory_limit_mb: 12288
      memory_limit_mb: 12288
      memory_limit_mb: 12288
      memory_limit_mb: 12288
    }
  }
}
allow_soft_placement: true
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    auto_mixed_precision: ON
    gemm_optimization: ON
  }
}
enable_graph_opt_place: true
is_blaze: true

2022-07-20 05:35:21.705103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1642] Found device 0 with properties: 
name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
pciBusID: 0000:5e:00.0
2022-07-20 05:35:21.705137: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-07-20 05:35:21.705146: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-07-20 05:35:21.705153: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-07-20 05:35:21.705160: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-07-20 05:35:21.705167: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2022-07-20 05:35:21.705175: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-07-20 05:35:21.705182: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-07-20 05:35:21.706255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1770] Adding visible gpu devices: 0
2022-07-20 05:35:21.706292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-07-20 05:35:21.706300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2022-07-20 05:35:21.706306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2022-07-20 05:35:21.708970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12288 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5)
2022-07-20 05:35:21.709534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 12288 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5)
2022-07-20 05:35:21.710092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 12288 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5)
2022-07-20 05:35:21.710642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 12288 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:5e:00.0, compute capability: 7.5)
2022-07-20 05:35:21.710707: I tensorflow/core/kernels/blaze_predictor.cc:119] Blaze start with step id 1024
2022-07-20 05:35:21.710723: I tensorflow/core/kernels/blaze_predictor.cc:120] Creat session succ 0x7f598bc70010
2022-07-20 05:35:21.710733: I tensorflow/core/kernels/blaze_predictor.cc:73] BlazePredictor will use device /job:localhost/replica:0/task:0/device:GPU:3
2022-07-20 05:35:21.717221: I tensorflow/core/common_runtime/placer.cc:128] Allow optimize placer
2022-07-20 05:35:21.717714: I tensorflow/core/kernels/blaze_predictor.cc:92] create session with callable options feed: "ncomm"
feed: "comm"
fetch: "Softmax"
feed_devices {
  key: "comm"
  value: "/job:localhost/replica:0/task:0/device:GPU:3"
}
feed_devices {
  key: "ncomm"
  value: "/job:localhost/replica:0/task:0/device:GPU:3"
}
fetch_devices {
  key: "Softmax"
  value: "/job:localhost/replica:0/task:0/device:GPU:3"
}
fetch_skip_sync: true

2022-07-20 05:35:21.776143: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1816] Running auto_mixed_precision graph optimizer
2022-07-20 05:35:21.777885: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1772] Converted 53/91 nodes to float16 precision using 2 cast(s) to float16 (excluding Const and Variable casts)
2022-07-20 05:35:21.862140: I tensorflow/compiler/jit/build_xla_ops_pass.cc:398] enable_xla_auto_padding=0
2022-07-20 05:35:21.862186: I tensorflow/compiler/jit/build_xla_ops_pass.cc:404] auto_padding_shape 
2022-07-20 05:35:21.862851: I tensorflow/core/kernels/blaze_predictor.cc:132] MakeCallable succ 0x7f598bc70010
2022-07-20 05:35:21.862875: I tensorflow/core/kernels/blaze_predictor.cc:205] req_dev: /device:CPU:0; blaze_dev: /device:GPU:3
2022-07-20 05:35:21.863290: I tensorflow/core/kernels/blaze_xla_predictor.cc:367] Begin warmup
2022-07-20 05:35:21.864189: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 1
2022-07-20 05:35:21.864414: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [1,906],float [1,975]; Tensor<type: int32 shape: [2] values: 1 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-07-20 05:35:22.695333: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 1 has warmuped; cost us: 831108
2022-07-20 05:35:22.695390: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 64
2022-07-20 05:35:22.695632: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [64,906],float [1,975]; Tensor<type: int32 shape: [2] values: 64 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-07-20 05:35:22.978849: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-07-20 05:35:23.411015: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 64 has warmuped; cost us: 715616
2022-07-20 05:35:23.411038: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 128
2022-07-20 05:35:23.411213: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [128,906],float [1,975]; Tensor<type: int32 shape: [2] values: 128 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-07-20 05:35:23.696143: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-07-20 05:35:23.699879: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 128 has warmuped; cost us: 288830
2022-07-20 05:35:23.699902: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 256
2022-07-20 05:35:23.700039: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [256,906],float [1,975]; Tensor<type: int32 shape: [2] values: 256 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-07-20 05:35:23.977799: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-07-20 05:35:23.981464: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 256 has warmuped; cost us: 281553
2022-07-20 05:35:23.981491: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 384
2022-07-20 05:35:23.981637: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [384,906],float [1,975]; Tensor<type: int32 shape: [2] values: 384 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-07-20 05:35:24.258945: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-07-20 05:35:24.262656: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 384 has warmuped; cost us: 281148
2022-07-20 05:35:24.262699: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 512
2022-07-20 05:35:24.262860: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [512,906],float [1,975]; Tensor<type: int32 shape: [2] values: 512 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-07-20 05:35:24.538123: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-07-20 05:35:24.541813: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 512 has warmuped; cost us: 279100
2022-07-20 05:35:24.541848: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 1024
2022-07-20 05:35:24.541994: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=2,_XlaNumResourceArgs=0],float [1024,906],float [1,975]; Tensor<type: int32 shape: [2] values: 1024 1>; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-07-20 05:35:24.818855: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-07-20 05:35:24.822592: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 1024 has warmuped; cost us: 280732
2022-07-20 05:35:24.823352: I /home/yunlong.xyl/projects/temp/blaze-benchmark/benchmark/core/model.cc:385] Init and warmup model complete: ad_rtp_wt_ctr_wt_union_v1_turing
2022-Jul-20 05:35:27.826618 ====================================================
-- Histograms ------------------------------------------------------------------
ad_rtp_wt_ctr_wt_union_v1_turing_latency
             count = 12673
               min = 640
               max = 8907
              mean = 949.38
            stddev = 273.39
            median = 930.00
              75% <= 1016.00
              95% <= 1137.75
              98% <= 1188.00
              99% <= 1234.75
            99.9% <= 8717.78

-- Meters ----------------------------------------------------------------------
ad_rtp_wt_ctr_wt_union_v1_turing_throughput
             count = 12673
         mean rate = 4232.07 events per 1 Seconds
     1-minute rate = 0.00 events per 1 Seconds
     5-minute rate = 0.00 events per 1 Seconds
    15-minute rate = 0.00 events per 1 Seconds


2022-Jul-20 05:35:30.826925 ====================================================
-- Histograms ------------------------------------------------------------------
ad_rtp_wt_ctr_wt_union_v1_turing_latency
             count = 25375
               min = 640
               max = 8907
              mean = 948.95
            stddev = 273.43
            median = 933.00
              75% <= 1016.75
              95% <= 1133.00
              98% <= 1178.50
              99% <= 1215.75
            99.9% <= 8727.68

-- Meters ----------------------------------------------------------------------
ad_rtp_wt_ctr_wt_union_v1_turing_throughput
             count = 25377
         mean rate = 4233.21 events per 1 Seconds
     1-minute rate = 4231.60 events per 1 Seconds
     5-minute rate = 4231.60 events per 1 Seconds
    15-minute rate = 4231.60 events per 1 Seconds


2022-Jul-20 05:35:33.827151 ====================================================
-- Histograms ------------------------------------------------------------------
ad_rtp_wt_ctr_wt_union_v1_turing_latency
             count = 38092
               min = 640
               max = 8907
              mean = 947.27
            stddev = 271.54
            median = 936.00
              75% <= 1015.50
              95% <= 1123.00
              98% <= 1151.00
              99% <= 1192.00
            99.9% <= 8727.68

-- Meters ----------------------------------------------------------------------
ad_rtp_wt_ctr_wt_union_v1_turing_throughput
             count = 38093
         mean rate = 4234.92 events per 1 Seconds
     1-minute rate = 4231.60 events per 1 Seconds
     5-minute rate = 4231.60 events per 1 Seconds
    15-minute rate = 4231.60 events per 1 Seconds


2022-Jul-20 05:35:36.827384 ====================================================
-- Histograms ------------------------------------------------------------------
ad_rtp_wt_ctr_wt_union_v1_turing_latency
             count = 50781
               min = 652
               max = 8907
              mean = 948.36
            stddev = 271.09
            median = 936.00
              75% <= 1013.75
              95% <= 1119.75
              98% <= 1163.50
              99% <= 1199.50
            99.9% <= 8727.68

-- Meters ----------------------------------------------------------------------
ad_rtp_wt_ctr_wt_union_v1_turing_throughput
             count = 50781
         mean rate = 4233.44 events per 1 Seconds
     1-minute rate = 4232.08 events per 1 Seconds
     5-minute rate = 4231.70 events per 1 Seconds
    15-minute rate = 4231.63 events per 1 Seconds


2022-Jul-20 05:35:39.827620 ====================================================
-- Histograms ------------------------------------------------------------------
ad_rtp_wt_ctr_wt_union_v1_turing_latency
             count = 63468
               min = 688
               max = 8907
              mean = 952.68
            stddev = 269.91
            median = 939.00
              75% <= 1014.75
              95% <= 1117.75
              98% <= 1151.00
              99% <= 1197.50
            99.9% <= 8727.68

-- Meters ----------------------------------------------------------------------
ad_rtp_wt_ctr_wt_union_v1_turing_throughput
             count = 63468
         mean rate = 4232.48 events per 1 Seconds
     1-minute rate = 4232.08 events per 1 Seconds
     5-minute rate = 4231.70 events per 1 Seconds
    15-minute rate = 4231.63 events per 1 Seconds


