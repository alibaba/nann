+ ln -sf ../../runmeta/all_star_newstag_nmd_jrc/frozen_graph.pb user/frozen_graph.pb
+ LD_LIBRARY_PATH=/usr/local/nvidia/lib64
+ PATH=/usr/local/nvidia/bin/
+ /usr/local/nvidia/bin/nvidia-cuda-mps-control -d
An instance of this daemon is already running
+ TF_XLA_PTX_CACHE_DIR=./xla_cache
+ TF_CPP_MIN_VLOG_LEVEL=0
+ BLAZE_USE_MPS=1
+ LD_LIBRARY_PATH=/usr/local/nvidia/lib64:/usr/local/cuda-11.2/lib64
+ ../../../build/benchmark/benchmark benchmark_conf
2022-08-04 07:52:04.338015: I /home/yunlong.xyl/blaze-benchmark/benchmark/core/model.cc:333] 1656993881179967.runmeta, inferred batchsize = 166, star
2022-08-04 07:52:04.339148: I /home/yunlong.xyl/tensorflow/tensorflow/core/common_runtime/direct_session.h:441] Blaze will use globla_opts : device_count {
  key: "GPU"
  value: 1
}
gpu_options {
  allow_growth: true
  visible_device_list: "0"
  experimental {
    virtual_devices {
      memory_limit_mb: 12288
      memory_limit_mb: 12288
      memory_limit_mb: 12288
      memory_limit_mb: 12288
    }
  }
}
allow_soft_placement: true
graph_options {
  rewrite_options {
    layout_optimizer: OFF
    auto_mixed_precision: OFF
  }
}
enable_graph_opt_place: true
blaze_options {
  warmup_batchsize: 200
  xla_compilation: true
  gemm_optimization: true
  auto_mixed_precision: true
  no_warmup_inputs: "att_ncomm2"
  no_warmup_inputs: "att_ncomm3"
  no_warmup_inputs: "cross_long1"
  no_warmup_inputs: "cross_long2"
  no_warmup_inputs: "model_route_index"
  config_proto {
    graph_options {
      rewrite_options {
        auto_mixed_precision: OFF
        gemm_optimization: ON
      }
    }
    force_run_in_caller_thread: true
    enable_graph_opt_place: true
  }
  wait_ms: 20
}

2022-08-04 07:52:04.339290: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-08-04 07:52:04.494732: I /home/yunlong.xyl/blaze-benchmark/benchmark/core/model.cc:166] GetDeviceCount: cpu_count =  1, gpu_count = 4
2022-08-04 07:52:04.494851: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F FMA
2022-08-04 07:52:04.512696: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-08-04 07:52:04.512719: I tensorflow/stream_executor/executor_cache.cc:41] TF_NUM_CONTEXTS_PER_GPU = 4
2022-08-04 07:52:04.512726: I tensorflow/stream_executor/executor_cache.cc:62] TF_NUM_CONTEXTS_PER_GPU = 4
2022-08-04 07:52:04.513111: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2900000000 Hz
2022-08-04 07:52:04.519067: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556ba4ae4aa0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-08-04 07:52:04.519085: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-08-04 07:52:04.520954: I tensorflow/stream_executor/executor_cache.cc:62] TF_NUM_CONTEXTS_PER_GPU = 4
2022-08-04 07:52:04.628367: I tensorflow/stream_executor/cuda/cuda_driver.cc:454] cuDevicePrimaryCtxRetain context 0x556ba3fd2490
2022-08-04 07:52:04.631990: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556ba4b47c90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-08-04 07:52:04.632013: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-SXM4-80GB, Compute Capability 8.0
2022-08-04 07:52:04.634646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1642] Found device 0 with properties: 
name: NVIDIA A100-SXM4-80GB major: 8 minor: 0 memoryClockRate(GHz): 1.41
pciBusID: 0000:54:00.0
2022-08-04 07:52:04.634664: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-08-04 07:52:04.637802: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-08-04 07:52:04.638569: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-08-04 07:52:04.638752: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-08-04 07:52:04.639405: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2022-08-04 07:52:04.639974: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-08-04 07:52:04.640051: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-08-04 07:52:04.644762: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1770] Adding visible gpu devices: 0
2022-08-04 07:52:04.644806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-08-04 07:52:04.644811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2022-08-04 07:52:04.644815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2022-08-04 07:52:04.684290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 07:52:04.687681: I tensorflow/stream_executor/executor_cache.cc:62] TF_NUM_CONTEXTS_PER_GPU = 4
2022-08-04 07:52:04.782619: I tensorflow/stream_executor/cuda/cuda_driver.cc:458] Primary context has been used, cuCtxCreate context 0x556ba4ec69e0
2022-08-04 07:52:04.782650: W tensorflow/stream_executor/cuda/cuda_driver.cc:472] A non-primary context 0x556ba3fd2490 for device 0 exists before initializing the StreamExecutor. The primary context is now 0x556ba4ec69e0. We haven't verified StreamExecutor works with that.
2022-08-04 07:52:04.785854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 07:52:04.789478: I tensorflow/stream_executor/executor_cache.cc:62] TF_NUM_CONTEXTS_PER_GPU = 4
2022-08-04 07:52:04.883632: I tensorflow/stream_executor/cuda/cuda_driver.cc:458] Primary context has been used, cuCtxCreate context 0x556ba54b5950
2022-08-04 07:52:04.883657: W tensorflow/stream_executor/cuda/cuda_driver.cc:472] A non-primary context 0x556ba4ec69e0 for device 0 exists before initializing the StreamExecutor. The primary context is now 0x556ba54b5950. We haven't verified StreamExecutor works with that.
2022-08-04 07:52:04.886993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 07:52:04.890609: I tensorflow/stream_executor/executor_cache.cc:62] TF_NUM_CONTEXTS_PER_GPU = 4
2022-08-04 07:52:04.991685: I tensorflow/stream_executor/cuda/cuda_driver.cc:458] Primary context has been used, cuCtxCreate context 0x556ba5aaf9d0
2022-08-04 07:52:04.991714: W tensorflow/stream_executor/cuda/cuda_driver.cc:472] A non-primary context 0x556ba54b5950 for device 0 exists before initializing the StreamExecutor. The primary context is now 0x556ba5aaf9d0. We haven't verified StreamExecutor works with that.
2022-08-04 07:52:04.994092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 07:52:05.000775: I tensorflow/core/common_runtime/placer.cc:128] Allow optimize placer
2022-08-04 07:52:05.000975: I /home/yunlong.xyl/blaze-benchmark/benchmark/core/model.cc:234] Predictor 0 uses session star/CPU:0/GPU:0
2022-08-04 07:52:05.004740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1642] Found device 0 with properties: 
name: NVIDIA A100-SXM4-80GB major: 8 minor: 0 memoryClockRate(GHz): 1.41
pciBusID: 0000:54:00.0
2022-08-04 07:52:05.004769: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-08-04 07:52:05.004778: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-08-04 07:52:05.004785: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-08-04 07:52:05.004793: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-08-04 07:52:05.004800: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2022-08-04 07:52:05.004807: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-08-04 07:52:05.004813: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-08-04 07:52:05.009357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1770] Adding visible gpu devices: 0
2022-08-04 07:52:05.009384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-08-04 07:52:05.009388: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2022-08-04 07:52:05.009392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2022-08-04 07:52:05.020555: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 07:52:05.022809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 07:52:05.025472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 07:52:05.051823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 07:52:05.052270: I tensorflow/core/common_runtime/placer.cc:128] Allow optimize placer
2022-08-04 07:52:05.052376: I /home/yunlong.xyl/blaze-benchmark/benchmark/core/model.cc:234] Predictor 1 uses session star/CPU:0/GPU:1
2022-08-04 07:52:05.057372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1642] Found device 0 with properties: 
name: NVIDIA A100-SXM4-80GB major: 8 minor: 0 memoryClockRate(GHz): 1.41
pciBusID: 0000:54:00.0
2022-08-04 07:52:05.057387: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-08-04 07:52:05.057393: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-08-04 07:52:05.057397: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-08-04 07:52:05.057401: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-08-04 07:52:05.057406: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2022-08-04 07:52:05.057410: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-08-04 07:52:05.057414: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-08-04 07:52:05.063722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1770] Adding visible gpu devices: 0
2022-08-04 07:52:05.063738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-08-04 07:52:05.063743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2022-08-04 07:52:05.063746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2022-08-04 07:52:05.079236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 07:52:05.082366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 07:52:05.085355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 07:52:05.088506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 07:52:05.088931: I tensorflow/core/common_runtime/placer.cc:128] Allow optimize placer
2022-08-04 07:52:05.089036: I /home/yunlong.xyl/blaze-benchmark/benchmark/core/model.cc:234] Predictor 2 uses session star/CPU:0/GPU:2
2022-08-04 07:52:05.092490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1642] Found device 0 with properties: 
name: NVIDIA A100-SXM4-80GB major: 8 minor: 0 memoryClockRate(GHz): 1.41
pciBusID: 0000:54:00.0
2022-08-04 07:52:05.092507: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-08-04 07:52:05.092512: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-08-04 07:52:05.092516: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-08-04 07:52:05.092520: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-08-04 07:52:05.092524: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2022-08-04 07:52:05.092528: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-08-04 07:52:05.092533: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-08-04 07:52:05.098622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1770] Adding visible gpu devices: 0
2022-08-04 07:52:05.098636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-08-04 07:52:05.098641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2022-08-04 07:52:05.098644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2022-08-04 07:52:05.114181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 07:52:05.117318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 07:52:05.120454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 07:52:05.123598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 07:52:05.123999: I tensorflow/core/common_runtime/placer.cc:128] Allow optimize placer
2022-08-04 07:52:05.124104: I /home/yunlong.xyl/blaze-benchmark/benchmark/core/model.cc:234] Predictor 3 uses session star/CPU:0/GPU:3
2022-08-04 07:52:05.166045: I tensorflow/core/kernels/blaze_xla_kernel.cc:80] blaze set thread pool size 2
2022-08-04 07:52:05.166245: I tensorflow/core/kernels/blaze_xla_kernel.cc:80] blaze set thread pool size 2
2022-08-04 07:52:05.166256: I tensorflow/core/kernels/blaze_xla_kernel.cc:88] blaze max waiting count 10
2022-08-04 07:52:05.166363: I tensorflow/core/kernels/blaze_xla_kernel.cc:155] Parse blaze options succ warmup_batchsize: 200
xla_compilation: true
gemm_optimization: true
auto_mixed_precision: true
no_warmup_inputs: "att_ncomm2"
no_warmup_inputs: "att_ncomm3"
no_warmup_inputs: "cross_long1"
no_warmup_inputs: "cross_long2"
no_warmup_inputs: "model_route_index"
config_proto {
  graph_options {
    rewrite_options {
      auto_mixed_precision: OFF
      gemm_optimization: ON
    }
  }
  force_run_in_caller_thread: true
  enable_graph_opt_place: true
}
wait_ms: 20

[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:317] Error parsing text-format tensorflow.GraphDef: 2:1: Expected identifier, got: 6
[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/io/zero_copy_stream_impl_lite.cc:155] Cannot allocate buffer larger than kint32max for StringOutputStream.
2022-08-04 07:52:14.857433: I tensorflow/core/kernels/blaze_xla_kernel.cc:100] Blaze create with options warmup_batchsize: 200
xla_compilation: true
gemm_optimization: true
auto_mixed_precision: true
no_warmup_inputs: "att_ncomm2"
no_warmup_inputs: "att_ncomm3"
no_warmup_inputs: "cross_long1"
no_warmup_inputs: "cross_long2"
no_warmup_inputs: "model_route_index"
config_proto {
  gpu_options {
    allow_growth: true
  }
  allow_soft_placement: true
  graph_options {
    rewrite_options {
      auto_mixed_precision: OFF
      gemm_optimization: ON
    }
  }
  force_run_in_caller_thread: true
  enable_graph_opt_place: true
}
wait_ms: 20

2022-08-04 07:52:15.343212: I tensorflow/core/kernels/blaze_predictor.cc:110] create session with config gpu_options {
  allow_growth: true
  visible_device_list: "0"
  experimental {
    virtual_devices {
      memory_limit_mb: 12288
      memory_limit_mb: 12288
      memory_limit_mb: 12288
      memory_limit_mb: 12288
    }
  }
}
allow_soft_placement: true
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    auto_mixed_precision: OFF
    gemm_optimization: ON
  }
}
enable_graph_opt_place: true
is_blaze: true

2022-08-04 07:52:15.347236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1642] Found device 0 with properties: 
name: NVIDIA A100-SXM4-80GB major: 8 minor: 0 memoryClockRate(GHz): 1.41
pciBusID: 0000:54:00.0
2022-08-04 07:52:15.347263: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-08-04 07:52:15.347272: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-08-04 07:52:15.347279: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-08-04 07:52:15.347287: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-08-04 07:52:15.347294: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2022-08-04 07:52:15.347302: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-08-04 07:52:15.347308: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-08-04 07:52:15.353871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1770] Adding visible gpu devices: 0
2022-08-04 07:52:15.353914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-08-04 07:52:15.353919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2022-08-04 07:52:15.353923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2022-08-04 07:52:15.370145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 07:52:15.373417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 07:52:15.376495: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 07:52:15.379779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 07:52:15.379833: I tensorflow/core/kernels/blaze_predictor.cc:119] Blaze start with step id 1024
2022-08-04 07:52:15.379838: I tensorflow/core/kernels/blaze_predictor.cc:120] Creat session succ 0x556ba649b6f0
2022-08-04 07:52:15.379847: I tensorflow/core/kernels/blaze_predictor.cc:73] BlazePredictor will use device /job:localhost/replica:0/task:0/device:GPU:0
2022-08-04 07:52:17.844962: I tensorflow/core/common_runtime/placer.cc:128] Allow optimize placer
2022-08-04 07:52:17.852545: I tensorflow/core/kernels/blaze_predictor.cc:92] create session with callable options feed: "comm"
feed: "att_comm2"
feed: "att_comm3"
feed: "ncomm"
feed: "model_route_index"
feed: "att_ncomm"
feed: "att_comm"
feed: "cross_long0"
feed: "cross_long1"
feed: "cross_global0"
feed: "cross_global1"
feed: "cross_long2"
feed: "cross_cr"
feed: "att_ncomm2"
feed: "nick_cate_indicators"
fetch: "add"
feed_devices {
  key: "att_comm"
  value: "/job:localhost/replica:0/task:0/device:GPU:0"
}
feed_devices {
  key: "att_comm2"
  value: "/job:localhost/replica:0/task:0/device:GPU:0"
}
feed_devices {
  key: "att_comm3"
  value: "/job:localhost/replica:0/task:0/device:GPU:0"
}
feed_devices {
  key: "att_ncomm"
  value: "/job:localhost/replica:0/task:0/device:GPU:0"
}
feed_devices {
  key: "att_ncomm2"
  value: "/job:localhost/replica:0/task:0/device:GPU:0"
}
feed_devices {
  key: "comm"
  value: "/job:localhost/replica:0/task:0/device:GPU:0"
}
feed_devices {
  key: "cross_cr"
  value: "/job:localhost/replica:0/task:0/device:GPU:0"
}
feed_devices {
  key: "cross_global0"
  value: "/job:localhost/replica:0/task:0/device:GPU:0"
}
feed_devices {
  key: "cross_global1"
  value: "/job:localhost/replica:0/task:0/device:GPU:0"
}
feed_devices {
  key: "cross_long0"
  value: "/job:localhost/replica:0/task:0/device:GPU:0"
}
feed_devices {
  key: "cross_long1"
  value: "/job:localhost/replica:0/task:0/device:GPU:0"
}
feed_devices {
  key: "cross_long2"
  value: "/job:localhost/replica:0/task:0/device:GPU:0"
}
feed_devices {
  key: "model_route_index"
  value: "/job:localhost/replica:0/task:0/device:GPU:0"
}
feed_devices {
  key: "ncomm"
  value: "/job:localhost/replica:0/task:0/device:GPU:0"
}
feed_devices {
  key: "nick_cate_indicators"
  value: "/job:localhost/replica:0/task:0/device:GPU:0"
}
fetch_devices {
  key: "add"
  value: "/job:localhost/replica:0/task:0/device:GPU:0"
}
fetch_skip_sync: true

2022-08-04 07:52:26.403657: I tensorflow/compiler/jit/build_xla_ops_pass.cc:398] enable_xla_auto_padding=0
2022-08-04 07:52:26.403695: I tensorflow/compiler/jit/build_xla_ops_pass.cc:404] auto_padding_shape 
2022-08-04 07:52:26.404230: I tensorflow/compiler/jit/build_xla_ops_pass.cc:398] enable_xla_auto_padding=0
2022-08-04 07:52:26.404238: I tensorflow/compiler/jit/build_xla_ops_pass.cc:404] auto_padding_shape 
2022-08-04 07:52:26.404752: I tensorflow/compiler/jit/build_xla_ops_pass.cc:398] enable_xla_auto_padding=0
2022-08-04 07:52:26.404759: I tensorflow/compiler/jit/build_xla_ops_pass.cc:404] auto_padding_shape 
2022-08-04 07:52:26.405231: I tensorflow/compiler/jit/build_xla_ops_pass.cc:398] enable_xla_auto_padding=0
2022-08-04 07:52:26.405238: I tensorflow/compiler/jit/build_xla_ops_pass.cc:404] auto_padding_shape 
2022-08-04 07:52:26.405708: I tensorflow/compiler/jit/build_xla_ops_pass.cc:398] enable_xla_auto_padding=0
2022-08-04 07:52:26.405714: I tensorflow/compiler/jit/build_xla_ops_pass.cc:404] auto_padding_shape 
2022-08-04 07:52:26.406154: I tensorflow/compiler/jit/build_xla_ops_pass.cc:398] enable_xla_auto_padding=0
2022-08-04 07:52:26.406160: I tensorflow/compiler/jit/build_xla_ops_pass.cc:404] auto_padding_shape 
2022-08-04 07:52:26.406591: I tensorflow/compiler/jit/build_xla_ops_pass.cc:398] enable_xla_auto_padding=0
2022-08-04 07:52:26.406596: I tensorflow/compiler/jit/build_xla_ops_pass.cc:404] auto_padding_shape 
2022-08-04 07:52:26.883566: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-08-04 07:52:27.452873: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2022-08-04 07:52:27.546643: I tensorflow/core/kernels/blaze_predictor.cc:132] MakeCallable succ 0x556ba649b6f0
2022-08-04 07:52:27.546682: I tensorflow/core/kernels/blaze_predictor.cc:205] req_dev: /device:CPU:0; blaze_dev: /device:GPU:0
2022-08-04 07:52:27.550162: I tensorflow/core/kernels/blaze_xla_predictor.cc:367] Begin warmup
2022-08-04 07:52:27.550299: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 200
2022-08-04 07:52:27.556177: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_1[_XlaCompiledKernel=true,_XlaNumConstantArgs=32,_XlaNumResourceArgs=0],half [200,1852],half [200,1040]; Tensor<type: int32 shape: [2] values: 0 0>; Tensor<type: int32 shape: [2] values: 0 800>; Tensor<type: int32 shape: [2] values: 1 1>; Tensor<type: int32 shape: [2] values: 0 1040>; Tensor<type: int32 shape: [2] values: 0 48>; Tensor<type: int32 shape: [2] values: 0 64>; Tensor<type: int32 shape: [2] values: 0 80>; Tensor<type: int32 shape: [2] values: 0 96>; Tensor<type: int32 shape: [2] values: 0 112>; Tensor<type: int32 shape: [2] values: 0 160>; Tensor<type: int32 shape: [2] values: 0 176>; Tensor<type: int32 shape: [2] values: 0 144>; Tensor<type: int32 shape: [3] values: -1 4 200>; Tensor<type: int32 shape: [5] values: -1 2 6...>; Tensor<type: int32 shape: [] values: 1>; Tensor<type: int32 shape: [3] values: 0 0 0>; Tensor<type: int32 shape: [3] values: 0 0 180>; Tensor<type: int32 shape: [3] values: 1 1 1>; Tensor<type: int32 shape: [5] values: 0 0 0...>; Tensor<type: int32 shape: [5] values: 0 0 3...>; Tensor<type: int32 shape: [5] values: 1 1 1...>; Tensor<type: int32 shape: [5] values: 0 0 6...>; Tensor<type: int32 shape: [5] values: -1 4 9...>; Tensor<type: int32 shape: [4] values: -1 6 5...>; Tensor<type: int32 shape: [5] values: 0 0 7...>; Tensor<type: int32 shape: [5] values: 0 0 9...>; Tensor<type: int32 shape: [3] values: 8 0 0>; Tensor<type: int32 shape: [3] values: 12 0 0>; Tensor<type: int32 shape: [4] values: -1 24 5...>; Tensor<type: int32 shape: [4] values: -1 4 5...>; Tensor<type: int32 shape: [4] values: -1 8 5...>; Tensor<type: int32 shape: [4] values: 4 -1 1...> with request count 1 and compile threshold 0 shape info=0
2022-08-04 07:52:27.572279: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:268] Cache XLA PTXs in ./xla_cache. This line is logged at most once for the lifetime of the process.
2022-08-04 07:52:27.572295: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:285] Will not cache XLA CUBINs. This line is logged at most once for the lifetime of the process.
2022-08-04 07:52:27.572625: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:329] RunBackend() - Will load PTX from file: ./xla_cache/10153300373092785533.ptx
2022-08-04 07:52:28.589047: I tensorflow/compiler/jit/xla_compilation_cache.cc:292] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-08-04 07:52:28.864426: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_2[_XlaCompiledKernel=true,_XlaNumConstantArgs=9,_XlaNumResourceArgs=0],half [1,1000],half [1,18000],half [1,4500]; Tensor<type: int32 shape: [4] values: 6 150 4...>; Tensor<type: int32 shape: [4] values: 1 50 4...>; Tensor<type: int32 shape: [4] values: 3 150 2...>; Tensor<type: int32 shape: [4] values: 2 0 1...>; Tensor<type: int32 shape: [3] values: 24 150 5>; Tensor<type: int32 shape: [4] values: 1 4 50...>; Tensor<type: int32 shape: [3] values: 6 150 5>; Tensor<type: int32 shape: [] values: 0>; Tensor<type: int32 shape: [4] values: 1 30 150...> with request count 1 and compile threshold 0 shape info=0
2022-08-04 07:52:28.868502: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:329] RunBackend() - Will load PTX from file: ./xla_cache/4695837893004515636.ptx
2022-08-04 07:52:29.404637: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_4[_XlaCompiledKernel=true,_XlaNumConstantArgs=1,_XlaNumResourceArgs=0],float [4,200,200,1]; Tensor<type: int32 shape: [4] values: 0 1 3...> with request count 1 and compile threshold 0 shape info=0
2022-08-04 07:52:29.984338: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=52,_XlaNumResourceArgs=0],float [200,96],float [16,200,24],float [200,4,2,4],float [200,30,2,4],float [200,14,2,4],float [4,200,24,1],float [200,1852],float [200,96],half [1,1728],half [1,4800],half [1,19200],half [1,4800],half [1,38400]; Tensor<type: int32 shape: [4] values: 2 8 150...>; Tensor<type: int32 shape: [3] values: 6 50 16>; Tensor<type: int32 shape: [3] values: 6 200 16>; Tensor<type: int32 shape: [4] values: 0 2 1...>; Tensor<type: int32 shape: [3] values: 1 0 2>; Tensor<type: int32 shape: [3] values: 2 150 128>; Tensor<type: int32 shape: [3] values: 1 50 96>; Tensor<type: int32 shape: [3] values: 1 200 96>; Tensor<type: int32 shape: [1] values: 0>; Tensor<type: int32 shape: [1] values: 1>; Tensor<type: int32 shape: [1] values: 2>; Tensor<type: int32 shape: [3] values: 16 0 0>; Tensor<type: int32 shape: [4] values: 1 200 4...>; Tensor<type: int32 shape: [2] values: 200 1>; Tensor<type: int32 shape: [4] values: 2 50 4...>; Tensor<type: int32 shape: [3] values: 4 200 24>; Tensor<type: int32 shape: [3] values: -1 4 8>; Tensor<type: int32 shape: [4] values: 2 150 4...>; Tensor<type: int32 shape: [3] values: 8 50 24>; Tensor<type: int32 shape: [3] values: -1 30 8>; Tensor<type: int32 shape: [3] values: 0 1 0>; Tensor<type: int32 shape: [3] values: 0 2 0>; Tensor<type: int32 shape: [3] values: 0 3 0>; Tensor<type: int32 shape: [3] values: -1 14 8>; Tensor<type: int32 shape: [3] values: 0 6 0>; Tensor<type: int32 shape: [3] values: 0 12 0>; Tensor<type: int32 shape: [3] values: 0 18 0>; Tensor<type: int32 shape: [3] values: 0 24 0>; Tensor<type: int32 shape: [3] values: 0 27 0>; Tensor<type: int32 shape: [3] values: 0 4 0>; Tensor<type: int32 shape: [3] values: 0 8 0>; Tensor<type: int32 shape: [3] values: 0 11 0>; Tensor<type: int32 shape: [3] values: 8 150 32>; Tensor<type: int32 shape: [2] values: -1 384>; Tensor<type: int32 shape: [4] values: 1 4 -1...>; Tensor<type: int32 shape: [4] values: 1 0 2...>; Tensor<type: int32 shape: [4] values: 2 4 -1...>; Tensor<type: int32 shape: [2] values: -1 96>; Tensor<type: int32 shape: [4] values: 2 4 -1...>; Tensor<type: int32 shape: [2] values: -1 192>; Tensor<type: int32 shape: [2] values: 0 -96>; Tensor<type: int32 shape: [2] values: -1 256>; Tensor<type: int32 shape: [2] values: 0 0>; Tensor<type: int32 shape: [2] values: 0 96>; Tensor<type: int32 shape: [2] values: 1 1>; Tensor<type: int32 shape: [3] values: 1 1 1>; Tensor<type: int32 shape: [3] values: 8 0 0>; Tensor<type: int32 shape: [3] values: 0 0 0>; Tensor<type: int32 shape: [] values: 0>; Tensor<type: int32 shape: [4] values: 2 0 1...>; Tensor<type: int32 shape: [] values: 1>; Tensor<type: int32 shape: [3] values: 12 0 0> with request count 1 and compile threshold 0 shape info=0
2022-08-04 07:52:31.052922: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_5[_XlaCompiledKernel=true,_XlaNumConstantArgs=1,_XlaNumResourceArgs=0],float [200,5244],float [1,5244],half [5244,1024],float [1024],float [1,1024],float [],float [],float [1024,512],float [512],float [1,512],float [512,256],float [256],float [1,256],float [256,128],float [128],float [1,128],float [128,64],float [64],float [1,64],float [64,2],float [2]; Tensor<type: int32 shape: [1] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 07:52:31.787893: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_6[_XlaCompiledKernel=true,_XlaNumConstantArgs=1,_XlaNumResourceArgs=0],float [200,5244],float [1,5244],half [5244,1024],float [1024],float [1,1024],float [],float [],float [1024,512],float [512],float [1,512],float [512,256],float [256],float [1,256],float [256,128],float [128],float [1,128],float [128,64],float [64],float [1,64],float [64,2],float [2]; Tensor<type: int32 shape: [1] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 07:52:32.471882: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_7[_XlaCompiledKernel=true,_XlaNumConstantArgs=1,_XlaNumResourceArgs=0],float [200,2],float [200,2],float []; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 07:52:32.932285: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 200 has warmuped; cost us: 5381965
2022-08-04 07:52:32.950121: I tensorflow/core/kernels/blaze_xla_kernel.cc:80] blaze set thread pool size 2
2022-08-04 07:52:32.950345: I tensorflow/core/kernels/blaze_xla_kernel.cc:80] blaze set thread pool size 2
2022-08-04 07:52:32.950354: I tensorflow/core/kernels/blaze_xla_kernel.cc:88] blaze max waiting count 10
2022-08-04 07:52:32.950444: I tensorflow/core/kernels/blaze_xla_kernel.cc:155] Parse blaze options succ warmup_batchsize: 200
xla_compilation: true
gemm_optimization: true
auto_mixed_precision: true
no_warmup_inputs: "att_ncomm2"
no_warmup_inputs: "att_ncomm3"
no_warmup_inputs: "cross_long1"
no_warmup_inputs: "cross_long2"
no_warmup_inputs: "model_route_index"
config_proto {
  graph_options {
    rewrite_options {
      auto_mixed_precision: OFF
      gemm_optimization: ON
    }
  }
  force_run_in_caller_thread: true
  enable_graph_opt_place: true
}
wait_ms: 20

[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:317] Error parsing text-format tensorflow.GraphDef: 2:1: Expected identifier, got: 6
[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/io/zero_copy_stream_impl_lite.cc:155] Cannot allocate buffer larger than kint32max for StringOutputStream.
2022-08-04 07:52:40.671909: I tensorflow/core/kernels/blaze_xla_kernel.cc:100] Blaze create with options warmup_batchsize: 200
xla_compilation: true
gemm_optimization: true
auto_mixed_precision: true
no_warmup_inputs: "att_ncomm2"
no_warmup_inputs: "att_ncomm3"
no_warmup_inputs: "cross_long1"
no_warmup_inputs: "cross_long2"
no_warmup_inputs: "model_route_index"
config_proto {
  gpu_options {
    allow_growth: true
  }
  allow_soft_placement: true
  graph_options {
    rewrite_options {
      auto_mixed_precision: OFF
      gemm_optimization: ON
    }
  }
  force_run_in_caller_thread: true
  enable_graph_opt_place: true
}
wait_ms: 20

2022-08-04 07:52:40.923116: I tensorflow/core/kernels/blaze_predictor.cc:110] create session with config gpu_options {
  allow_growth: true
  visible_device_list: "0"
  experimental {
    virtual_devices {
      memory_limit_mb: 12288
      memory_limit_mb: 12288
      memory_limit_mb: 12288
      memory_limit_mb: 12288
    }
  }
}
allow_soft_placement: true
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    auto_mixed_precision: OFF
    gemm_optimization: ON
  }
}
enable_graph_opt_place: true
is_blaze: true

2022-08-04 07:52:40.939216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1642] Found device 0 with properties: 
name: NVIDIA A100-SXM4-80GB major: 8 minor: 0 memoryClockRate(GHz): 1.41
pciBusID: 0000:54:00.0
2022-08-04 07:52:40.939244: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-08-04 07:52:40.939256: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-08-04 07:52:40.939263: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-08-04 07:52:40.939271: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-08-04 07:52:40.939278: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2022-08-04 07:52:40.939286: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-08-04 07:52:40.939293: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-08-04 07:52:40.945599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1770] Adding visible gpu devices: 0
2022-08-04 07:52:40.945636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-08-04 07:52:40.945641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2022-08-04 07:52:40.945645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2022-08-04 07:52:40.961973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 07:52:40.965245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 07:52:40.968514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 07:52:40.971589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 07:52:40.971642: I tensorflow/core/kernels/blaze_predictor.cc:119] Blaze start with step id 1024
2022-08-04 07:52:40.971647: I tensorflow/core/kernels/blaze_predictor.cc:120] Creat session succ 0x556cb2be5550
2022-08-04 07:52:40.971654: I tensorflow/core/kernels/blaze_predictor.cc:73] BlazePredictor will use device /job:localhost/replica:0/task:0/device:GPU:1
2022-08-04 07:52:43.011182: I tensorflow/core/common_runtime/placer.cc:128] Allow optimize placer
2022-08-04 07:52:43.018649: I tensorflow/core/kernels/blaze_predictor.cc:92] create session with callable options feed: "comm"
feed: "att_comm2"
feed: "att_comm3"
feed: "ncomm"
feed: "model_route_index"
feed: "att_ncomm"
feed: "att_comm"
feed: "cross_long0"
feed: "cross_long1"
feed: "cross_global0"
feed: "cross_global1"
feed: "cross_long2"
feed: "cross_cr"
feed: "att_ncomm2"
feed: "nick_cate_indicators"
fetch: "add"
feed_devices {
  key: "att_comm"
  value: "/job:localhost/replica:0/task:0/device:GPU:1"
}
feed_devices {
  key: "att_comm2"
  value: "/job:localhost/replica:0/task:0/device:GPU:1"
}
feed_devices {
  key: "att_comm3"
  value: "/job:localhost/replica:0/task:0/device:GPU:1"
}
feed_devices {
  key: "att_ncomm"
  value: "/job:localhost/replica:0/task:0/device:GPU:1"
}
feed_devices {
  key: "att_ncomm2"
  value: "/job:localhost/replica:0/task:0/device:GPU:1"
}
feed_devices {
  key: "comm"
  value: "/job:localhost/replica:0/task:0/device:GPU:1"
}
feed_devices {
  key: "cross_cr"
  value: "/job:localhost/replica:0/task:0/device:GPU:1"
}
feed_devices {
  key: "cross_global0"
  value: "/job:localhost/replica:0/task:0/device:GPU:1"
}
feed_devices {
  key: "cross_global1"
  value: "/job:localhost/replica:0/task:0/device:GPU:1"
}
feed_devices {
  key: "cross_long0"
  value: "/job:localhost/replica:0/task:0/device:GPU:1"
}
feed_devices {
  key: "cross_long1"
  value: "/job:localhost/replica:0/task:0/device:GPU:1"
}
feed_devices {
  key: "cross_long2"
  value: "/job:localhost/replica:0/task:0/device:GPU:1"
}
feed_devices {
  key: "model_route_index"
  value: "/job:localhost/replica:0/task:0/device:GPU:1"
}
feed_devices {
  key: "ncomm"
  value: "/job:localhost/replica:0/task:0/device:GPU:1"
}
feed_devices {
  key: "nick_cate_indicators"
  value: "/job:localhost/replica:0/task:0/device:GPU:1"
}
fetch_devices {
  key: "add"
  value: "/job:localhost/replica:0/task:0/device:GPU:1"
}
fetch_skip_sync: true

2022-08-04 07:52:51.391651: I tensorflow/compiler/jit/build_xla_ops_pass.cc:398] enable_xla_auto_padding=0
2022-08-04 07:52:51.391687: I tensorflow/compiler/jit/build_xla_ops_pass.cc:404] auto_padding_shape 
2022-08-04 07:52:51.392219: I tensorflow/compiler/jit/build_xla_ops_pass.cc:398] enable_xla_auto_padding=0
2022-08-04 07:52:51.392227: I tensorflow/compiler/jit/build_xla_ops_pass.cc:404] auto_padding_shape 
2022-08-04 07:52:51.392742: I tensorflow/compiler/jit/build_xla_ops_pass.cc:398] enable_xla_auto_padding=0
2022-08-04 07:52:51.392750: I tensorflow/compiler/jit/build_xla_ops_pass.cc:404] auto_padding_shape 
2022-08-04 07:52:51.393222: I tensorflow/compiler/jit/build_xla_ops_pass.cc:398] enable_xla_auto_padding=0
2022-08-04 07:52:51.393229: I tensorflow/compiler/jit/build_xla_ops_pass.cc:404] auto_padding_shape 
2022-08-04 07:52:51.393690: I tensorflow/compiler/jit/build_xla_ops_pass.cc:398] enable_xla_auto_padding=0
2022-08-04 07:52:51.393695: I tensorflow/compiler/jit/build_xla_ops_pass.cc:404] auto_padding_shape 
2022-08-04 07:52:51.394138: I tensorflow/compiler/jit/build_xla_ops_pass.cc:398] enable_xla_auto_padding=0
2022-08-04 07:52:51.394143: I tensorflow/compiler/jit/build_xla_ops_pass.cc:404] auto_padding_shape 
2022-08-04 07:52:51.394581: I tensorflow/compiler/jit/build_xla_ops_pass.cc:398] enable_xla_auto_padding=0
2022-08-04 07:52:51.394586: I tensorflow/compiler/jit/build_xla_ops_pass.cc:404] auto_padding_shape 
2022-08-04 07:52:52.046672: I tensorflow/core/kernels/blaze_predictor.cc:132] MakeCallable succ 0x556cb2be5550
2022-08-04 07:52:52.046710: I tensorflow/core/kernels/blaze_predictor.cc:205] req_dev: /device:CPU:0; blaze_dev: /device:GPU:1
2022-08-04 07:52:52.049740: I tensorflow/core/kernels/blaze_xla_predictor.cc:367] Begin warmup
2022-08-04 07:52:52.049875: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 200
2022-08-04 07:52:52.265772: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_2[_XlaCompiledKernel=true,_XlaNumConstantArgs=9,_XlaNumResourceArgs=0],half [1,1000],half [1,18000],half [1,4500]; Tensor<type: int32 shape: [4] values: 6 150 4...>; Tensor<type: int32 shape: [4] values: 1 50 4...>; Tensor<type: int32 shape: [4] values: 3 150 2...>; Tensor<type: int32 shape: [4] values: 2 0 1...>; Tensor<type: int32 shape: [3] values: 24 150 5>; Tensor<type: int32 shape: [4] values: 1 4 50...>; Tensor<type: int32 shape: [3] values: 6 150 5>; Tensor<type: int32 shape: [] values: 0>; Tensor<type: int32 shape: [4] values: 1 30 150...> with request count 1 and compile threshold 0 shape info=0
2022-08-04 07:52:52.269541: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:329] RunBackend() - Will load PTX from file: ./xla_cache/4695837893004515636.ptx
2022-08-04 07:52:52.269616: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-08-04 07:52:52.270013: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_1[_XlaCompiledKernel=true,_XlaNumConstantArgs=32,_XlaNumResourceArgs=0],half [200,1852],half [200,1040]; Tensor<type: int32 shape: [2] values: 0 0>; Tensor<type: int32 shape: [2] values: 0 800>; Tensor<type: int32 shape: [2] values: 1 1>; Tensor<type: int32 shape: [2] values: 0 1040>; Tensor<type: int32 shape: [2] values: 0 48>; Tensor<type: int32 shape: [2] values: 0 64>; Tensor<type: int32 shape: [2] values: 0 80>; Tensor<type: int32 shape: [2] values: 0 96>; Tensor<type: int32 shape: [2] values: 0 112>; Tensor<type: int32 shape: [2] values: 0 160>; Tensor<type: int32 shape: [2] values: 0 176>; Tensor<type: int32 shape: [2] values: 0 144>; Tensor<type: int32 shape: [3] values: -1 4 200>; Tensor<type: int32 shape: [5] values: -1 2 6...>; Tensor<type: int32 shape: [] values: 1>; Tensor<type: int32 shape: [3] values: 0 0 0>; Tensor<type: int32 shape: [3] values: 0 0 180>; Tensor<type: int32 shape: [3] values: 1 1 1>; Tensor<type: int32 shape: [5] values: 0 0 0...>; Tensor<type: int32 shape: [5] values: 0 0 3...>; Tensor<type: int32 shape: [5] values: 1 1 1...>; Tensor<type: int32 shape: [5] values: 0 0 6...>; Tensor<type: int32 shape: [5] values: -1 4 9...>; Tensor<type: int32 shape: [4] values: -1 6 5...>; Tensor<type: int32 shape: [5] values: 0 0 7...>; Tensor<type: int32 shape: [5] values: 0 0 9...>; Tensor<type: int32 shape: [3] values: 8 0 0>; Tensor<type: int32 shape: [3] values: 12 0 0>; Tensor<type: int32 shape: [4] values: -1 24 5...>; Tensor<type: int32 shape: [4] values: -1 4 5...>; Tensor<type: int32 shape: [4] values: -1 8 5...>; Tensor<type: int32 shape: [4] values: 4 -1 1...> with request count 1 and compile threshold 0 shape info=0
2022-08-04 07:52:52.283784: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:329] RunBackend() - Will load PTX from file: ./xla_cache/10153300373092785533.ptx
2022-08-04 07:52:52.283915: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-08-04 07:52:52.699859: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_4[_XlaCompiledKernel=true,_XlaNumConstantArgs=1,_XlaNumResourceArgs=0],float [4,200,200,1]; Tensor<type: int32 shape: [4] values: 0 1 3...> with request count 1 and compile threshold 0 shape info=0
2022-08-04 07:52:52.749158: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-08-04 07:52:52.749841: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=52,_XlaNumResourceArgs=0],float [200,96],float [16,200,24],float [200,4,2,4],float [200,30,2,4],float [200,14,2,4],float [4,200,24,1],float [200,1852],float [200,96],half [1,1728],half [1,4800],half [1,19200],half [1,4800],half [1,38400]; Tensor<type: int32 shape: [4] values: 2 8 150...>; Tensor<type: int32 shape: [3] values: 6 50 16>; Tensor<type: int32 shape: [3] values: 6 200 16>; Tensor<type: int32 shape: [4] values: 0 2 1...>; Tensor<type: int32 shape: [3] values: 1 0 2>; Tensor<type: int32 shape: [3] values: 2 150 128>; Tensor<type: int32 shape: [3] values: 1 50 96>; Tensor<type: int32 shape: [3] values: 1 200 96>; Tensor<type: int32 shape: [1] values: 0>; Tensor<type: int32 shape: [1] values: 1>; Tensor<type: int32 shape: [1] values: 2>; Tensor<type: int32 shape: [3] values: 16 0 0>; Tensor<type: int32 shape: [4] values: 1 200 4...>; Tensor<type: int32 shape: [2] values: 200 1>; Tensor<type: int32 shape: [4] values: 2 50 4...>; Tensor<type: int32 shape: [3] values: 4 200 24>; Tensor<type: int32 shape: [3] values: -1 4 8>; Tensor<type: int32 shape: [4] values: 2 150 4...>; Tensor<type: int32 shape: [3] values: 8 50 24>; Tensor<type: int32 shape: [3] values: -1 30 8>; Tensor<type: int32 shape: [3] values: 0 1 0>; Tensor<type: int32 shape: [3] values: 0 2 0>; Tensor<type: int32 shape: [3] values: 0 3 0>; Tensor<type: int32 shape: [3] values: -1 14 8>; Tensor<type: int32 shape: [3] values: 0 6 0>; Tensor<type: int32 shape: [3] values: 0 12 0>; Tensor<type: int32 shape: [3] values: 0 18 0>; Tensor<type: int32 shape: [3] values: 0 24 0>; Tensor<type: int32 shape: [3] values: 0 27 0>; Tensor<type: int32 shape: [3] values: 0 4 0>; Tensor<type: int32 shape: [3] values: 0 8 0>; Tensor<type: int32 shape: [3] values: 0 11 0>; Tensor<type: int32 shape: [3] values: 8 150 32>; Tensor<type: int32 shape: [2] values: -1 384>; Tensor<type: int32 shape: [4] values: 1 4 -1...>; Tensor<type: int32 shape: [4] values: 1 0 2...>; Tensor<type: int32 shape: [4] values: 2 4 -1...>; Tensor<type: int32 shape: [2] values: -1 96>; Tensor<type: int32 shape: [4] values: 2 4 -1...>; Tensor<type: int32 shape: [2] values: -1 192>; Tensor<type: int32 shape: [2] values: 0 -96>; Tensor<type: int32 shape: [2] values: -1 256>; Tensor<type: int32 shape: [2] values: 0 0>; Tensor<type: int32 shape: [2] values: 0 96>; Tensor<type: int32 shape: [2] values: 1 1>; Tensor<type: int32 shape: [3] values: 1 1 1>; Tensor<type: int32 shape: [3] values: 8 0 0>; Tensor<type: int32 shape: [3] values: 0 0 0>; Tensor<type: int32 shape: [] values: 0>; Tensor<type: int32 shape: [4] values: 2 0 1...>; Tensor<type: int32 shape: [] values: 1>; Tensor<type: int32 shape: [3] values: 12 0 0> with request count 1 and compile threshold 0 shape info=0
2022-08-04 07:52:53.996669: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_5[_XlaCompiledKernel=true,_XlaNumConstantArgs=1,_XlaNumResourceArgs=0],float [200,5244],float [1,5244],half [5244,1024],float [1024],float [1,1024],float [],float [],float [1024,512],float [512],float [1,512],float [512,256],float [256],float [1,256],float [256,128],float [128],float [1,128],float [128,64],float [64],float [1,64],float [64,2],float [2]; Tensor<type: int32 shape: [1] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 07:52:54.811550: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_6[_XlaCompiledKernel=true,_XlaNumConstantArgs=1,_XlaNumResourceArgs=0],float [200,5244],float [1,5244],half [5244,1024],float [1024],float [1,1024],float [],float [],float [1024,512],float [512],float [1,512],float [512,256],float [256],float [1,256],float [256,128],float [128],float [1,128],float [128,64],float [64],float [1,64],float [64,2],float [2]; Tensor<type: int32 shape: [1] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 07:52:55.598895: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_7[_XlaCompiledKernel=true,_XlaNumConstantArgs=1,_XlaNumResourceArgs=0],float [200,2],float [200,2],float []; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 07:52:55.642116: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-08-04 07:52:55.642901: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 200 has warmuped; cost us: 3593014
2022-08-04 07:52:55.660150: I tensorflow/core/kernels/blaze_xla_kernel.cc:80] blaze set thread pool size 2
2022-08-04 07:52:55.660353: I tensorflow/core/kernels/blaze_xla_kernel.cc:80] blaze set thread pool size 2
2022-08-04 07:52:55.660361: I tensorflow/core/kernels/blaze_xla_kernel.cc:88] blaze max waiting count 10
2022-08-04 07:52:55.660447: I tensorflow/core/kernels/blaze_xla_kernel.cc:155] Parse blaze options succ warmup_batchsize: 200
xla_compilation: true
gemm_optimization: true
auto_mixed_precision: true
no_warmup_inputs: "att_ncomm2"
no_warmup_inputs: "att_ncomm3"
no_warmup_inputs: "cross_long1"
no_warmup_inputs: "cross_long2"
no_warmup_inputs: "model_route_index"
config_proto {
  graph_options {
    rewrite_options {
      auto_mixed_precision: OFF
      gemm_optimization: ON
    }
  }
  force_run_in_caller_thread: true
  enable_graph_opt_place: true
}
wait_ms: 20

[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:317] Error parsing text-format tensorflow.GraphDef: 2:1: Expected identifier, got: 6
[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/io/zero_copy_stream_impl_lite.cc:155] Cannot allocate buffer larger than kint32max for StringOutputStream.
2022-08-04 07:53:03.277837: I tensorflow/core/kernels/blaze_xla_kernel.cc:100] Blaze create with options warmup_batchsize: 200
xla_compilation: true
gemm_optimization: true
auto_mixed_precision: true
no_warmup_inputs: "att_ncomm2"
no_warmup_inputs: "att_ncomm3"
no_warmup_inputs: "cross_long1"
no_warmup_inputs: "cross_long2"
no_warmup_inputs: "model_route_index"
config_proto {
  gpu_options {
    allow_growth: true
  }
  allow_soft_placement: true
  graph_options {
    rewrite_options {
      auto_mixed_precision: OFF
      gemm_optimization: ON
    }
  }
  force_run_in_caller_thread: true
  enable_graph_opt_place: true
}
wait_ms: 20

2022-08-04 07:53:03.581297: I tensorflow/core/kernels/blaze_predictor.cc:110] create session with config gpu_options {
  allow_growth: true
  visible_device_list: "0"
  experimental {
    virtual_devices {
      memory_limit_mb: 12288
      memory_limit_mb: 12288
      memory_limit_mb: 12288
      memory_limit_mb: 12288
    }
  }
}
allow_soft_placement: true
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    auto_mixed_precision: OFF
    gemm_optimization: ON
  }
}
enable_graph_opt_place: true
is_blaze: true

2022-08-04 07:53:03.584838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1642] Found device 0 with properties: 
name: NVIDIA A100-SXM4-80GB major: 8 minor: 0 memoryClockRate(GHz): 1.41
pciBusID: 0000:54:00.0
2022-08-04 07:53:03.584865: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-08-04 07:53:03.584872: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-08-04 07:53:03.584879: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-08-04 07:53:03.584884: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-08-04 07:53:03.584889: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2022-08-04 07:53:03.584894: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-08-04 07:53:03.584899: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-08-04 07:53:03.615696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1770] Adding visible gpu devices: 0
2022-08-04 07:53:03.615728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-08-04 07:53:03.615733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2022-08-04 07:53:03.615737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2022-08-04 07:53:03.631742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 07:53:03.634984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 07:53:03.638236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 07:53:03.641735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 07:53:03.641784: I tensorflow/core/kernels/blaze_predictor.cc:119] Blaze start with step id 1024
2022-08-04 07:53:03.641789: I tensorflow/core/kernels/blaze_predictor.cc:120] Creat session succ 0x556f4e0ba000
2022-08-04 07:53:03.641798: I tensorflow/core/kernels/blaze_predictor.cc:73] BlazePredictor will use device /job:localhost/replica:0/task:0/device:GPU:2
2022-08-04 07:53:05.925874: I tensorflow/core/common_runtime/placer.cc:128] Allow optimize placer
2022-08-04 07:53:05.934290: I tensorflow/core/kernels/blaze_predictor.cc:92] create session with callable options feed: "comm"
feed: "att_comm2"
feed: "att_comm3"
feed: "ncomm"
feed: "model_route_index"
feed: "att_ncomm"
feed: "att_comm"
feed: "cross_long0"
feed: "cross_long1"
feed: "cross_global0"
feed: "cross_global1"
feed: "cross_long2"
feed: "cross_cr"
feed: "att_ncomm2"
feed: "nick_cate_indicators"
fetch: "add"
feed_devices {
  key: "att_comm"
  value: "/job:localhost/replica:0/task:0/device:GPU:2"
}
feed_devices {
  key: "att_comm2"
  value: "/job:localhost/replica:0/task:0/device:GPU:2"
}
feed_devices {
  key: "att_comm3"
  value: "/job:localhost/replica:0/task:0/device:GPU:2"
}
feed_devices {
  key: "att_ncomm"
  value: "/job:localhost/replica:0/task:0/device:GPU:2"
}
feed_devices {
  key: "att_ncomm2"
  value: "/job:localhost/replica:0/task:0/device:GPU:2"
}
feed_devices {
  key: "comm"
  value: "/job:localhost/replica:0/task:0/device:GPU:2"
}
feed_devices {
  key: "cross_cr"
  value: "/job:localhost/replica:0/task:0/device:GPU:2"
}
feed_devices {
  key: "cross_global0"
  value: "/job:localhost/replica:0/task:0/device:GPU:2"
}
feed_devices {
  key: "cross_global1"
  value: "/job:localhost/replica:0/task:0/device:GPU:2"
}
feed_devices {
  key: "cross_long0"
  value: "/job:localhost/replica:0/task:0/device:GPU:2"
}
feed_devices {
  key: "cross_long1"
  value: "/job:localhost/replica:0/task:0/device:GPU:2"
}
feed_devices {
  key: "cross_long2"
  value: "/job:localhost/replica:0/task:0/device:GPU:2"
}
feed_devices {
  key: "model_route_index"
  value: "/job:localhost/replica:0/task:0/device:GPU:2"
}
feed_devices {
  key: "ncomm"
  value: "/job:localhost/replica:0/task:0/device:GPU:2"
}
feed_devices {
  key: "nick_cate_indicators"
  value: "/job:localhost/replica:0/task:0/device:GPU:2"
}
fetch_devices {
  key: "add"
  value: "/job:localhost/replica:0/task:0/device:GPU:2"
}
fetch_skip_sync: true

2022-08-04 07:53:14.935061: I tensorflow/compiler/jit/build_xla_ops_pass.cc:398] enable_xla_auto_padding=0
2022-08-04 07:53:14.935099: I tensorflow/compiler/jit/build_xla_ops_pass.cc:404] auto_padding_shape 
2022-08-04 07:53:14.935720: I tensorflow/compiler/jit/build_xla_ops_pass.cc:398] enable_xla_auto_padding=0
2022-08-04 07:53:14.935730: I tensorflow/compiler/jit/build_xla_ops_pass.cc:404] auto_padding_shape 
2022-08-04 07:53:14.936233: I tensorflow/compiler/jit/build_xla_ops_pass.cc:398] enable_xla_auto_padding=0
2022-08-04 07:53:14.936240: I tensorflow/compiler/jit/build_xla_ops_pass.cc:404] auto_padding_shape 
2022-08-04 07:53:14.936718: I tensorflow/compiler/jit/build_xla_ops_pass.cc:398] enable_xla_auto_padding=0
2022-08-04 07:53:14.936726: I tensorflow/compiler/jit/build_xla_ops_pass.cc:404] auto_padding_shape 
2022-08-04 07:53:14.937192: I tensorflow/compiler/jit/build_xla_ops_pass.cc:398] enable_xla_auto_padding=0
2022-08-04 07:53:14.937198: I tensorflow/compiler/jit/build_xla_ops_pass.cc:404] auto_padding_shape 
2022-08-04 07:53:14.937659: I tensorflow/compiler/jit/build_xla_ops_pass.cc:398] enable_xla_auto_padding=0
2022-08-04 07:53:14.937665: I tensorflow/compiler/jit/build_xla_ops_pass.cc:404] auto_padding_shape 
2022-08-04 07:53:14.938086: I tensorflow/compiler/jit/build_xla_ops_pass.cc:398] enable_xla_auto_padding=0
2022-08-04 07:53:14.938091: I tensorflow/compiler/jit/build_xla_ops_pass.cc:404] auto_padding_shape 
2022-08-04 07:53:15.621061: I tensorflow/core/kernels/blaze_predictor.cc:132] MakeCallable succ 0x556f4e0ba000
2022-08-04 07:53:15.621102: I tensorflow/core/kernels/blaze_predictor.cc:205] req_dev: /device:CPU:0; blaze_dev: /device:GPU:2
2022-08-04 07:53:15.623317: I tensorflow/core/kernels/blaze_xla_predictor.cc:367] Begin warmup
2022-08-04 07:53:15.623469: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 200
2022-08-04 07:53:15.870001: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_2[_XlaCompiledKernel=true,_XlaNumConstantArgs=9,_XlaNumResourceArgs=0],half [1,1000],half [1,18000],half [1,4500]; Tensor<type: int32 shape: [4] values: 6 150 4...>; Tensor<type: int32 shape: [4] values: 1 50 4...>; Tensor<type: int32 shape: [4] values: 3 150 2...>; Tensor<type: int32 shape: [4] values: 2 0 1...>; Tensor<type: int32 shape: [3] values: 24 150 5>; Tensor<type: int32 shape: [4] values: 1 4 50...>; Tensor<type: int32 shape: [3] values: 6 150 5>; Tensor<type: int32 shape: [] values: 0>; Tensor<type: int32 shape: [4] values: 1 30 150...> with request count 1 and compile threshold 0 shape info=0
2022-08-04 07:53:15.873704: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:329] RunBackend() - Will load PTX from file: ./xla_cache/4695837893004515636.ptx
2022-08-04 07:53:15.873784: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-08-04 07:53:15.874154: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_1[_XlaCompiledKernel=true,_XlaNumConstantArgs=32,_XlaNumResourceArgs=0],half [200,1852],half [200,1040]; Tensor<type: int32 shape: [2] values: 0 0>; Tensor<type: int32 shape: [2] values: 0 800>; Tensor<type: int32 shape: [2] values: 1 1>; Tensor<type: int32 shape: [2] values: 0 1040>; Tensor<type: int32 shape: [2] values: 0 48>; Tensor<type: int32 shape: [2] values: 0 64>; Tensor<type: int32 shape: [2] values: 0 80>; Tensor<type: int32 shape: [2] values: 0 96>; Tensor<type: int32 shape: [2] values: 0 112>; Tensor<type: int32 shape: [2] values: 0 160>; Tensor<type: int32 shape: [2] values: 0 176>; Tensor<type: int32 shape: [2] values: 0 144>; Tensor<type: int32 shape: [3] values: -1 4 200>; Tensor<type: int32 shape: [5] values: -1 2 6...>; Tensor<type: int32 shape: [] values: 1>; Tensor<type: int32 shape: [3] values: 0 0 0>; Tensor<type: int32 shape: [3] values: 0 0 180>; Tensor<type: int32 shape: [3] values: 1 1 1>; Tensor<type: int32 shape: [5] values: 0 0 0...>; Tensor<type: int32 shape: [5] values: 0 0 3...>; Tensor<type: int32 shape: [5] values: 1 1 1...>; Tensor<type: int32 shape: [5] values: 0 0 6...>; Tensor<type: int32 shape: [5] values: -1 4 9...>; Tensor<type: int32 shape: [4] values: -1 6 5...>; Tensor<type: int32 shape: [5] values: 0 0 7...>; Tensor<type: int32 shape: [5] values: 0 0 9...>; Tensor<type: int32 shape: [3] values: 8 0 0>; Tensor<type: int32 shape: [3] values: 12 0 0>; Tensor<type: int32 shape: [4] values: -1 24 5...>; Tensor<type: int32 shape: [4] values: -1 4 5...>; Tensor<type: int32 shape: [4] values: -1 8 5...>; Tensor<type: int32 shape: [4] values: 4 -1 1...> with request count 1 and compile threshold 0 shape info=0
2022-08-04 07:53:15.887983: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:329] RunBackend() - Will load PTX from file: ./xla_cache/10153300373092785533.ptx
2022-08-04 07:53:15.888107: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-08-04 07:53:16.332313: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_4[_XlaCompiledKernel=true,_XlaNumConstantArgs=1,_XlaNumResourceArgs=0],float [4,200,200,1]; Tensor<type: int32 shape: [4] values: 0 1 3...> with request count 1 and compile threshold 0 shape info=0
2022-08-04 07:53:16.380945: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-08-04 07:53:16.381661: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=52,_XlaNumResourceArgs=0],float [200,96],float [16,200,24],float [200,4,2,4],float [200,30,2,4],float [200,14,2,4],float [4,200,24,1],float [200,1852],float [200,96],half [1,1728],half [1,4800],half [1,19200],half [1,4800],half [1,38400]; Tensor<type: int32 shape: [4] values: 2 8 150...>; Tensor<type: int32 shape: [3] values: 6 50 16>; Tensor<type: int32 shape: [3] values: 6 200 16>; Tensor<type: int32 shape: [4] values: 0 2 1...>; Tensor<type: int32 shape: [3] values: 1 0 2>; Tensor<type: int32 shape: [3] values: 2 150 128>; Tensor<type: int32 shape: [3] values: 1 50 96>; Tensor<type: int32 shape: [3] values: 1 200 96>; Tensor<type: int32 shape: [1] values: 0>; Tensor<type: int32 shape: [1] values: 1>; Tensor<type: int32 shape: [1] values: 2>; Tensor<type: int32 shape: [3] values: 16 0 0>; Tensor<type: int32 shape: [4] values: 1 200 4...>; Tensor<type: int32 shape: [2] values: 200 1>; Tensor<type: int32 shape: [4] values: 2 50 4...>; Tensor<type: int32 shape: [3] values: 4 200 24>; Tensor<type: int32 shape: [3] values: -1 4 8>; Tensor<type: int32 shape: [4] values: 2 150 4...>; Tensor<type: int32 shape: [3] values: 8 50 24>; Tensor<type: int32 shape: [3] values: -1 30 8>; Tensor<type: int32 shape: [3] values: 0 1 0>; Tensor<type: int32 shape: [3] values: 0 2 0>; Tensor<type: int32 shape: [3] values: 0 3 0>; Tensor<type: int32 shape: [3] values: -1 14 8>; Tensor<type: int32 shape: [3] values: 0 6 0>; Tensor<type: int32 shape: [3] values: 0 12 0>; Tensor<type: int32 shape: [3] values: 0 18 0>; Tensor<type: int32 shape: [3] values: 0 24 0>; Tensor<type: int32 shape: [3] values: 0 27 0>; Tensor<type: int32 shape: [3] values: 0 4 0>; Tensor<type: int32 shape: [3] values: 0 8 0>; Tensor<type: int32 shape: [3] values: 0 11 0>; Tensor<type: int32 shape: [3] values: 8 150 32>; Tensor<type: int32 shape: [2] values: -1 384>; Tensor<type: int32 shape: [4] values: 1 4 -1...>; Tensor<type: int32 shape: [4] values: 1 0 2...>; Tensor<type: int32 shape: [4] values: 2 4 -1...>; Tensor<type: int32 shape: [2] values: -1 96>; Tensor<type: int32 shape: [4] values: 2 4 -1...>; Tensor<type: int32 shape: [2] values: -1 192>; Tensor<type: int32 shape: [2] values: 0 -96>; Tensor<type: int32 shape: [2] values: -1 256>; Tensor<type: int32 shape: [2] values: 0 0>; Tensor<type: int32 shape: [2] values: 0 96>; Tensor<type: int32 shape: [2] values: 1 1>; Tensor<type: int32 shape: [3] values: 1 1 1>; Tensor<type: int32 shape: [3] values: 8 0 0>; Tensor<type: int32 shape: [3] values: 0 0 0>; Tensor<type: int32 shape: [] values: 0>; Tensor<type: int32 shape: [4] values: 2 0 1...>; Tensor<type: int32 shape: [] values: 1>; Tensor<type: int32 shape: [3] values: 12 0 0> with request count 1 and compile threshold 0 shape info=0
2022-08-04 07:53:17.635351: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_5[_XlaCompiledKernel=true,_XlaNumConstantArgs=1,_XlaNumResourceArgs=0],float [200,5244],float [1,5244],half [5244,1024],float [1024],float [1,1024],float [],float [],float [1024,512],float [512],float [1,512],float [512,256],float [256],float [1,256],float [256,128],float [128],float [1,128],float [128,64],float [64],float [1,64],float [64,2],float [2]; Tensor<type: int32 shape: [1] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 07:53:17.792215: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-08-04 07:53:17.795357: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_6[_XlaCompiledKernel=true,_XlaNumConstantArgs=1,_XlaNumResourceArgs=0],float [200,5244],float [1,5244],half [5244,1024],float [1024],float [1,1024],float [],float [],float [1024,512],float [512],float [1,512],float [512,256],float [256],float [1,256],float [256,128],float [128],float [1,128],float [128,64],float [64],float [1,64],float [64,2],float [2]; Tensor<type: int32 shape: [1] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 07:53:17.947131: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-08-04 07:53:17.948898: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_7[_XlaCompiledKernel=true,_XlaNumConstantArgs=1,_XlaNumResourceArgs=0],float [200,2],float [200,2],float []; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 07:53:17.988143: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-08-04 07:53:17.988786: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 200 has warmuped; cost us: 2365304
2022-08-04 07:53:18.006019: I tensorflow/core/kernels/blaze_xla_kernel.cc:80] blaze set thread pool size 2
2022-08-04 07:53:18.006250: I tensorflow/core/kernels/blaze_xla_kernel.cc:80] blaze set thread pool size 2
2022-08-04 07:53:18.006258: I tensorflow/core/kernels/blaze_xla_kernel.cc:88] blaze max waiting count 10
2022-08-04 07:53:18.006335: I tensorflow/core/kernels/blaze_xla_kernel.cc:155] Parse blaze options succ warmup_batchsize: 200
xla_compilation: true
gemm_optimization: true
auto_mixed_precision: true
no_warmup_inputs: "att_ncomm2"
no_warmup_inputs: "att_ncomm3"
no_warmup_inputs: "cross_long1"
no_warmup_inputs: "cross_long2"
no_warmup_inputs: "model_route_index"
config_proto {
  graph_options {
    rewrite_options {
      auto_mixed_precision: OFF
      gemm_optimization: ON
    }
  }
  force_run_in_caller_thread: true
  enable_graph_opt_place: true
}
wait_ms: 20

[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/text_format.cc:317] Error parsing text-format tensorflow.GraphDef: 2:1: Expected identifier, got: 6
[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/io/zero_copy_stream_impl_lite.cc:155] Cannot allocate buffer larger than kint32max for StringOutputStream.
2022-08-04 07:53:25.563419: I tensorflow/core/kernels/blaze_xla_kernel.cc:100] Blaze create with options warmup_batchsize: 200
xla_compilation: true
gemm_optimization: true
auto_mixed_precision: true
no_warmup_inputs: "att_ncomm2"
no_warmup_inputs: "att_ncomm3"
no_warmup_inputs: "cross_long1"
no_warmup_inputs: "cross_long2"
no_warmup_inputs: "model_route_index"
config_proto {
  gpu_options {
    allow_growth: true
  }
  allow_soft_placement: true
  graph_options {
    rewrite_options {
      auto_mixed_precision: OFF
      gemm_optimization: ON
    }
  }
  force_run_in_caller_thread: true
  enable_graph_opt_place: true
}
wait_ms: 20

2022-08-04 07:53:25.823997: I tensorflow/core/kernels/blaze_predictor.cc:110] create session with config gpu_options {
  allow_growth: true
  visible_device_list: "0"
  experimental {
    virtual_devices {
      memory_limit_mb: 12288
      memory_limit_mb: 12288
      memory_limit_mb: 12288
      memory_limit_mb: 12288
    }
  }
}
allow_soft_placement: true
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    auto_mixed_precision: OFF
    gemm_optimization: ON
  }
}
enable_graph_opt_place: true
is_blaze: true

2022-08-04 07:53:25.827581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1642] Found device 0 with properties: 
name: NVIDIA A100-SXM4-80GB major: 8 minor: 0 memoryClockRate(GHz): 1.41
pciBusID: 0000:54:00.0
2022-08-04 07:53:25.827607: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2022-08-04 07:53:25.827613: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-08-04 07:53:25.827619: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-08-04 07:53:25.827625: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-08-04 07:53:25.827630: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2022-08-04 07:53:25.827635: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2022-08-04 07:53:25.827640: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-08-04 07:53:25.831993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1770] Adding visible gpu devices: 0
2022-08-04 07:53:25.832027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-08-04 07:53:25.832032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2022-08-04 07:53:25.832036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2022-08-04 07:53:25.842906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 07:53:25.845107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 07:53:25.847291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 07:53:25.849480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1328] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 12288 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:54:00.0, compute capability: 8.0)
2022-08-04 07:53:25.849527: I tensorflow/core/kernels/blaze_predictor.cc:119] Blaze start with step id 1024
2022-08-04 07:53:25.849532: I tensorflow/core/kernels/blaze_predictor.cc:120] Creat session succ 0x556fe9fffd00
2022-08-04 07:53:25.849539: I tensorflow/core/kernels/blaze_predictor.cc:73] BlazePredictor will use device /job:localhost/replica:0/task:0/device:GPU:3
2022-08-04 07:53:27.799690: I tensorflow/core/common_runtime/placer.cc:128] Allow optimize placer
2022-08-04 07:53:27.807100: I tensorflow/core/kernels/blaze_predictor.cc:92] create session with callable options feed: "comm"
feed: "att_comm2"
feed: "att_comm3"
feed: "ncomm"
feed: "model_route_index"
feed: "att_ncomm"
feed: "att_comm"
feed: "cross_long0"
feed: "cross_long1"
feed: "cross_global0"
feed: "cross_global1"
feed: "cross_long2"
feed: "cross_cr"
feed: "att_ncomm2"
feed: "nick_cate_indicators"
fetch: "add"
feed_devices {
  key: "att_comm"
  value: "/job:localhost/replica:0/task:0/device:GPU:3"
}
feed_devices {
  key: "att_comm2"
  value: "/job:localhost/replica:0/task:0/device:GPU:3"
}
feed_devices {
  key: "att_comm3"
  value: "/job:localhost/replica:0/task:0/device:GPU:3"
}
feed_devices {
  key: "att_ncomm"
  value: "/job:localhost/replica:0/task:0/device:GPU:3"
}
feed_devices {
  key: "att_ncomm2"
  value: "/job:localhost/replica:0/task:0/device:GPU:3"
}
feed_devices {
  key: "comm"
  value: "/job:localhost/replica:0/task:0/device:GPU:3"
}
feed_devices {
  key: "cross_cr"
  value: "/job:localhost/replica:0/task:0/device:GPU:3"
}
feed_devices {
  key: "cross_global0"
  value: "/job:localhost/replica:0/task:0/device:GPU:3"
}
feed_devices {
  key: "cross_global1"
  value: "/job:localhost/replica:0/task:0/device:GPU:3"
}
feed_devices {
  key: "cross_long0"
  value: "/job:localhost/replica:0/task:0/device:GPU:3"
}
feed_devices {
  key: "cross_long1"
  value: "/job:localhost/replica:0/task:0/device:GPU:3"
}
feed_devices {
  key: "cross_long2"
  value: "/job:localhost/replica:0/task:0/device:GPU:3"
}
feed_devices {
  key: "model_route_index"
  value: "/job:localhost/replica:0/task:0/device:GPU:3"
}
feed_devices {
  key: "ncomm"
  value: "/job:localhost/replica:0/task:0/device:GPU:3"
}
feed_devices {
  key: "nick_cate_indicators"
  value: "/job:localhost/replica:0/task:0/device:GPU:3"
}
fetch_devices {
  key: "add"
  value: "/job:localhost/replica:0/task:0/device:GPU:3"
}
fetch_skip_sync: true

2022-08-04 07:53:36.096640: I tensorflow/compiler/jit/build_xla_ops_pass.cc:398] enable_xla_auto_padding=0
2022-08-04 07:53:36.096677: I tensorflow/compiler/jit/build_xla_ops_pass.cc:404] auto_padding_shape 
2022-08-04 07:53:36.097210: I tensorflow/compiler/jit/build_xla_ops_pass.cc:398] enable_xla_auto_padding=0
2022-08-04 07:53:36.097219: I tensorflow/compiler/jit/build_xla_ops_pass.cc:404] auto_padding_shape 
2022-08-04 07:53:36.097738: I tensorflow/compiler/jit/build_xla_ops_pass.cc:398] enable_xla_auto_padding=0
2022-08-04 07:53:36.097746: I tensorflow/compiler/jit/build_xla_ops_pass.cc:404] auto_padding_shape 
2022-08-04 07:53:36.098217: I tensorflow/compiler/jit/build_xla_ops_pass.cc:398] enable_xla_auto_padding=0
2022-08-04 07:53:36.098223: I tensorflow/compiler/jit/build_xla_ops_pass.cc:404] auto_padding_shape 
2022-08-04 07:53:36.098689: I tensorflow/compiler/jit/build_xla_ops_pass.cc:398] enable_xla_auto_padding=0
2022-08-04 07:53:36.098696: I tensorflow/compiler/jit/build_xla_ops_pass.cc:404] auto_padding_shape 
2022-08-04 07:53:36.099132: I tensorflow/compiler/jit/build_xla_ops_pass.cc:398] enable_xla_auto_padding=0
2022-08-04 07:53:36.099137: I tensorflow/compiler/jit/build_xla_ops_pass.cc:404] auto_padding_shape 
2022-08-04 07:53:36.099560: I tensorflow/compiler/jit/build_xla_ops_pass.cc:398] enable_xla_auto_padding=0
2022-08-04 07:53:36.099565: I tensorflow/compiler/jit/build_xla_ops_pass.cc:404] auto_padding_shape 
2022-08-04 07:53:36.809528: I tensorflow/core/kernels/blaze_predictor.cc:132] MakeCallable succ 0x556fe9fffd00
2022-08-04 07:53:36.809566: I tensorflow/core/kernels/blaze_predictor.cc:205] req_dev: /device:CPU:0; blaze_dev: /device:GPU:3
2022-08-04 07:53:36.811806: I tensorflow/core/kernels/blaze_xla_predictor.cc:367] Begin warmup
2022-08-04 07:53:36.811945: I tensorflow/core/kernels/blaze_xla_predictor.cc:109] begin warmup 200
2022-08-04 07:53:37.310848: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_2[_XlaCompiledKernel=true,_XlaNumConstantArgs=9,_XlaNumResourceArgs=0],half [1,1000],half [1,18000],half [1,4500]; Tensor<type: int32 shape: [4] values: 6 150 4...>; Tensor<type: int32 shape: [4] values: 1 50 4...>; Tensor<type: int32 shape: [4] values: 3 150 2...>; Tensor<type: int32 shape: [4] values: 2 0 1...>; Tensor<type: int32 shape: [3] values: 24 150 5>; Tensor<type: int32 shape: [4] values: 1 4 50...>; Tensor<type: int32 shape: [3] values: 6 150 5>; Tensor<type: int32 shape: [] values: 0>; Tensor<type: int32 shape: [4] values: 1 30 150...> with request count 1 and compile threshold 0 shape info=0
2022-08-04 07:53:37.314707: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:329] RunBackend() - Will load PTX from file: ./xla_cache/4695837893004515636.ptx
2022-08-04 07:53:37.314799: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-08-04 07:53:37.315251: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_1[_XlaCompiledKernel=true,_XlaNumConstantArgs=32,_XlaNumResourceArgs=0],half [200,1852],half [200,1040]; Tensor<type: int32 shape: [2] values: 0 0>; Tensor<type: int32 shape: [2] values: 0 800>; Tensor<type: int32 shape: [2] values: 1 1>; Tensor<type: int32 shape: [2] values: 0 1040>; Tensor<type: int32 shape: [2] values: 0 48>; Tensor<type: int32 shape: [2] values: 0 64>; Tensor<type: int32 shape: [2] values: 0 80>; Tensor<type: int32 shape: [2] values: 0 96>; Tensor<type: int32 shape: [2] values: 0 112>; Tensor<type: int32 shape: [2] values: 0 160>; Tensor<type: int32 shape: [2] values: 0 176>; Tensor<type: int32 shape: [2] values: 0 144>; Tensor<type: int32 shape: [3] values: -1 4 200>; Tensor<type: int32 shape: [5] values: -1 2 6...>; Tensor<type: int32 shape: [] values: 1>; Tensor<type: int32 shape: [3] values: 0 0 0>; Tensor<type: int32 shape: [3] values: 0 0 180>; Tensor<type: int32 shape: [3] values: 1 1 1>; Tensor<type: int32 shape: [5] values: 0 0 0...>; Tensor<type: int32 shape: [5] values: 0 0 3...>; Tensor<type: int32 shape: [5] values: 1 1 1...>; Tensor<type: int32 shape: [5] values: 0 0 6...>; Tensor<type: int32 shape: [5] values: -1 4 9...>; Tensor<type: int32 shape: [4] values: -1 6 5...>; Tensor<type: int32 shape: [5] values: 0 0 7...>; Tensor<type: int32 shape: [5] values: 0 0 9...>; Tensor<type: int32 shape: [3] values: 8 0 0>; Tensor<type: int32 shape: [3] values: 12 0 0>; Tensor<type: int32 shape: [4] values: -1 24 5...>; Tensor<type: int32 shape: [4] values: -1 4 5...>; Tensor<type: int32 shape: [4] values: -1 8 5...>; Tensor<type: int32 shape: [4] values: 4 -1 1...> with request count 1 and compile threshold 0 shape info=0
2022-08-04 07:53:37.330182: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:329] RunBackend() - Will load PTX from file: ./xla_cache/10153300373092785533.ptx
2022-08-04 07:53:37.330342: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-08-04 07:53:37.808944: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_4[_XlaCompiledKernel=true,_XlaNumConstantArgs=1,_XlaNumResourceArgs=0],float [4,200,200,1]; Tensor<type: int32 shape: [4] values: 0 1 3...> with request count 1 and compile threshold 0 shape info=0
2022-08-04 07:53:37.856476: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-08-04 07:53:37.857251: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_0[_XlaCompiledKernel=true,_XlaNumConstantArgs=52,_XlaNumResourceArgs=0],float [200,96],float [16,200,24],float [200,4,2,4],float [200,30,2,4],float [200,14,2,4],float [4,200,24,1],float [200,1852],float [200,96],half [1,1728],half [1,4800],half [1,19200],half [1,4800],half [1,38400]; Tensor<type: int32 shape: [4] values: 2 8 150...>; Tensor<type: int32 shape: [3] values: 6 50 16>; Tensor<type: int32 shape: [3] values: 6 200 16>; Tensor<type: int32 shape: [4] values: 0 2 1...>; Tensor<type: int32 shape: [3] values: 1 0 2>; Tensor<type: int32 shape: [3] values: 2 150 128>; Tensor<type: int32 shape: [3] values: 1 50 96>; Tensor<type: int32 shape: [3] values: 1 200 96>; Tensor<type: int32 shape: [1] values: 0>; Tensor<type: int32 shape: [1] values: 1>; Tensor<type: int32 shape: [1] values: 2>; Tensor<type: int32 shape: [3] values: 16 0 0>; Tensor<type: int32 shape: [4] values: 1 200 4...>; Tensor<type: int32 shape: [2] values: 200 1>; Tensor<type: int32 shape: [4] values: 2 50 4...>; Tensor<type: int32 shape: [3] values: 4 200 24>; Tensor<type: int32 shape: [3] values: -1 4 8>; Tensor<type: int32 shape: [4] values: 2 150 4...>; Tensor<type: int32 shape: [3] values: 8 50 24>; Tensor<type: int32 shape: [3] values: -1 30 8>; Tensor<type: int32 shape: [3] values: 0 1 0>; Tensor<type: int32 shape: [3] values: 0 2 0>; Tensor<type: int32 shape: [3] values: 0 3 0>; Tensor<type: int32 shape: [3] values: -1 14 8>; Tensor<type: int32 shape: [3] values: 0 6 0>; Tensor<type: int32 shape: [3] values: 0 12 0>; Tensor<type: int32 shape: [3] values: 0 18 0>; Tensor<type: int32 shape: [3] values: 0 24 0>; Tensor<type: int32 shape: [3] values: 0 27 0>; Tensor<type: int32 shape: [3] values: 0 4 0>; Tensor<type: int32 shape: [3] values: 0 8 0>; Tensor<type: int32 shape: [3] values: 0 11 0>; Tensor<type: int32 shape: [3] values: 8 150 32>; Tensor<type: int32 shape: [2] values: -1 384>; Tensor<type: int32 shape: [4] values: 1 4 -1...>; Tensor<type: int32 shape: [4] values: 1 0 2...>; Tensor<type: int32 shape: [4] values: 2 4 -1...>; Tensor<type: int32 shape: [2] values: -1 96>; Tensor<type: int32 shape: [4] values: 2 4 -1...>; Tensor<type: int32 shape: [2] values: -1 192>; Tensor<type: int32 shape: [2] values: 0 -96>; Tensor<type: int32 shape: [2] values: -1 256>; Tensor<type: int32 shape: [2] values: 0 0>; Tensor<type: int32 shape: [2] values: 0 96>; Tensor<type: int32 shape: [2] values: 1 1>; Tensor<type: int32 shape: [3] values: 1 1 1>; Tensor<type: int32 shape: [3] values: 8 0 0>; Tensor<type: int32 shape: [3] values: 0 0 0>; Tensor<type: int32 shape: [] values: 0>; Tensor<type: int32 shape: [4] values: 2 0 1...>; Tensor<type: int32 shape: [] values: 1>; Tensor<type: int32 shape: [3] values: 12 0 0> with request count 1 and compile threshold 0 shape info=0
2022-08-04 07:53:39.203084: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_5[_XlaCompiledKernel=true,_XlaNumConstantArgs=1,_XlaNumResourceArgs=0],float [200,5244],float [1,5244],half [5244,1024],float [1024],float [1,1024],float [],float [],float [1024,512],float [512],float [1,512],float [512,256],float [256],float [1,256],float [256,128],float [128],float [1,128],float [128,64],float [64],float [1,64],float [64,2],float [2]; Tensor<type: int32 shape: [1] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 07:53:39.355973: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-08-04 07:53:39.358640: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_6[_XlaCompiledKernel=true,_XlaNumConstantArgs=1,_XlaNumResourceArgs=0],float [200,5244],float [1,5244],half [5244,1024],float [1024],float [1,1024],float [],float [],float [1024,512],float [512],float [1,512],float [512,256],float [256],float [1,256],float [256,128],float [128],float [1,128],float [128,64],float [64],float [1,64],float [64,2],float [2]; Tensor<type: int32 shape: [1] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 07:53:39.510142: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-08-04 07:53:39.511927: I tensorflow/compiler/jit/xla_compilation_cache.cc:369] Compilation cache entry hit: 0  signature: cluster_7[_XlaCompiledKernel=true,_XlaNumConstantArgs=1,_XlaNumResourceArgs=0],float [200,2],float [200,2],float []; Tensor<type: int32 shape: [] values: 1> with request count 1 and compile threshold 0 shape info=0
2022-08-04 07:53:39.551394: I tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:605] Compile ptx to cubin: found in cache
2022-08-04 07:53:39.552143: I tensorflow/core/kernels/blaze_xla_predictor.cc:137] batch 200 has warmuped; cost us: 2740186
2022-08-04 07:53:39.554499: I /home/yunlong.xyl/blaze-benchmark/benchmark/core/model.cc:435] Init and warmup model complete: star
2022-Aug-04 07:53:42.555098 ====================================================
-- Histograms ------------------------------------------------------------------
star_batchsize
             count = 5031
               min = 166
               max = 166
              mean = 166.00
            stddev = 0.00
            median = 166.00
              75% <= 166.00
              95% <= 166.00
              98% <= 166.00
              99% <= 166.00
            99.9% <= 166.00
star_latency
             count = 5031
               min = 1885
               max = 6038
              mean = 2373.79
            stddev = 228.54
            median = 2360.00
              75% <= 2437.00
              95% <= 2629.75
              98% <= 2732.50
              99% <= 2947.50
            99.9% <= 6013.10

-- Meters ----------------------------------------------------------------------
star_throughput
             count = 5031
         mean rate = 1678.68 events per 1 Seconds
     1-minute rate = 0.00 events per 1 Seconds
     5-minute rate = 0.00 events per 1 Seconds
    15-minute rate = 0.00 events per 1 Seconds


2022-Aug-04 07:53:45.555546 ====================================================
-- Histograms ------------------------------------------------------------------
star_batchsize
             count = 10097
               min = 166
               max = 166
              mean = 166.00
            stddev = 0.00
            median = 166.00
              75% <= 166.00
              95% <= 166.00
              98% <= 166.00
              99% <= 166.00
            99.9% <= 166.00
star_latency
             count = 10097
               min = 1939
               max = 5042
              mean = 2373.65
            stddev = 188.93
            median = 2361.00
              75% <= 2436.00
              95% <= 2608.75
              98% <= 2710.50
              99% <= 2827.00
            99.9% <= 5020.93

-- Meters ----------------------------------------------------------------------
star_throughput
             count = 10097
         mean rate = 1683.58 events per 1 Seconds
     1-minute rate = 1680.60 events per 1 Seconds
     5-minute rate = 1680.60 events per 1 Seconds
    15-minute rate = 1680.60 events per 1 Seconds


2022-Aug-04 07:53:48.555901 ====================================================
-- Histograms ------------------------------------------------------------------
star_batchsize
             count = 15181
               min = 166
               max = 166
              mean = 166.00
            stddev = 0.00
            median = 166.00
              75% <= 166.00
              95% <= 166.00
              98% <= 166.00
              99% <= 166.00
            99.9% <= 166.00
star_latency
             count = 15183
               min = 1939
               max = 4199
              mean = 2365.64
            stddev = 163.34
            median = 2355.50
              75% <= 2437.00
              95% <= 2597.00
              98% <= 2674.00
              99% <= 2756.25
            99.9% <= 4198.45

-- Meters ----------------------------------------------------------------------
star_throughput
             count = 15184
         mean rate = 1687.54 events per 1 Seconds
     1-minute rate = 1680.60 events per 1 Seconds
     5-minute rate = 1680.60 events per 1 Seconds
    15-minute rate = 1680.60 events per 1 Seconds


2022-Aug-04 07:53:51.556268 ====================================================
-- Histograms ------------------------------------------------------------------
star_batchsize
             count = 20262
               min = 166
               max = 166
              mean = 166.00
            stddev = 0.00
            median = 166.00
              75% <= 166.00
              95% <= 166.00
              98% <= 166.00
              99% <= 166.00
            99.9% <= 166.00
star_latency
             count = 20262
               min = 1946
               max = 3674
              mean = 2362.25
            stddev = 148.37
            median = 2354.00
              75% <= 2434.75
              95% <= 2590.75
              98% <= 2665.00
              99% <= 2747.75
            99.9% <= 3672.08

-- Meters ----------------------------------------------------------------------
star_throughput
             count = 20265
         mean rate = 1689.02 events per 1 Seconds
     1-minute rate = 1681.96 events per 1 Seconds
     5-minute rate = 1680.88 events per 1 Seconds
    15-minute rate = 1680.69 events per 1 Seconds


2022-Aug-04 07:53:54.556653 ====================================================
-- Histograms ------------------------------------------------------------------
star_batchsize
             count = 25329
               min = 166
               max = 166
              mean = 166.00
            stddev = 0.00
            median = 166.00
              75% <= 166.00
              95% <= 166.00
              98% <= 166.00
              99% <= 166.00
            99.9% <= 166.00
star_latency
             count = 25329
               min = 1946
               max = 3674
              mean = 2364.17
            stddev = 153.40
            median = 2354.00
              75% <= 2437.00
              95% <= 2607.50
              98% <= 2672.50
              99% <= 2753.00
            99.9% <= 3672.08

-- Meters ----------------------------------------------------------------------
star_throughput
             count = 25329
         mean rate = 1688.77 events per 1 Seconds
     1-minute rate = 1681.96 events per 1 Seconds
     5-minute rate = 1680.88 events per 1 Seconds
    15-minute rate = 1680.69 events per 1 Seconds


2022-Aug-04 07:53:57.557001 ====================================================
-- Histograms ------------------------------------------------------------------
star_batchsize
             count = 30427
               min = 166
               max = 166
              mean = 166.00
            stddev = 0.00
            median = 166.00
              75% <= 166.00
              95% <= 166.00
              98% <= 166.00
              99% <= 166.00
            99.9% <= 166.00
star_latency
             count = 30427
               min = 1911
               max = 3597
              mean = 2358.46
            stddev = 144.20
            median = 2353.00
              75% <= 2429.00
              95% <= 2599.50
              98% <= 2668.00
              99% <= 2722.25
            99.9% <= 3595.40

-- Meters ----------------------------------------------------------------------
star_throughput
             count = 30427
         mean rate = 1690.50 events per 1 Seconds
     1-minute rate = 1682.47 events per 1 Seconds
     5-minute rate = 1681.01 events per 1 Seconds
    15-minute rate = 1680.74 events per 1 Seconds


2022-Aug-04 07:54:00.557337 ====================================================
-- Histograms ------------------------------------------------------------------
star_batchsize
             count = 35500
               min = 166
               max = 166
              mean = 166.00
            stddev = 0.00
            median = 166.00
              75% <= 166.00
              95% <= 166.00
              98% <= 166.00
              99% <= 166.00
            99.9% <= 166.00
star_latency
             count = 35501
               min = 1911
               max = 3597
              mean = 2358.48
            stddev = 141.39
            median = 2352.00
              75% <= 2426.00
              95% <= 2577.00
              98% <= 2668.00
              99% <= 2717.75
            99.9% <= 3595.40

-- Meters ----------------------------------------------------------------------
star_throughput
             count = 35501
         mean rate = 1690.59 events per 1 Seconds
     1-minute rate = 1683.62 events per 1 Seconds
     5-minute rate = 1681.27 events per 1 Seconds
    15-minute rate = 1680.83 events per 1 Seconds


2022-Aug-04 07:54:03.557727 ====================================================
-- Histograms ------------------------------------------------------------------
star_batchsize
             count = 40569
               min = 166
               max = 166
              mean = 166.00
            stddev = 0.00
            median = 166.00
              75% <= 166.00
              95% <= 166.00
              98% <= 166.00
              99% <= 166.00
            99.9% <= 166.00
star_latency
             count = 40570
               min = 1906
               max = 3854
              mean = 2360.98
            stddev = 146.16
            median = 2355.00
              75% <= 2427.75
              95% <= 2576.75
              98% <= 2663.00
              99% <= 2704.00
            99.9% <= 3847.58

-- Meters ----------------------------------------------------------------------
star_throughput
             count = 40570
         mean rate = 1690.45 events per 1 Seconds
     1-minute rate = 1683.62 events per 1 Seconds
     5-minute rate = 1681.27 events per 1 Seconds
    15-minute rate = 1680.83 events per 1 Seconds


2022-Aug-04 07:54:06.558150 ====================================================
-- Histograms ------------------------------------------------------------------
star_batchsize
             count = 45699
               min = 166
               max = 166
              mean = 166.00
            stddev = 0.00
            median = 166.00
              75% <= 166.00
              95% <= 166.00
              98% <= 166.00
              99% <= 166.00
            99.9% <= 166.00
star_latency
             count = 45700
               min = 1911
               max = 3854
              mean = 2360.78
            stddev = 145.05
            median = 2355.00
              75% <= 2426.00
              95% <= 2576.75
              98% <= 2656.50
              99% <= 2694.50
            99.9% <= 3847.58

-- Meters ----------------------------------------------------------------------
star_throughput
             count = 45700
         mean rate = 1692.59 events per 1 Seconds
     1-minute rate = 1684.03 events per 1 Seconds
     5-minute rate = 1681.39 events per 1 Seconds
    15-minute rate = 1680.87 events per 1 Seconds


2022-Aug-04 07:54:09.558532 ====================================================
-- Histograms ------------------------------------------------------------------
star_batchsize
             count = 50782
               min = 166
               max = 166
              mean = 166.00
            stddev = 0.00
            median = 166.00
              75% <= 166.00
              95% <= 166.00
              98% <= 166.00
              99% <= 166.00
            99.9% <= 166.00
star_latency
             count = 50782
               min = 1928
               max = 3854
              mean = 2360.82
            stddev = 147.02
            median = 2355.00
              75% <= 2429.00
              95% <= 2578.00
              98% <= 2656.50
              99% <= 2696.00
            99.9% <= 3847.58

-- Meters ----------------------------------------------------------------------
star_throughput
             count = 50784
         mean rate = 1692.78 events per 1 Seconds
     1-minute rate = 1685.65 events per 1 Seconds
     5-minute rate = 1681.77 events per 1 Seconds
    15-minute rate = 1681.00 events per 1 Seconds


2022-Aug-04 07:54:12.558948 ====================================================
-- Histograms ------------------------------------------------------------------
star_batchsize
             count = 55853
               min = 166
               max = 166
              mean = 166.00
            stddev = 0.00
            median = 166.00
              75% <= 166.00
              95% <= 166.00
              98% <= 166.00
              99% <= 166.00
            99.9% <= 166.00
star_latency
             count = 55853
               min = 1908
               max = 3854
              mean = 2362.97
            stddev = 156.22
            median = 2355.50
              75% <= 2429.00
              95% <= 2588.00
              98% <= 2665.00
              99% <= 2879.75
            99.9% <= 3847.58

-- Meters ----------------------------------------------------------------------
star_throughput
             count = 55853
         mean rate = 1692.47 events per 1 Seconds
     1-minute rate = 1685.65 events per 1 Seconds
     5-minute rate = 1681.77 events per 1 Seconds
    15-minute rate = 1681.00 events per 1 Seconds


2022-Aug-04 07:54:15.559360 ====================================================
-- Histograms ------------------------------------------------------------------
star_batchsize
             count = 60963
               min = 166
               max = 166
              mean = 166.00
            stddev = 0.00
            median = 166.00
              75% <= 166.00
              95% <= 166.00
              98% <= 166.00
              99% <= 166.00
            99.9% <= 166.00
star_latency
             count = 60963
               min = 1908
               max = 3854
              mean = 2357.25
            stddev = 149.51
            median = 2349.00
              75% <= 2426.00
              95% <= 2581.75
              98% <= 2663.00
              99% <= 2715.50
            99.9% <= 3845.98

-- Meters ----------------------------------------------------------------------
star_throughput
             count = 60963
         mean rate = 1693.36 events per 1 Seconds
     1-minute rate = 1686.60 events per 1 Seconds
     5-minute rate = 1682.03 events per 1 Seconds
    15-minute rate = 1681.09 events per 1 Seconds


2022-Aug-04 07:54:18.559708 ====================================================
-- Histograms ------------------------------------------------------------------
star_batchsize
             count = 66041
               min = 166
               max = 166
              mean = 166.00
            stddev = 0.00
            median = 166.00
              75% <= 166.00
              95% <= 166.00
              98% <= 166.00
              99% <= 166.00
            99.9% <= 166.00
star_latency
             count = 66041
               min = 1916
               max = 3533
              mean = 2353.76
            stddev = 139.85
            median = 2348.50
              75% <= 2424.00
              95% <= 2575.75
              98% <= 2663.00
              99% <= 2715.50
            99.9% <= 3521.38

-- Meters ----------------------------------------------------------------------
star_throughput
             count = 66041
         mean rate = 1693.29 events per 1 Seconds
     1-minute rate = 1686.60 events per 1 Seconds
     5-minute rate = 1682.03 events per 1 Seconds
    15-minute rate = 1681.09 events per 1 Seconds


2022-Aug-04 07:54:21.560062 ====================================================
-- Histograms ------------------------------------------------------------------
star_batchsize
             count = 71127
               min = 166
               max = 166
              mean = 166.00
            stddev = 0.00
            median = 166.00
              75% <= 166.00
              95% <= 166.00
              98% <= 166.00
              99% <= 166.00
            99.9% <= 166.00
star_latency
             count = 71127
               min = 1770
               max = 3533
              mean = 2353.78
            stddev = 138.26
            median = 2351.50
              75% <= 2426.00
              95% <= 2573.75
              98% <= 2655.50
              99% <= 2697.50
            99.9% <= 3521.38

-- Meters ----------------------------------------------------------------------
star_throughput
             count = 71127
         mean rate = 1693.42 events per 1 Seconds
     1-minute rate = 1687.07 events per 1 Seconds
     5-minute rate = 1682.20 events per 1 Seconds
    15-minute rate = 1681.15 events per 1 Seconds


2022-Aug-04 07:54:24.560441 ====================================================
-- Histograms ------------------------------------------------------------------
star_batchsize
             count = 76226
               min = 166
               max = 166
              mean = 166.00
            stddev = 0.00
            median = 166.00
              75% <= 166.00
              95% <= 166.00
              98% <= 166.00
              99% <= 166.00
            99.9% <= 166.00
star_latency
             count = 76226
               min = 1770
               max = 3533
              mean = 2354.35
            stddev = 139.92
            median = 2350.00
              75% <= 2427.00
              95% <= 2574.75
              98% <= 2663.00
              99% <= 2689.25
            99.9% <= 3521.38

-- Meters ----------------------------------------------------------------------
star_throughput
             count = 76226
         mean rate = 1693.83 events per 1 Seconds
     1-minute rate = 1687.94 events per 1 Seconds
     5-minute rate = 1682.46 events per 1 Seconds
    15-minute rate = 1681.25 events per 1 Seconds


2022-Aug-04 07:54:27.560830 ====================================================
-- Histograms ------------------------------------------------------------------
star_batchsize
             count = 81315
               min = 166
               max = 166
              mean = 166.00
            stddev = 0.00
            median = 166.00
              75% <= 166.00
              95% <= 166.00
              98% <= 166.00
              99% <= 166.00
            99.9% <= 166.00
star_latency
             count = 81315
               min = 1770
               max = 3533
              mean = 2353.91
            stddev = 138.36
            median = 2349.00
              75% <= 2426.75
              95% <= 2575.00
              98% <= 2661.00
              99% <= 2686.50
            99.9% <= 3521.38

-- Meters ----------------------------------------------------------------------
star_throughput
             count = 81315
         mean rate = 1693.97 events per 1 Seconds
     1-minute rate = 1687.94 events per 1 Seconds
     5-minute rate = 1682.46 events per 1 Seconds
    15-minute rate = 1681.25 events per 1 Seconds


2022-Aug-04 07:54:30.561208 ====================================================
-- Histograms ------------------------------------------------------------------
star_batchsize
             count = 86391
               min = 166
               max = 166
              mean = 166.00
            stddev = 0.00
            median = 166.00
              75% <= 166.00
              95% <= 166.00
              98% <= 166.00
              99% <= 166.00
            99.9% <= 166.00
star_latency
             count = 86391
               min = 1770
               max = 5480
              mean = 2358.35
            stddev = 167.68
            median = 2352.00
              75% <= 2426.75
              95% <= 2575.00
              98% <= 2647.00
              99% <= 2683.75
            99.9% <= 5431.33

-- Meters ----------------------------------------------------------------------
star_throughput
             count = 86391
         mean rate = 1693.84 events per 1 Seconds
     1-minute rate = 1688.49 events per 1 Seconds
     5-minute rate = 1682.67 events per 1 Seconds
    15-minute rate = 1681.32 events per 1 Seconds


2022-Aug-04 07:54:33.561615 ====================================================
-- Histograms ------------------------------------------------------------------
star_batchsize
             count = 91456
               min = 166
               max = 166
              mean = 166.00
            stddev = 0.00
            median = 166.00
              75% <= 166.00
              95% <= 166.00
              98% <= 166.00
              99% <= 166.00
            99.9% <= 166.00
star_latency
             count = 91456
               min = 1770
               max = 5480
              mean = 2359.20
            stddev = 169.44
            median = 2352.50
              75% <= 2429.00
              95% <= 2575.75
              98% <= 2655.50
              99% <= 2702.00
            99.9% <= 5431.33

-- Meters ----------------------------------------------------------------------
star_throughput
             count = 91456
         mean rate = 1693.52 events per 1 Seconds
     1-minute rate = 1688.49 events per 1 Seconds
     5-minute rate = 1682.67 events per 1 Seconds
    15-minute rate = 1681.32 events per 1 Seconds


2022-Aug-04 07:54:36.561954 ====================================================
-- Histograms ------------------------------------------------------------------
star_batchsize
             count = 96524
               min = 166
               max = 166
              mean = 166.00
            stddev = 0.00
            median = 166.00
              75% <= 166.00
              95% <= 166.00
              98% <= 166.00
              99% <= 166.00
            99.9% <= 166.00
star_latency
             count = 96524
               min = 1770
               max = 5480
              mean = 2359.12
            stddev = 168.89
            median = 2351.00
              75% <= 2427.00
              95% <= 2576.00
              98% <= 2660.00
              99% <= 2707.00
            99.9% <= 5431.33

-- Meters ----------------------------------------------------------------------
star_throughput
             count = 96524
         mean rate = 1693.29 events per 1 Seconds
     1-minute rate = 1688.55 events per 1 Seconds
     5-minute rate = 1682.77 events per 1 Seconds
    15-minute rate = 1681.37 events per 1 Seconds


2022-Aug-04 07:54:39.562339 ====================================================
-- Histograms ------------------------------------------------------------------
star_batchsize
             count = 101606
               min = 166
               max = 166
              mean = 166.00
            stddev = 0.00
            median = 166.00
              75% <= 166.00
              95% <= 166.00
              98% <= 166.00
              99% <= 166.00
            99.9% <= 166.00
star_latency
             count = 101606
               min = 1770
               max = 5480
              mean = 2361.28
            stddev = 168.50
            median = 2353.00
              75% <= 2429.00
              95% <= 2581.75
              98% <= 2663.00
              99% <= 2707.75
            99.9% <= 5431.33

-- Meters ----------------------------------------------------------------------
star_throughput
             count = 101606
         mean rate = 1693.32 events per 1 Seconds
     1-minute rate = 1688.76 events per 1 Seconds
     5-minute rate = 1682.91 events per 1 Seconds
    15-minute rate = 1681.42 events per 1 Seconds


2022-Aug-04 07:54:42.562744 ====================================================
-- Histograms ------------------------------------------------------------------
star_batchsize
             count = 106694
               min = 166
               max = 166
              mean = 166.00
            stddev = 0.00
            median = 166.00
              75% <= 166.00
              95% <= 166.00
              98% <= 166.00
              99% <= 166.00
            99.9% <= 166.00
star_latency
             count = 106695
               min = 1770
               max = 5480
              mean = 2361.34
            stddev = 169.20
            median = 2353.00
              75% <= 2431.00
              95% <= 2576.75
              98% <= 2663.00
              99% <= 2721.75
            99.9% <= 5431.33

-- Meters ----------------------------------------------------------------------
star_throughput
             count = 106696
         mean rate = 1693.46 events per 1 Seconds
     1-minute rate = 1688.76 events per 1 Seconds
     5-minute rate = 1682.91 events per 1 Seconds
    15-minute rate = 1681.42 events per 1 Seconds


2022-Aug-04 07:54:45.563101 ====================================================
-- Histograms ------------------------------------------------------------------
star_batchsize
             count = 111802
               min = 166
               max = 166
              mean = 166.00
            stddev = 0.00
            median = 166.00
              75% <= 166.00
              95% <= 166.00
              98% <= 166.00
              99% <= 166.00
            99.9% <= 166.00
star_latency
             count = 111802
               min = 1916
               max = 5480
              mean = 2361.42
            stddev = 167.38
            median = 2352.00
              75% <= 2431.00
              95% <= 2577.75
              98% <= 2656.00
              99% <= 2707.00
            99.9% <= 5431.33

-- Meters ----------------------------------------------------------------------
star_throughput
             count = 111802
         mean rate = 1693.84 events per 1 Seconds
     1-minute rate = 1689.72 events per 1 Seconds
     5-minute rate = 1683.21 events per 1 Seconds
    15-minute rate = 1681.53 events per 1 Seconds


2022-Aug-04 07:54:48.563438 ====================================================
-- Histograms ------------------------------------------------------------------
star_batchsize
             count = 116876
               min = 166
               max = 166
              mean = 166.00
            stddev = 0.00
            median = 166.00
              75% <= 166.00
              95% <= 166.00
              98% <= 166.00
              99% <= 166.00
            99.9% <= 166.00
star_latency
             count = 116876
               min = 1916
               max = 5480
              mean = 2362.16
            stddev = 166.32
            median = 2353.00
              75% <= 2431.00
              95% <= 2576.75
              98% <= 2656.00
              99% <= 2707.00
            99.9% <= 5431.33

-- Meters ----------------------------------------------------------------------
star_throughput
             count = 116876
         mean rate = 1693.73 events per 1 Seconds
     1-minute rate = 1689.72 events per 1 Seconds
     5-minute rate = 1683.21 events per 1 Seconds
    15-minute rate = 1681.53 events per 1 Seconds


2022-Aug-04 07:54:51.563799 ====================================================
-- Histograms ------------------------------------------------------------------
star_batchsize
             count = 121937
               min = 166
               max = 166
              mean = 166.00
            stddev = 0.00
            median = 166.00
              75% <= 166.00
              95% <= 166.00
              98% <= 166.00
              99% <= 166.00
            99.9% <= 166.00
star_latency
             count = 121937
               min = 1916
               max = 5480
              mean = 2361.63
            stddev = 165.68
            median = 2352.00
              75% <= 2429.75
              95% <= 2576.75
              98% <= 2656.00
              99% <= 2707.00
            99.9% <= 5431.33

-- Meters ----------------------------------------------------------------------
star_throughput
             count = 121937
         mean rate = 1693.44 events per 1 Seconds
     1-minute rate = 1689.93 events per 1 Seconds
     5-minute rate = 1683.36 events per 1 Seconds
    15-minute rate = 1681.59 events per 1 Seconds


2022-Aug-04 07:54:54.564160 ====================================================
-- Histograms ------------------------------------------------------------------
star_batchsize
             count = 127029
               min = 166
               max = 166
              mean = 166.00
            stddev = 0.00
            median = 166.00
              75% <= 166.00
              95% <= 166.00
              98% <= 166.00
              99% <= 166.00
            99.9% <= 166.00
star_latency
             count = 127030
               min = 1916
               max = 5480
              mean = 2360.62
            stddev = 164.95
            median = 2352.00
              75% <= 2431.00
              95% <= 2576.75
              98% <= 2652.00
              99% <= 2702.00
            99.9% <= 5431.33

-- Meters ----------------------------------------------------------------------
star_throughput
             count = 127031
         mean rate = 1693.61 events per 1 Seconds
     1-minute rate = 1690.02 events per 1 Seconds
     5-minute rate = 1683.49 events per 1 Seconds
    15-minute rate = 1681.64 events per 1 Seconds


2022-Aug-04 07:54:57.564666 ====================================================
-- Histograms ------------------------------------------------------------------
star_batchsize
             count = 132113
               min = 166
               max = 166
              mean = 166.00
            stddev = 0.00
            median = 166.00
              75% <= 166.00
              95% <= 166.00
              98% <= 166.00
              99% <= 166.00
            99.9% <= 166.00
star_latency
             count = 132113
               min = 1713
               max = 5480
              mean = 2359.73
            stddev = 166.33
            median = 2352.00
              75% <= 2429.00
              95% <= 2576.25
              98% <= 2652.00
              99% <= 2702.00
            99.9% <= 5431.33

-- Meters ----------------------------------------------------------------------
star_throughput
             count = 132113
         mean rate = 1693.62 events per 1 Seconds
     1-minute rate = 1690.02 events per 1 Seconds
     5-minute rate = 1683.49 events per 1 Seconds
    15-minute rate = 1681.64 events per 1 Seconds


2022-Aug-04 07:55:00.565057 ====================================================
-- Histograms ------------------------------------------------------------------
star_batchsize
             count = 137245
               min = 166
               max = 166
              mean = 166.00
            stddev = 0.00
            median = 166.00
              75% <= 166.00
              95% <= 166.00
              98% <= 166.00
              99% <= 166.00
            99.9% <= 166.00
star_latency
             count = 137245
               min = 1713
               max = 5480
              mean = 2358.08
            stddev = 166.42
            median = 2352.00
              75% <= 2426.75
              95% <= 2569.00
              98% <= 2645.00
              99% <= 2702.00
            99.9% <= 5431.33

-- Meters ----------------------------------------------------------------------
star_throughput
             count = 137245
         mean rate = 1694.24 events per 1 Seconds
     1-minute rate = 1690.85 events per 1 Seconds
     5-minute rate = 1683.77 events per 1 Seconds
    15-minute rate = 1681.74 events per 1 Seconds


2022-Aug-04 07:55:03.565393 ====================================================
-- Histograms ------------------------------------------------------------------
star_batchsize
             count = 142369
               min = 166
               max = 166
              mean = 166.00
            stddev = 0.00
            median = 166.00
              75% <= 166.00
              95% <= 166.00
              98% <= 166.00
              99% <= 166.00
            99.9% <= 166.00
star_latency
             count = 142369
               min = 1713
               max = 5480
              mean = 2356.13
            stddev = 166.24
            median = 2348.50
              75% <= 2426.00
              95% <= 2572.00
              98% <= 2633.00
              99% <= 2686.50
            99.9% <= 5431.33

-- Meters ----------------------------------------------------------------------
star_throughput
             count = 142369
         mean rate = 1694.72 events per 1 Seconds
     1-minute rate = 1690.85 events per 1 Seconds
     5-minute rate = 1683.77 events per 1 Seconds
    15-minute rate = 1681.74 events per 1 Seconds


2022-Aug-04 07:55:06.565822 ====================================================
-- Histograms ------------------------------------------------------------------
star_batchsize
             count = 147474
               min = 166
               max = 166
              mean = 166.00
            stddev = 0.00
            median = 166.00
              75% <= 166.00
              95% <= 166.00
              98% <= 166.00
              99% <= 166.00
            99.9% <= 166.00
star_latency
             count = 147474
               min = 1713
               max = 5480
              mean = 2354.19
            stddev = 166.01
            median = 2345.00
              75% <= 2425.00
              95% <= 2572.00
              98% <= 2651.00
              99% <= 2677.25
            99.9% <= 5431.33

-- Meters ----------------------------------------------------------------------
star_throughput
             count = 147474
         mean rate = 1694.95 events per 1 Seconds
     1-minute rate = 1692.21 events per 1 Seconds
     5-minute rate = 1684.16 events per 1 Seconds
    15-minute rate = 1681.89 events per 1 Seconds


2022-Aug-04 07:55:09.566183 ====================================================
-- Histograms ------------------------------------------------------------------
star_batchsize
             count = 152555
               min = 166
               max = 166
              mean = 166.00
            stddev = 0.00
            median = 166.00
              75% <= 166.00
              95% <= 166.00
              98% <= 166.00
              99% <= 166.00
            99.9% <= 166.00
star_latency
             count = 152555
               min = 1713
               max = 5480
              mean = 2352.96
            stddev = 165.35
            median = 2346.00
              75% <= 2423.00
              95% <= 2560.75
              98% <= 2636.50
              99% <= 2668.50
            99.9% <= 5431.33

-- Meters ----------------------------------------------------------------------
star_throughput
             count = 152555
         mean rate = 1694.90 events per 1 Seconds
     1-minute rate = 1692.52 events per 1 Seconds
     5-minute rate = 1684.36 events per 1 Seconds
    15-minute rate = 1681.97 events per 1 Seconds


2022-Aug-04 07:55:12.566579 ====================================================
-- Histograms ------------------------------------------------------------------
star_batchsize
             count = 157614
               min = 166
               max = 166
              mean = 166.00
            stddev = 0.00
            median = 166.00
              75% <= 166.00
              95% <= 166.00
              98% <= 166.00
              99% <= 166.00
            99.9% <= 166.00
star_latency
             count = 157615
               min = 1713
               max = 5480
              mean = 2355.79
            stddev = 166.18
            median = 2348.00
              75% <= 2426.00
              95% <= 2577.00
              98% <= 2638.00
              99% <= 2676.75
            99.9% <= 5431.33

-- Meters ----------------------------------------------------------------------
star_throughput
             count = 157615
         mean rate = 1694.63 events per 1 Seconds
     1-minute rate = 1692.52 events per 1 Seconds
     5-minute rate = 1684.36 events per 1 Seconds
    15-minute rate = 1681.97 events per 1 Seconds


2022-Aug-04 07:55:15.567020 ====================================================
-- Histograms ------------------------------------------------------------------
star_batchsize
             count = 162715
               min = 166
               max = 166
              mean = 166.00
            stddev = 0.00
            median = 166.00
              75% <= 166.00
              95% <= 166.00
              98% <= 166.00
              99% <= 166.00
            99.9% <= 166.00
star_latency
             count = 162717
               min = 1713
               max = 5480
              mean = 2354.48
            stddev = 165.16
            median = 2347.00
              75% <= 2423.00
              95% <= 2560.75
              98% <= 2630.50
              99% <= 2676.75
            99.9% <= 5431.33

-- Meters ----------------------------------------------------------------------
star_throughput
             count = 162717
         mean rate = 1694.81 events per 1 Seconds
     1-minute rate = 1692.32 events per 1 Seconds
     5-minute rate = 1684.46 events per 1 Seconds
    15-minute rate = 1682.01 events per 1 Seconds


2022-Aug-04 07:55:18.567396 ====================================================
-- Histograms ------------------------------------------------------------------
star_batchsize
             count = 167812
               min = 166
               max = 166
              mean = 166.00
            stddev = 0.00
            median = 166.00
              75% <= 166.00
              95% <= 166.00
              98% <= 166.00
              99% <= 166.00
            99.9% <= 166.00
star_latency
             count = 167812
               min = 1713
               max = 5480
              mean = 2353.29
            stddev = 166.30
            median = 2347.00
              75% <= 2420.00
              95% <= 2555.75
              98% <= 2638.00
              99% <= 2713.75
            99.9% <= 5431.33

-- Meters ----------------------------------------------------------------------
star_throughput
             count = 167813
         mean rate = 1694.92 events per 1 Seconds
     1-minute rate = 1692.32 events per 1 Seconds
     5-minute rate = 1684.46 events per 1 Seconds
    15-minute rate = 1682.01 events per 1 Seconds


2022-Aug-04 07:55:21.567778 ====================================================
-- Histograms ------------------------------------------------------------------
star_batchsize
             count = 172886
               min = 166
               max = 166
              mean = 166.00
            stddev = 0.00
            median = 166.00
              75% <= 166.00
              95% <= 166.00
              98% <= 166.00
              99% <= 166.00
            99.9% <= 166.00
star_latency
             count = 172887
               min = 1713
               max = 5480
              mean = 2353.70
            stddev = 165.56
            median = 2347.00
              75% <= 2419.75
              95% <= 2555.75
              98% <= 2643.00
              99% <= 2713.75
            99.9% <= 5431.33

-- Meters ----------------------------------------------------------------------
star_throughput
             count = 172887
         mean rate = 1694.81 events per 1 Seconds
     1-minute rate = 1693.02 events per 1 Seconds
     5-minute rate = 1684.73 events per 1 Seconds
    15-minute rate = 1682.12 events per 1 Seconds


2022-Aug-04 07:55:24.568223 ====================================================
-- Histograms ------------------------------------------------------------------
star_batchsize
             count = 177955
               min = 166
               max = 166
              mean = 166.00
            stddev = 0.00
            median = 166.00
              75% <= 166.00
              95% <= 166.00
              98% <= 166.00
              99% <= 166.00
            99.9% <= 166.00
star_latency
             count = 177955
               min = 1713
               max = 3019
              mean = 2350.06
            stddev = 126.43
            median = 2347.00
              75% <= 2418.00
              95% <= 2550.75
              98% <= 2630.50
              99% <= 2683.75
            99.9% <= 3016.68

-- Meters ----------------------------------------------------------------------
star_throughput
             count = 177955
         mean rate = 1694.65 events per 1 Seconds
     1-minute rate = 1692.66 events per 1 Seconds
     5-minute rate = 1684.79 events per 1 Seconds
    15-minute rate = 1682.15 events per 1 Seconds


2022-Aug-04 07:55:27.568631 ====================================================
-- Histograms ------------------------------------------------------------------
star_batchsize
             count = 183016
               min = 166
               max = 166
              mean = 166.00
            stddev = 0.00
            median = 166.00
              75% <= 166.00
              95% <= 166.00
              98% <= 166.00
              99% <= 166.00
            99.9% <= 166.00
star_latency
             count = 183016
               min = 1939
               max = 3019
              mean = 2352.67
            stddev = 125.38
            median = 2350.00
              75% <= 2420.75
              95% <= 2551.00
              98% <= 2626.00
              99% <= 2681.50
            99.9% <= 3017.00

-- Meters ----------------------------------------------------------------------
star_throughput
             count = 183016
         mean rate = 1694.43 events per 1 Seconds
     1-minute rate = 1692.66 events per 1 Seconds
     5-minute rate = 1684.79 events per 1 Seconds
    15-minute rate = 1682.15 events per 1 Seconds


